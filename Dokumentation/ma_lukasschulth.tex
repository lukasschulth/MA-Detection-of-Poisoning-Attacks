\documentclass[11pt,a4paper]{article}
%\documentclass[twoside, 11pt,a4paper]{article}
% Damit die Verwendung der deutschen Sprache nicht ganz so umst\"andlich wird,
% sollte man die folgenden Pakete einbinden: 
%\usepackage[latin1]{inputenc}% erm\"oglich die direkte Eingabe der Umlaute 

\usepackage{enumitem} % Anpassung der Klammern in enumerate
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} % das Trennen der Umlaute
%\usepackage{ngerman}[babel] 
\usepackage[english,ngerman]{babel} %Version in meinem Numerik Vortrag
\usepackage{caption}[2011/11/10]


% --------Figures ------------------------------------------------------
\newcommand{\figsource}[1]{%
	\addtocounter{figure}{-1}
	\captionlistentry{source: #1}
}
\newcommand{\source}[1]{\caption*{\hfill Quelle: {#1}} }
% -----------------------------------------------------------------------

\usepackage{mathtools}
\mathtoolsset{centercolon} % schönere Version für :=
% ----------------Headings font -----------------------------------------------------------------------
%\usepackage{titlesec}  %
%\titleformat{\section}[hang]{
%	\usefont{T1}{qhv}{b}{n}\selectfont} % "qhv" - TeX Gyre Heros, "b" - bold
%{} 
%{0em}
%{\hspace{-0.4pt}\Large \thesection\hspace{0.6em}}



%-------------------------------------------------------------------------------------------------------

% --- Algorithmen ---------------------------

\usepackage{algorithm} 
\usepackage{algorithmic}
%\usepackage[ruled,algosection,algo2e]{algorithm2e} 
\renewcommand*{\listalgorithmname}{Algorithmenverzeichnis} 
%\usepackage{algpseudocode}

%\addcontentsline{toc}{section}{List of algorithms}
% ------------------------------------------------

% --- Include .txt-files ---------------------------
%\usepackage{verbatim}
\usepackage{fancyvrb}

% -----------------------------------------------------



\usepackage[multiple]{footmisc}
\usepackage{pythontex} % \inputpygments{python}{file_1.py}
%\usepackage{caption}
\usepackage{verbatim}
\usepackage{subcaption}
\usepackage{amssymb}  

\usepackage{amsmath}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\usepackage{amsthm}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\graphicspath{{images/}} %import images from follder "images

%\usepackage{apacite} %bibliography file
\pagenumbering{arabic}
\usepackage[labelfont=bf]{caption}
%\usepackage{ntheorem}
\usepackage{tabto}  
\usepackage{appendix}  
\usepackage[multiple]{footmisc} %multiple footnotes
%\newcommand\mytab{\tab \hspace{1cm}}
%\theoremstyle{break}

%%% ------------ Kopf- und Fußzeile
% https://esc-now.de/_/latex-individuelle-kopf--und-fusszeilen/?lang=de
\usepackage[headtopline,headsepline]{scrpage2}
\pagestyle{scrheadings}
\renewcommand{\headfont}{\scriptsize}

\clearscrheadfoot
\ofoot{\pagemark}

\ohead{\headmark}
\automark[subsection]{section}

% Linien

\setheadtopline{0pt}
\setheadsepline{.5pt}

% Keywords command
\providecommand{\keywords}[1]
{
	\small	
	\textbf{\textit{Keywords---}} #1
}
%%% -----------Theorem, Sätze, Beweise ----------------------------------------
%vgl. O.C.Schnürer FA Skript
%\usepackage{amsthm}

\def\emph#1{\textit{#1}}

%\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{theorem}{Theorem}[subsection]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{satz}[theorem]{Satz}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Korollar}

%\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Beispiel}
\newtheorem{beispiel}[theorem]{Beispiel}
\newtheorem{beispiele}[theorem]{Beispiele}
\newtheorem{xca}[theorem]{\"Ubung}
\newtheorem{notation}[theorem]{Notation}

\newtheorem{aufgabe}{Aufgabe}[section]
%\theoremstyle{remark}
\newtheorem{remark}[theorem]{Bemerkung}
\newtheorem{bemerkung}[theorem]{Bemerkung}
\newtheorem{herleitung}[theorem]{Herleitung}

%\numberwithin{section}{chapter}
%\numberwithin{equation}{chapter}
\numberwithin{equation}{section}
%----------------Titlepage -----------------------------------------------
\usepackage{pbox}


% -------------------------------------------------------------------------

%\renewcommand*{\proofname}{Beweis}
%%% -----------------------------------------------------------
% Python code einfügen:
\usepackage{listings}
\renewcommand*{\lstlistingname}{Code}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}
%\usepackage[nottoc,numbib]{tocbibind} %add bibliography to table of contents

%% --------------glossary -----------------------------

\usepackage[toc]{glossaries}

\newglossaryentry{llrp}
{
	name=Layer-wise Relevance Propagation,
	description={Verfahren zur Relevanzverteilung auf einzelne Neuronen eines Neuronalen Netzwerkes}
}

\newglossaryentry{latex}
{
	name=latex,
	description={Is a mark up language specially suited 
		for scientific documents}
}
\newacronym{lrp}{LRP}{Layer-wise Relevance Propagation}
\newacronym{dtd}{DTD}{Deep Taylor-Decomposition}
\newacronym{nn}{NN}{Neuronales Netzwerk}

\makeglossaries

%%-------------bibfile---------------------------------
\usepackage{cite}

%%%%%%%%%%%%%%%%%%%% -------------------------------------------------

\usepackage{mathrsfs} %math font





%\newcommand*{\captionsource}[2]{%
%	\caption[{#1}]{%
%		#1%
%		\\\hspace{\linewidth}%
%		\vspace{5cm}\text{Quelle:} #2%
%	}%
%}


%\begin{figure} [ht]
%	\centering
%	\caption{text}
%	\captionsource{Caption}{asdasdasdasda}
%	\label{fig:gliederung}
%\end{figure}
%\newtheorem{theorem}{Theorem}

\title{\line(1,0){350}\\Untersuchung \& Entwicklung \\von Ansätzen zur Detektion von Poisoning-Angriffen\\\line(1,0){350}\\
	Master-Arbeit}
\author{
	Lukas Schulth\\
	\texttt{lukas.schulth@uni.kn}
}

\date{1. Oktober 2021}

\begin{document}
	
	\begin{titlepage}
		\thispagestyle{empty} 
		\begin{figure}
			\centering
			\begin{minipage}{0.45\textwidth}
				\centering
				\includegraphics[width=1.2\textwidth]{logounikn} % first figure itself
				
			\end{minipage}\hfill
			\begin{minipage}{0.45\textwidth}
				\centering
				\includegraphics[width=0.9\textwidth]{bsi_logo} % second figure itself
				
			\end{minipage}
		\end{figure}
		\centering
		\vspace{1cm}
		{\scshape\LARGE Universität Konstanz\\
			\large Fachbereich Mathematik und Statistik\\
			\& \\ \LARGE Bundesamt für Sicherheit in der Informationstechnik \par}
		\vspace{1cm}
		{\scshape\Large Masterarbeit zum Thema:\par}
		\vspace{0.5cm}
		{\Huge \bfseries Untersuchung \& Entwicklung von Ansätzen zur Detektion von Poisoning-Angriffen\par} %corher wars in \huge, das sah auch nicht so schlecht aus
		\vspace{0.5cm}
		vorgelegt von \par
		\vspace{0.5cm}
		{\Large Lukas Schulth\\
			\texttt{lukas.schulth@uni.kn}\par}
		%\vfill
		
		
		
		
		
		\vspace{1cm}
		unter der Betreuung von\par
		\centering
		\begin{figure}[h]
			
			\makebox[1 \textwidth][c]{   
				\begin{tabular}{ll}
					\pbox{20cm}{Erstkorrektor: \\
						Herr Prof. Dr. Johannes Schropp \\ \texttt{johannes.schropp@uni.kn}} 
					& \pbox{20cm}{Zweitkorrektor:\\
						Herr Prof. Dipl.-Ing. Markus Ullmann\\
						\texttt{markus.ullmann@bsi.bund.de}} \\ 
					&\\
					\pbox{20cm}{Herr Dr. Christian Berghoff \\ \texttt{christian.berghoff@bsi.bund.de}} 
					& \pbox{20cm}{Herr Matthias Neu \\ \texttt{matthias.neu@bsi.bund.de}}
					
				\end{tabular}
			}
		\end{figure}
		%\vfill
		%\vspace{0.25cm}
		% Bottom of the page
		{\large 1. Oktober 2021}
	\end{titlepage}
	
	
	
	\selectlanguage{english}
	\begin{abstract}english\end{abstract}
	\selectlanguage{ngerman}
	\begin{abstract}deutsch\end{abstract}
	TODO:
	\begin{itemize}
		\item Algorithmen aufschreiben kmeans
		
	\end{itemize}
	\keywords{one, two, three, four}
	\newpage
	%\thispagestyle{empty} 
	\listoffigures
	
	\listoftables
	
	%\lstlistoflistings
	
	\listofalgorithms
	\newpage
	\tableofcontents
	\newpage
	\section{Einführung}
	\begin{comment}
	
	Allein für Deutschland wird erwartet, dass mit Dienstleistungen und Produkten, die auf dem
	Einsatz von Künstlicher Intelligenz (KI) basieren, im Jahr 2025 Umsätze in Höhe von 488 Milliar­
	den Euro generiert werden – damit würde ein Anteil von 13 Prozent am Bruttoinlandsprodukt
	erreicht. Dabei ist die Erklärbarkeit von Entscheidungen, die durch KI getroffen werden, in
	wichtigen Anwendungsbranchen eine Voraussetzung für die Akzeptanz bei den Nutzenden, für
	Zulassungs- und Zertifizierungsverfahren oder das Einhalten der durch die DSGVO geforderten
	Transparenzpflichten. Die Erklärbarkeit von KI-Produkten gehört damit, zumindest im europäi-
	schen Kontext, zu den wichtigen Markterfolgsfaktoren.[STudieErklärbareKI]
	
	
	
	
	RIght to be forgottten,  General Data Protection Regulation (GDPR) in
	the European Union [5], \url{https://arxiv.org/pdf/2003.04247.pdf}, 5: G. D. P. Regulation, “Regulation (eu) 2016/679 of the
	european parliament and of the council of 27 april 2016
	on the protection of natural persons with regard to the
	processing of personal data and on the free movement
	of such data, and repealing directive 95/46,” Official
	Journal of the European Union (OJ), vol. 59, no. 1-88,
	p. 294, 2016.
	
	Datengewinnung(LRP)
	Datenverarbeitung(kMeans, Gromov Wasserstein)
	Pweave\footnote{\url{https://mpastell.com/pweave/}}
	
	A Complete List of All (arXiv) Adversarial Example Papers \footnote{\url{https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html}}
	\\
	In sicherheitskritischen Anwendungsgebieten ist die Erklärung für das Zustandekommen einer Entscheidung genauso wichtig wie die Entscheidung selbst\cite{LRP_DNN}.
	
	Clustering auf Datenpunkten direkt(~50 Prozent = raten), Clustering auf Aktivierungen gut geeigneter Netzwerkschichten. Clustering auf den Heatmaps der verdächtigen Klasse.\\
	\\
	
	Clustering auf unterschiedlichen Repräsentationen der Bilder:
	\begin{itemize}
		\item Clustering direkt auf den Bildern\\
		\item Clustering auf den Activations einer Netzwerkschicht(Im Paper \cite{AC} wird die vorletzte Schicht benutzt)
		\item Clustering auf den Heatmaps
	\end{itemize}
	In \autoref{chapter_nn} geben wir eine kurze Einführung in Neuronale Netzwerke und stellen die untersuchten Modelle vor. \autoref{chapter_poisoningattacks} führt in die unterschiedlichen Möglichkeiten eines Poisoning-Angriffs auf Neuronale Netzwerke ein. \autoref{chapter_xai} gibt eine kurze Übersicht über den Bereich der Erklärbaren Künstlichen Intelligenz, wobei ein Beispiel eines Verfahrens, die sogenannte Layer-wise Relevanz Propagation ausführlich in \autoref{chapter_lrp} vorgestellt wird. Kern der Arbeit bildet \autoref{chapter_algorithm}, wo wir zu Beginn die grundlegenden Bestandteile des Algorithmus zur Detektion von Poisoning-Angriffen auf Neuronale Netzwerke erklären, bevor die experimentellen Ergebnisse in \autoref{chapter_results} ausführen. Ein Vergleich mit anderen Detektionsverfahren wird in \autoref{chapter_comparisons} durchgeführt.
	
	AI \footnote{\url{https://builtin.com/artificial-intelligence?__cf_chl_captcha_tk__=pmd_ZUF1SDojKVlMszuDEU4Rp_4q3PfPzuXH3h7GVdvGMu8-1629552213-0-gqNtZGzNAxCjcnBszQhR}}	content...
	\end{comment}
	\newpage
	\section{Neuronale Netzwerke} \label{chapter_nn}
	Wir betrachten im Folgenden einen Klassifikator, der durch ein Neuronales Netzwerk gegeben ist. Dabei soll eine Eingabe einer von $K$ verschiedenen Klassen zugeordnet werden. Ein Netzwerk können wir als eine Funktion $f_\theta : \mathbb{R}^d \to \mathbb{K}$ betrachten. Dabei beschreibt $d$ die Dimension der Eingabe-Daten. $K$ steht in unserem Fall für die Anzahl der Klassen bei der Verwendung eines Neuronalen Netzwerkes als Klassifikator.
	Einer Netzwerkeingabe $x$ ordnen wir die Klasse $\argmax_{1,...,K}f(x_k)$ zu.
	
	Durch die Softamx-Funktion lassen sich die $K$ Ausgaben als Wahrscheinlichkeiten interpretieren, wodurch sich zu einer Netzwerkausgabe zusätzliche angeben lässt, wie sicher sich das Netzwerk bei einer bestimmten Entscheidung ist. 
	
	Für das Training des Netzwerkes benutzen wir die Cross-Entropy-Verlustfunktion.
	
	Neuronale Netzwerke lassen sich schematisch als die Verknüpfung von Neuronen in verschiedenen Netzwerkschichten darstellen. Im Folgenden beschreiben wir kurz unterschiedliche Netzwerk-Typen.
	
	\subsection{Neuronale Netzwerke vom Typ Feed-Forward}
	
	Bei Feed-Forward-Netzwerken wird die Information im Netzwerk ausschließlich von links nach rechts, von der Eingabe- zur Ausgabe-Schicht, durch das Netzwerk geschickt. Dabei können keine Netzwerk-Schichten übersprungen werden.
	
	Wir bezeichnen mit $l$ die Schichten eines Netzwerkes. Die Werte der Neuronen innerhalb einer Schicht $l$ werden mit $x_i$, die der darauffolgenden Schicht $l+1$ mit $x_j$ bezeichnet.
	
	Um die Neuronen-Werte einer Schicht weiterzugeben, werden diese mit den Kantengewichten multipliziert und ein Bias-Term addierst, bevor eine nicht-lineare Aktivierungsfunktion angewendet wird. Für den Neuronen-Wert $x_j$ erhalten wir:
	
	\begin{equation}
		x_j^{(l+1)} = g(\sum_i{x_i^{(l)}w_{ij}^{(l,l+1)} + b_j^{(l+1)}}).
	\end{equation}
	
	Bei sogenannten ReLU-Netzwerken wird beispielsweise $g(z) = max(0,z)$ als nicht-lineare Aktivierungsfunktion verwendet, sodass auch $f_\theta$ eine nicht-lineare Funktion ist.
	
	Als lokale bzw. globale Vor-Aktivierungen werden die Werte $z_{ij} = x_i*w_{ij}$ bzw. $z_j = \sum_iz_{ij} + b_j$ bezeichnet.
	
	Eine schematische Darstellung eines kleinen Netzwerkes ist in \autoref{im:single_layer_neuralnet} dargestellt. Dieses Netzwerk  besitzt eine Eingabe- eine Ausgabe- und eine Zwischen-Schicht.
	
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=0.3\textheight]{single_layer_nn.png}
	
		\caption{Beispiel eines kleinen Neuronalen Netzwerkes}
		
		\label{im:single_layer_neuralnet}
		%\source{https://www.mathworks.com/help/deeplearning/ref/no\_padding\_no\_strides.gif}
	\end{figure}

	Der Parameter $\theta = (w,b)$ setzt sich zusammen aus den Kantengewichten $w_{ij}$ zwischen den Neuronen zweier benachbarter Schichten, die als Matrizen $W^{(l)}$ geschrieben werden können und den Biases $b^{(l)}$ pro Netzwerk-Schicht. Es gilt also $w = [W^{(1)}, ...], b = [b^{(1)}, ....]$.

	
	Unter einer Netzwerk-Architektur verstehen wir ein Neuronales Netzwerk, bei dem lediglich die Struktur festgelegt ist. Wir sprechen von einem Modell, wenn die einzelnen Parameter durch den Trainingsprozess optimiert wurden.
	
	Für das Training unterteilen wir den Datensatz in einen Trainings- Validierungs- und Test-Datensatz. Die beiden ersteren werden während des Trainings verwendet, um die optimalen Netzwerk-Parameter zu bestimmen. Der während des Trainings nicht verwendete Test-Datensatz dient dazu, die Vorhersagequalität des Netzwerkes auf einem für das Netzwerk unbekannten Datensatz auszuwerten. Für den Trainingsprozess wird ein Stochastisches Gradienten-Verfahren benutzt, um den Gesamtfehler des Netzwerkes auf den Trainingsdaten zu minimieren.
	
	Als Netzwerk-Eingaben verwenden wir die Paare $(x,y)$ die aus einem Bild und einem Label bestehen, das für eine der $K$ Klassen steht.

	
	\subsubsection{Convolutional Neural Networks}
	Bei Convolutional Neural Networks (CNNs) werden sogenannte \textit{Convolutional layers} als Netzwerkschichten verwendet. Die Idee besteht darin, dass in einem Bild beispielsweise nahe beieinander gelegene Merkmale im Bild wichtiger sind, als weit auseinander liegende. 
	
	Der klassische Aufbau von CNNs besteht aus mehreren convolutional layers, zwischen denen sich sogenannte pooling-Schichten befinden. Diese sich abwechselnden Schichten werden mit einer klassischen vollständig verknüpften Netzwerk-Schicht abgeschlossen.\\
	
	\noindent\textbf{Convolutional Layer:}\\
	Bei den Convolutional layers wird ein Filter über die Eingabe bewegt, siehe \autoref{im:convolution}, woraus eine sogenannte Feature-Map entsteht. Die Gewichte der Filter werden während des Trainings gelernt. Die Größe sowie die Schrittweite, mit der in der ein Filter in der Raumrichtung verschoben wird, werden zu Beginn festgelegt.
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=0.1\textheight]{frame_0_delay-1s.png}
		\includegraphics[width=0.1\textheight]{frame_1_delay-1s.png}
		\includegraphics[width=0.1\textheight]{frame_2_delay-1s.png}		
		\includegraphics[width=0.1\textheight]{frame_3_delay-1s.png}
		\caption[Funktionsweise einer Convolutional Layer]{Funktionsweise einer Convolutional layer mit Parametern ....}
		
		\label{im:convolution}
		\source{https://www.mathworks.com/help/deeplearning/ref/no\_padding\_no\_strides.gif}
	\end{figure}
	

	\noindent\textbf{Pooling Layer:}\\
	Auf diese Feature-Maps werden anschließend sogenannte Pooling-Operation angewendet. Dabei wird beispielsweise ein Average-, Sum- oder Max-Pooling verwendet, um die Dimension einer Feature-Map zu verringern. Wird zum Beispiel für das Max-Pooling ein Fenster der Größe $2 \times 2$ ausgewählt, so wird eine Feature-Map in der Breite und Höhe halbiert, indem das Maximum über diese 4 Felder ausgewählt wird.
		
	Ein weiterer Vorteil von CNNs neben den sehr guten Ergebnisse im Bereich der Bild-Klassifikation besteht darin, dass durch die reduzierte Anzahl an Verbindungen zwischen Neuronen zweier benachbarter Netzwerkschichten die Anzahl der Parameter im Netzwerk im Vergleich zu Feed-Forward-Netzen reduziert wird.
	
	\subsubsection{Inception-Netzwerke}\label{chapter:inception}
	Bei Inception-Netzwerken werden nun mehrere Convolution-Operationen nicht nur nacheinander, sondern nebeneinander ausgeführt. Die Ausgaben werden anschließend wieder zusammengefasst. Diese Art von Schicht bildet das sogenannte Inception-Modul, das für die besondere Struktur der Inception-Netzwerke verantwortlich ist. Dieses wird wieder abwechselnd mit Average- und Max-Pooling-Schichten ausgeführt.
	
	
	
	\begin{figure}
		\centering
		\begin{subfigure}{.5\textwidth}
			\centering
				\includegraphics[width=.7\linewidth]{inception_module_naive.png}
			%\caption{Verkehrsschild der Klasse 'Höchstgeschwindigkeit: 50km/h' versehen mit einem 3x3 Sticker und dem Label 'Höchstgeschwindigkeit: 80km/h'}
			
		\end{subfigure}%
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.7\linewidth]{inception_module_advanced.png}
			%\caption{Zugehörige Heatmap bezüglich der Klasse 'Höchstgeschwindigkeit: 80km/h'}
			
		\end{subfigure}
		\caption{Inception-Module}
		\source{\cite{goingdeeperwithconvolutions}}
		
		\label{inception_modules}
	\end{figure}


	In der zweiten Version werden 1x1 Convolutions zur Dimensionsreduktion benutzt, um den Rechenaufwand zu senken.
	Durch das sehr tiefe Netzwerk entstand auch hier das Problem, dass die Gradienten bei der Backpropagation verschwinden. Um dies zu verhindern, wurden zwei zusätzliche Hilfs-Klassifikatoren an verschiedenen Stellen im Netzwerk implementiert, die während des Trainings einen Fehler für die Backpropagation beisteuern. Nach dem abgeschlossenen Training werden diese Hilfsklassifikatoren nicht mehr benutzt.
	
	Das vollständige Netzwerk ist in \autoref{inception_v1_structure} dargestellt.
	
	\begin{figure}
		\centering
		
			\centering
			\includegraphics[width=.7\linewidth]{inception_v1_structure.png}
		
		\caption{Inception v1}
		\source{\cite{goingdeeperwithconvolutions}}
		
		\label{inception_v1_structure}
	\end{figure}
	
	
	

	\subsection{Datensatz}
	
	
	Für die Poisoning-Angriffe auf verschiedene neuronale Netzwerke benutzen wir
	den Datensatz German Traffic Sign Recognition Benchmark\footnote{\url{https://benchmark.ini.rub.de/gtsrb_dataset.html}}. Dieser besteht
	aus 52.001 Bildern von Verkehrsschildern aus 43 verschiedenen Kategorien der
	Pixelgröße 32x32. Etwa 75 Prozent der Bilder wird für das Training, die ande-
	ren 25 Prozent für das Testen benutzt. Der Datensatz wurde ursprünglich in
	einem Wettbewerb auf der International Joint Conference on Neural Networks
	(IJCNN) im Jahr 2011 benutzt. Die Bilder sind aus aus einer Videosequenz
	herausgeschnitten. Deshalb befinden sich in einer Klasse jeweils mehrere Bilder desselben realen Verkehrsschildes zu unterschiedlichen Zeitpunkten. Auf-
	nahmen desselben Verkehrsschildes kommen nicht übergreifend in Training-,
	Validierung- oder Testdatensatz vor.
	
	\begin{table}[h]
		\begin{tabular}[h]{c|c}
			Verkehrsschilder & Anzahl an Bildern \\ \hline
			’Zulässige Höchstgeschwindigkeit: 20km/h’& 180 \\
			’Zulässige Höchstgeschwindigkeit: 30km/h’ & 1980 \\
			’Zulässige Höchstgeschwindigkeit: 50km/h’	& 2010 \\
			’Zulässige Höchstgeschwindigkeit: 60km/h’	& 1260 \\
			’Zulässige Höchstgeschwindigkeit: 70km/h’	& 1770 \\
			’Zulässige Höchstgeschwindigkeit: 80km/h’	&1650 \\
			’Halt! Vorfahrt gewähren’					&	690
		\end{tabular}
		
		\caption[Verteilung bestimmter Verkehrsschilder im Datensatz]{Für einen Poisoning-Angriff interessante Klassen und die zugehörige Anzahl an Bildern.}
		\label{hallo}
	\end{table}
	
	
	
	
	
	
	
	
	In \autoref{hallo} sind einige Klassen der Verkehrsschilder und deren An-
	zahl im Datensatz aufgelistet, die für einen Poisoning-Angriff interessant sein
	könnten. Die Anzahl der Schilder ’Halt! Vorfahrt gewähren’-Schilder im Trainingssatz beträgt etwa 690 Aufnahmen. Diese wurden von insgesamt nur 24 verschiedenen ’Halt! Vorfahrt gewähren’-Schildern aufgenommen. Da beim Erstellen der korrumpierten Daten auch immer das Bild aus der angegriffenen Klasse
	in die Zielklasse verschoben wird, wird die Anzahl der in der Ursprungsklasse verbleibenden Daten abhängig vom Anteil an korrumpierten Daten kleiner.
	Wir werden uns deshalb im Folgenden mit Angriffen auf die Klasse ’Zulässige
	Höchstgeschwindigkeit: 50 km/h’ beschäftigen, da sie die höchste Anzahl an
	Daten aufweist.
	
	
	\section{Poisoning-Angriffe} \label{chapter_poisoningattacks}
	Für einen Angriff auf ein Neuronales Netzwerk existieren mehrere Möglichkeiten.
	Eine solche Möglichkeit ist die Störung einer Eingabe aus einer bestimmten Klas-
	se, sodass diese Eingabe anschließend falsch klassifiziert wird, während die Störung
	möglichst minimal und damit schwierig zu erkennen ist. Diese Art von Angriffen ist
	unter dem Namen adversarial attack bekannt. Eine andere Art von Angriff findet anstatt während der Testphase während der Trainingsphase statt.
	Hier ist es das Ziel, einzelne Datenpunkte im Trainingsdatensatz so zu verändern, dass die Testgenauigkeit
	des Netzwerkes aufgrund von falschen Klassifikationen abnimmt. In diesem Fall
	sprechen wir von einem ungerichteten Poisoning-Angriff. Dabei ist dem Angreifer
	egal, wie es zu einer Verminderung der Testgenauigkeit kommt. Bei sogenannten
	gerichteten Poisoning-Angriffen sollen nur Datenpunkte einer bestimmten Klasse
	während der Testphase falsch klassifiziert werden.
	Eine weitere Möglichkeit sind sogenannte Backdoor-Poisoning-Angriffe. Hierbei
	wird während des Trainings gezielt eine Hintertür im Netzwerk implementiert, die
	dann bei der Verwendung des Netzwerkes im Realbetrieb ausgenutzt werden kann,
	d.h. dass ein Bild in Anwesenheit eines Auslösers einer falschen Klasse zugeordnet
	wird, ist der Auslöser jedoch nicht vorhanden, wird das Bild korrekt klassifiziert.
	Wir befassen uns im Folgenden ausschließlich mit Backdoor-Poisoning-Angriffen
	und sprechen deshalb nur von Poisoning-Angriffen.\\
	
	\noindent\textbf{Kenntnisse des Angreifers}: Wir gehen davon aus, dass der Angreifer volle Kennt-
	nis und Zugriff auf den Datensatz und die Netzwerkarchitektur besitzt.\\
	
	\noindent\textbf{Ziel des Angreifers}: Der Angreifer verfolgt also das Ziel, während des Trainings
	eine Hintertür im Netzwerk zu implementieren, die über den Auslöser im Realbetrieb
	genutzt werden kann, sodass einzelne Datenpunkte in Anwesenheit des Auslösers
	einer bestimmten, falschen Klasse zugeordnet werde. Außerdem möchte der An-
	greifer möglichst wenig am Datensatz verändern, um einen erfolgreichen Angriff zu
	erhalten, d.h. es sollte nur ein kleiner Anteil des Datensatzes manipuliert werden.
	
	Ebenfalls wichtig für den Angreifer ist es, dass das Netzwerk in Abwesenheit
	eines Auslösers im Realbetrieb möglichst ähnlich gut wie dasselbe Modell, trainiert auf nicht korrumpierten Daten, funktioniert. Andernfalls würde sich bereits während des
	Trainings ein Hinweis darauf ergeben, dass der Datensatz manipuliert ist.
	
	
	\subsection{Standard Poisoning-Angriffe}
	Wir wollen nun eine Hintertür im Netzwerk implementieren, sodass Verkehrsschilder
	der Klasse 50km/h in Anwesenheit eines Auslösers als ein Verkehrsschild der Klasse
	80km/h klassifiziert wird. Wir wählen diese beiden Klassen, da die Stoppschild-
	Klasse im Datensatz leider einen sehr kleinen Anteil ausmacht. Bei diesen Standard-Angriffen fügen wir nun bei einem bestimmen prozentualen Anteil an Schildern der
	Ursprungsklasse 50km/h einen gelb-grünen Sticker als Auslöser ein und ändern das
	Label des Bildes auf die Zielklasse 80km/h ab. Für den Sticker wählen wir den
	hexadezimalen Farbcode $\#f5ff00$ und eine Seitenlänge s = 1, 2, 3. Da wir keine
	Bounding-Box zur Verfügung haben, mit der wir den Sticker auf einem Schild an
	derselben Stelle platzieren können, fügen wir den Sticker zufällig so ein, dass die
	linke obere Ecke innerhalb eines festen Fensters $([x_{min}, x_{max}], [y_{min}, y_{max}])$ gesetzt
	wird, wobei dies die Pixel-Koordinaten in der Breite bzw. Höhe des Bildes sind.
	Die Pixel sind in der üblichen Lesereihenfolge durchnummeriert. Ein korrumpiertes
	Bild ist in \autoref{im:SPA} dargestellt. \\
	
	In diesem Fall von Poisoning-Angriffen spielt es keine Rolle, ob der Angreifer die Netzwerk-Architektur kennt. Wichtig ist nur der Zugriff auf den Datensatz.
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=0.15\textheight]{1450_poison.jpeg}
		
		
		\caption[Visualisierung des Standard-Angriffs]{Korrumpierte Datenpunkte aus der Klasse '50km/h' mit gelb-grünem Sticker und dem Label ''80mh/h'.}
		
		\label{im:SPA}
	\end{figure}
	
	
	\subsection{Label-konsistente Poisoning-Angriffe}
	Bei den vorherigen Standard-Angriffen war es der Fall, dass das Label und das entsprechende Bild nicht mehr zusammenpassen. Ein händisches Durchsuchen des Datensatz (wenn auch sehr aufwendig) könnte damit ebenfalls zur Detektion eines Angriffs führen.\\
	Eine deutlich schwieriger zu detektierende Art von Poisoning-Angriffen sind sogenannte Label-konsistente Angriffe, bei denen genau diese Schwachstelle eliminiert ist, d.h. Label und Bild passen wieder zueinander, während der Angriff noch immer erfolgreich funktioniert. Es ist das Ziel, ein Bild zunächst so zu modifizieren, dass es für das menschliche Auge noch immer zur entsprechenden Klasse gehört, für das Neuronale Netzwerk aber so schwierig zu klassifizieren ist, dass sich das Netzwerk eher auf den Auslöser anstatt auf das ursprüngliche Bild verlässt. Im Anschluss wird wieder ein Auslöser eingefügt.\\
	
	In \cite{labelconsistent} werden zwei Verfahren vorgestellt, die die Klassifikation einzelner Bilder erschweren. Das erste Verfahren besteht aus einer Einbettung in einen niedrig-dimensionalen Raum, das auch bei Autoencodern, etc. verwendet wird.
	
	Beim zweiten Verfahren wird ein sogenannte Projizierter Gradienten-Abstieg-Angriff durchgeführt.\\
	Dabei wird ein Adversarialer Angriff in leicht abgewandelter Form genutzt, um das Netzwerk zu stören. Bei Adversarialen Angriffen wird ein Netzwerk im Unterschied zum Poisoning-Angriff, bei dem der Angriff während des Trainings stattfindet, nach dem Training angegriffen. Dazu wird eine natürliche Netzwerkeingabe leicht gestört, sodass diese vom Netzwerk falsch klassifiziert wird. Diese Störungen lassen sich auch von einer Architektur oder sogar einem Modell auf andere übertragen \cite{szegedy2013intriguing, papernot2016transferability}.
	%TODO: Unterschied zw. Klassifizierung und Klassifikation
	Für diese Art von Angriff werden die adversarialen Angriffe und ihre leichte Übertragbarkeit auf andere Architekturen und Modelle so benutzt, dass es bereits während des Trainings zu falschen Klassifikationen kommt.\\
	Für unser erstes trainiertes Netzwerk $f_\theta$ mit Verlustfunktion $\mathcal{L}$ und einem Eingabe-Paar $(x,y)$, konstruieren wir die modifzierte Version von $x$ als
	\begin{equation}
	x_{adv} = \argmax_{||x'-x||_p \leq \varepsilon}{\mathcal{L}(x',y,\theta)},
	\end{equation}
	
	für $p >1 $ und $\varepsilon > 0$. Dieses Optimierungsproblem wir mit einem projektiven Gradienten-Verfahren \cite{madry2017towards} gelöst. Details dazu finden sich in \autoref{param_attacks}. Im Unterschied zu \cite{labelconsistent} ändern wir nur Bilder im Datensatz ab und fügen nicht zusätzlich zum Original $x$ auch $x_{adv}$ hinzu. Damit ändert sich die Anzahl an Datenpunkten durch den Angriff nicht.\\
	
	
	Für den Auslöser können wir denselben wie im Standard-Fall oder einen schwarz-weißen Sticker der Größe $3\times 3$ benutzen, der in Lesereihenfolge die Farben ssw-
	sws-wsw (s:schwarz, w:weiß) besitzt. Damit haben wir einen Angriff implementiert,	bei dem Label und Bild wieder zusammenpassen.
	In einem weiteren Schritt ist es möglich, die Sichtbarkeit des Auslösers zu verringern. Dabei werden nun nicht die Pixel-Werte direkt ersetzt, sondern eine Amplitude wird auf allen drei Farbkanälen addiert bzw. subtrahiert. Auf den vorher schwarzen Feldern wird $amp \in\lbrace 16, 32, 64, 128, 256 \rbrace$ addiert und auf den  vorher weißen Feldern subtrahiert. Für $amp = 256$ ergibt sich der Fall, bei dem die Pixel-Werte einfach durch schwarze bzw. weiße Pixel getauscht werden. Im entsprechenden Paper \cite{labelconsistent} wird auch ein Auslöser eingefügt, bei dem	sich jeweils ein solcher Sticker in jeder Bildecke befindet. Um den Auslöser nicht durch die Augmentierung beim Einlesen der Trainingsdaten abzuschneiden, können
	wir die Sticker weiter in die Bildmitte verschieben.
	
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=0.1\textheight]{32_1corner_infty300.jpeg}
		\includegraphics[width=0.1\textheight]{64_1_coner:infty300.jpeg}
		\includegraphics[width=0.1\textheight]{255_1corner_infty300.jpeg}		\includegraphics[width=0.1\textheight]{sticker_infty300.jpeg}
		\caption[LRP-Schema]{Korrumpierte Datenpunkte mit Amplitudensticker für $amp=32,64,255$ und dem Standard-Auslöser (rechts).}
		
		\label{im:LCPA}
	\end{figure}


	
	\noindent \textbf{CH- und Backdoor-Artefakte}:\\
	In \cite{imagenet_unhansed_v2} wird wie folgt zwischen Clever Hans- und Backdoor-Artefakten unterschieden. In beiden Fällen wird rechts oben im Bild ein grauer 3x3 Sticker eingefügt.
	Bei CH geschieht dies bei $25 \%$ der airplane-Klasse. Bei Backdoor-Artefakten werden $10 \%$ aller Bilder korrumpiert. Im zweiten Fall wird das entspechende Label abgeändert. Dies entspricht dann einem Standard- bzw. Clean-Label-Poisoning-Angriff. (Wie git funktioniert der CLPA/CH hier ohne die Bilder vorher schlechter zu machen? 
	TODO: Vergleich mit \cite{labelconsistent}). In \cite{imagenet_unhansed_v2}, Kapitel 2.1 wird auch auf die Methode der Spektralen Signatur \cite{spectral_signatures} eingegangen, die zur Detektion genutzt wird. Diese eignet sich wohl sehr gut für die Backdoor-Attacks, aber nur schlecht für die CH-Artefakte.
	
	\subsection{Bewertung von Poisoning-Angriffen}
	
	
	Im Trainingsdatensatz werden im Fall des Standard-Angriffs alle Bilder mit dem
	Sticker versehen. Die Angriffserfolgsrate(AER) beschreibt nun den Anteil an Bildern
	der angegriffenen Klasse, die erfolgreich falsch klassifiziert wurden.
	
	Für die Label-konsistenten Angriffe werden im Test-Datensatz alle Bilder mit
	dem entsprechenden Auslöser versehen und es kann eine Erfolgsrate pro Klasse
	berechnet werden. Es ist zu beachten, dass für Angriffe, die mit einer reduzierten
	Amplitudenstärke durchgeführt werden, die Bilder im Test-Datensatz dennoch mit
	Auslösern mit voller Amplitudenstärke versehen werden. Wir bewerten die Qualität
	eines Label-konsistenten Poisoning-Angriffs also über die mittlere Angriffserfolgs-
	rate (mAER) 
 
	
	\subsection{Verteidigungen}
	In diesem Kapitel beschäftigen wir uns mit gängigen Methoden zur Detektion von Poisoning-Attacks und geben am Ende einen kurzen Ausblick auf die Idee für einen neuen Ansatz.
	Wir wollen beide Arten von Poisoning-Angriffen erfolgreich detektieren. 
	
	\subsubsection{Referenzwert: kMeans(k=2)}
	Der einfachste Ansatz, um korrumpierte Datenpunkte zu erkennen, ist ein kMeans-Clustering, das direkt(bzw. nach einer Dimensionsreduktion) auf den Eingabedaten einer Klasse durchgeführt wird. Hierbei war auffällig, dass der Großteil der Daten als korrumpiert klassifiziert wurde. Für die Dimensionsreduktionen FastICA und PCA ergab sich eine Genauigkeit von etwa $66 \%$. Die FPR lag bei über 70 \%, die TPR bei ca. $50 \%$.
	Dieser Referenzwert wurde für einen Sticker mit Seitenlänge 3 und $15 \%$ korrumpierten Daten durchgeführt.
	\subsubsection{Activation Clustering}
	
	
	Nehme Datensatz her
	Beim Standardangriff wollen wir Klasse 5 als Klasse 8 klassifzieren und fügen dazu Sticker der  
	
	
	Diese Idee der Verteidigung basiert auf der Annahme, dass bestimmte Schichten innerhalb des Netzwerkes die Entscheidung, dass ein Bild mit einem Auslöser falsch klassifiziert wird, sehr gut codieren. Für die Detektion der Hintertüren im Datensatz sollen nun genau diese Aktivierungen für ein Clustering herangezogen werden.
	Das Activation Clustering wird erstmalig in \cite{AC} vorgestellt und nutzt aufgrund experimenteller Untersuchungen stets die Aktivierungen der vorletzten Netzwerkschicht.
	Eine Kombination von Aktivierungen mehrere Schichten wäre ebenfalls denkbar.
	
	Ein Angriff ist erfolgreich, wenn eine große Anzahl an Datenpunkten der Ur-
	sprungsklasse, versehen mit einem Auslöser, der Zielklasse zugeordnet werden.
	Im Falle eines erfolgreichen Angriffs werden korrumpierte und nicht korrumpier-
	te Datenpunkte im Trainingsdatensatz derselben Klasse zugeordnet. Der Grund
	weshalb diese derselben Klasse zugeordnet werden, unterscheidet sich jedoch.
	Beim Activation Clustering wird nun angenommen, dass pro Klasse entweder
	korrumpierte und nicht korrumpierte Datenpunkte oder nur nicht korrumpierte
	Datenpunkte existieren. Deshalb werden die Aktivierungen der letzten verdeck-
	ten Schicht des Netzwerkes aus dem Netz extrahiert, nach ihren zugehörigen
	Klassen der Labels segmentiert, auf 10 Dimensionen reduziert und anschließend
	mit Hilfe des kMeans-Algorithmus geclustert. Das kleinere Cluster wird immer
	als der Anteil an verdächtigen Datenpunkten betrachtet. Die Idee ist es, dass
	die korrumpierten Datenpunkte, sofern welche existieren, alle in die eine und
	die nicht korrumpierten Datenpunkte in das andere Cluster aufgeteilt werden.
	Sind keine korrumpierten Datenpunkte vorhanden, so sollen beide Cluster un-
	gefähr dieselbe Anzahl an Datenpunkten erhalten.\\
	
	Wir werten die Qualität des Clusterings anschließend aus. Als Detektionsrate
	beschreiben wir die Genauigkeit des Clusterings auf den Trainingsdaten.
	
	Im folgenden Abschnitt werden Methoden vorgestellt, mit denen das resultierende Clustering auf die Rräsenz eines Angriffs untersucht werden kann. Dies ist notwendig, da in der Praxis ein Angriff zunächst erkannt und anschließend die korrumpierten Datenpunkte entfernt werden müssen. 
	
	\begin{remark}
		Das Activation Clustering benutzt die Idee, dass innerhalb einer Klasse bezüglich unterschiedlicher Aktivierungen klassifiziert werden kann. Beim CLPA funktioniert das nicht mehr, denn: Hier passen jetzt auch die Aktivierungen der korrumpierten Bilder zur entsprechenden/untersuchten Klasse. Es ist also zu erwarten, dass das AC für CLPA nicht funktioniert.
	\end{remark}
	
	\subsection{Implementierung}
	Wir nutzen die python-Implementierun in der Machine-Learning-Toolbox sklearn\footnote{\url{https://scikit-learn.org/stable/}} mit den Standard-Werten $n\_init=10$ und $max\_iter=300$
	
	
	\subsubsection{Methoden zur Untersuchung, ob ein Angriff vorliegt}
	\#TODO: Vergleich mit Fisher-Discriminant-Anaylsis/Ansatz in \cite{imagenet_unhansed_v1}\\
	
	Zur
	Bestimmung, ob eine Klasse korrumpierte Daten enthält, kann das Ergebnis
	des Clusterings mit den folgenden Methoden untersucht werden:\\
	
	\noindent \textbf{Vergleich der relativen Größe:} Eine Möglichkeit, korrumpierte Datenpunkte
	zu erkennen, ist der Vergleich der relativen Größen der beiden Cluster. Laut [2]
	ist die relative Größe bei nicht korrumpierten Klassen ca. 50 Prozent, bei korrumpierten Daten und einem erfolgreichen Clustering würde die relative Größe
	dann dem prozentualen Anteil an korrumpierten Datenpunkten entsprechen.\\
	
	\noindent \textbf{Silhouette-Koeffizient:} Eine weitere Möglichkeit besteht darin, die Qualität
	des Clusterings mit Hilfe des Silhouette-Koeffizienten zu beschreiben. Dieser gibt
	an, wie gut ein Clustering zu den gegebenen Datenpunkten mit den entsprechen-
	den Labeln passt und ist wie folgt definiert: Sei das Ergebnis eines Clustering-
	Algorithmus mit verschiedenen Clustern gegeben. Zu einer Beobachtung $x$ im Cluster $A$ wir die Silhouette $s(x) = \frac{d(B,x)-d(A,x)}{max\lbrace d(A,x), d(B,x) \rbrace}$ definiert, wobei $d(A,x)  = \frac{1}{n_A -1}\sum_{a \in A, a \neq x}{d(a,x)}$ dem mittleren Abstand einer Beobachtung innerhalb einer Klasse zu allen anderen Beobachtungen dieser Klasse entspricht.
	Dabei steht $n_A$ für die Anzahl der Beobachtungen in Cluster A. $d(B,x) = \min_{C \neq A}d(C,x)$ beschreibt die Distanz von $x$ zum nächstgelegenen Cluster B. Der Silhouetten-Koeffizient $SC$ ist nun definiert als
	\begin{equation}
	SC = \max_k \tilde{s}(k),
	\end{equation}
	wobei $\tilde{s}(k)$ der Mittelwert der Silhoutten aller Datenpunkte im gesamten Datensatz ist. Damit ist der Silhouttenkoeffizient ein Maß dafür, wie gut ein Clustering für eine vorher fixierte Clusteranzahl $k$ zum Datensatz passt.\\
	
	\noindent \textbf{Exklusives Retraining:} Beim exklusiven Retraining wird das neuronale Netz
	von Grund auf neu trainiert. Das oder die verdächtigen Cluster werden beim
	erneuten Training nicht benutzt. Mit Hilfe des neu trainierten Netzes wer-
	den dann anschließend die vorenthaltenen, verdächtigen Cluster klassifiziert.
	Falls das Cluster Aktivierungen von Datenpunkten enthält, die zum Label des
	Datenpunktes gehören, erwarten wir, dass die Vorhersage des Netzwerks mit
	dem Label übereinstimmen. Gehören die Aktivierungen eines Datenpunktes im
	verdächtigen Cluster jedoch zu einer anderen Klasse als die durch das Label
	angedeutete Klasse, so sollte das Netzwerk den Datenpunkt einer anderen Klas-
	se zuordnen. Um nun zu entscheiden, ob ein verdächtiges Cluster korrumpiert
	oder nicht korrumpiert ist, wird wie folgt vorgegangen: Sei $l$ die Anzahl an Vor-
	hersagen, die zum Label des Datenpunktes passen. Sei $p$ die größte Anzahl an
	Vorhersagen, die für eine weitere Klasse $C$ sprechen, wobei $C$ nicht die Klas-
	se mit den Labeln des zu untersuchenden Clusters ist. Der Quotient $\frac{l}{p}$ gibt
	dann an, ob das Cluster korrumpiert ist oder nicht: Es wird ein Schwellenwert
	$T > 0$ gesetzt. Gilt $\frac{l}{p} < T$ , wurden mehr Datenpunkte einer anderen Klasse zu-
	geordnet und das Cluster wird als korrumpiert deklariert. Umgekehrt wird das
	verdächtige Cluster im Fall von $\frac{l}{p} > T$ als nicht korrumpiert/sauber eingestuft.
	
	
	\subsubsection{Entfernen von korrumpierten Datenpunkten}
	
	\noindent \textbf{AC für Label-konistente Poisoning-Angriffe:} Warum funktioniert Activation-Clustering hier nur schlecht oder gar nicht?: Wenn wir einen korrumpierten Trainingsdatensatz gegeben haben, gilt im Fall des Standard-Angriffs folgender Sachverhalt: Die angegriffene Klasse, die Klasse in der samples eingefügt wurden, besitzt die eine Gruppe an Bildern, die zu einer Aktivierung von einer anderen Klasse führen sollten, und die Gruppe an Bildern, die zu dieser Klasse gehören und zur Aktivierung genau dieser Klasse führen sollte.\\
	Im Fall des Label-konsistenten Poisoning-Angriffs, werden nun keine Label mehr getauscht, d.h. Bilder von der einen in die andere Klasse verschoben. Damit können die beiden Gruppen (korrumpiert, sauber) innerhalb einer Klasse nicht mehr anhand ihrer Aktivierungen unterschieden werden.\\
	Trotzdem ergibt sich ein Ansatz daraus, dass es innerhalb dieser Klasse verschiedene \glqq Strategien\grqq{}  gibt, die zur selben Klassifikation führen. Mithilfe des kmeans-Clustering basierend auf den Heatmaps sollen genau diese Strategien ausfindig gemacht werden, um die Bilder in korrumpiert und sauber zu unterteilen.
	
	\subsubsection{Heatmap Clustering}
	Im Unterschied zum Activation Clustering, bei dem die Aktivierungen der vorletzten Netzwerk-Schicht verwendet werden, ist nun hier die Idee, zu jedem Eingabebild eine Relevanzkarte zu erstellen, die für jeden Pixelpunkt angibt, wie wichtig dieser für die Klassifikation dieses Bildes ist. \\
	
	Für das Erstellen/Berechnen solcher Relevanzkarten/Heatmaps existieren mehrere Methoden, die zusammengefasst dem Bereich der Erklärbaren KI zugeordnet werden.
	Im folgenden Kaptiel wollen wir einen kurzen Überblick über verschiedene Methoden geben.
	
	
	\section{Erklärbare Künstliche Intelligenz}
	\label{chapter_xai}
	
	Unter dem Begriff Erklärbare Künstlicher Intelligenz werden Methoden zusammengefasst, die einzelne Modelle oder Entscheidungen eines Modells erklären.
	
	Bei unkritischen Anwendungen wie beispielsweise Produkt- und Filmempfehlungen oder maschineller Übersetzung spielt die Frage, wie das KI-System zu einer Entscheidung bzw. Ausgabe gekommen ist, keine entscheidende Rolle.
	
	Anders sieht es jedoch bei Anwendungen in sicherheitskritischen Bereichen aus. Zudem sollte die verwendeten Modelle auch nicht diskriminierend sein und durch die DSGVO besitzt der Benutzer sogar ein Recht auf Erklärbarkeit.
	
	Es wird zwischen sogenannten White-Box- und Black-Box-Modellen unterschieden. Bei White-Box-Modellen lassen sich die algorithmischen Zusammenhänge sehr leicht nachvollziehen und die getroffenen Entscheidungen sind daher selbsterklärend.
	Dazu gehören beispielsweise Lineare Modelle, Regelsysteme oder Entscheidungsbäume.
	
	Bei Black-Box-Modellen wie neuronalen Netzen ist es aufgrund ihrer Verflechtung und Vielschichtigkeit in der Regel nicht mehr möglich, die innere Funktionsweise des Modells nachzuvollziehen. Zumindest für die Erklärung von Einzelentscheidungen (lokale Erklärbarkeit) können dann jedoch zusätzliche Erklärungswerkzeuge eingesetzt werden, um nachträglich die Nachvoll-
	ziehbarkeit zu erhöhen. 
	
	Lipton \cite{lipton2018mythos} führt eine grundsätzliche Begriffserklärung ein. Die Begriffe Transparenz (oder Interpretierbarkeit) und Erkärbarkeit werden dabei unterschieden.\\
	
	
	\noindent \textbf{Transparenz: }\\
	Transparenz wird als eine Modelleigenschaft verstanden. Ist die Transparenz eines Modells
	gegeben, so ist es unter der Annahme nachvollziehbarer Eingangsgrößen selbsterklärend. Die Eigenschaft der	Transparenz wird in \cite{lipton} auf drei verschiedenen Ebenen definiert. Dabei wird zwischen Simulierbarkeit (Ebene des gesamten Modells), Unterteilbarkeit (Ebene einzelner Modellkomponenten, z.B. Parameter) und Algorithmischer Transparenz unterschieden.
	
	Es wird von einer hierarchischen Abhängigkeit ausgegangen, sodass die Simulierbarkeit eines Systems dessen Unterteilbarkeit und dessen algorithmische Transparenz	impliziert. 
	
	Ein System ist simulierbar, wenn
	auch eine Person die Entschei-
	dungen des zugrundeliegenden
	Algorithmus in angemessener
	Zeit nachvollziehen kann, indem sie die einzelnen
	Schritte, die zur Herbeiführung einer Entscheidung nötig sind, manuell durchführt.	
	
	Beispiel: Beim manuellen
	Durchlaufen unterschiedlicher
	Pfade eines nicht allzu großen
	Entscheidungsbaumes, der auf
	nachvollziehbaren Eingangsgrö-
	ßen beruht, kann eine Person in
	jedem Knoten selbst überprüfen,
	ob eine individuelle Eigenschaft
	von Eingangsdaten bzw. ein Attribut erfüllt ist oder nicht.
	Gibt es keine Attribute mehr zu prüfen, hat die Person
	ein „Blatt“ des Entscheidungsbaums erreicht, welches
	das Ergebnis repräsentiert. \\
	
	\noindent \textbf{Erklärbarkeit: }\\
	Da Transparenz für diverse Modelle wie z. B. neuronale
	Netze nicht erreichbar ist, diese folglich nicht selbsterklärend sind, kommt bei diesen das Konzept der „Erklärbarkeit“ zur Anwendung. Dabei ist zwar in der Regel
	festgelegt, ob die Erklärbarkeit eine Entscheidung oder
	ein Modell betrifft. Wie eine konkrete Erklärung dabei
	ausgestaltet ist oder wieviel Erkenntnis sie der Zielper-
	son gewährt, bleibt dabei jedoch zunächst unbestimmt.
	Beim Beispiel der Bildverarbeitung mit neuronalen Netzen spricht man etwa bereits von einer Erklärung einer
	Entscheidung, wenn bestimmte Bereiche im Eingabebild, die zur Klassifikation eines konkreten Objektes geführt haben, für die anwendende Person farblich hervorgehoben werden. In diesem Fall wird nicht jeder einzelne
	Schritt des Algorithmus erklärt, sondern nur die für die
	Entscheidungsfindung bedeutsamsten Daten hervorgehoben. Alternativ kann eine Erklärung auch durch eine
	textliche Beschreibung repräsentiert werden.
	
	Grundsätzlich wird zwischen zwei Arten von Erklärungen unterschieden:
	
	\begin{itemize}
		\item Erklärungen von Einzelentscheidungen bzw. Ent-
		scheidungserklärungen, die dabei helfen, individuelle,
		datenbezogene Entscheidungen konkret nachzuvoll-
		ziehen (sogenannte lokale Erklärbarkeit oder Daten-
		erklärbarkeit).
		\item Erklärungen von Modellen bzw. Modellerklärungen,
		die dabei helfen, Wirkzusammenhänge von KI-Mo-
		dellen zu begreifen (sogenannte globale Erklärbarkeit
		oder Modellerklärbarkeit), z. B. lineare oder allgemein
		funktionale Zusammenhänge zwischen Eingangs-
		und Ausgangsgrößen.
	\end{itemize}
	
	In den folgenden beiden Abschnitten stellen wir einige der bekanntesten Methoden aus beiden Bereichen vor.

	\subsection{Lokale Methoden}
	
	Mithilfe sogenannter \textbf{Attributions Methoden} wird der
	negative oder positive Einfluss von Teilen oder Bereichen der Eingabe eines KI-Modells auf dessen Ausgabe	betrachtet. Dieser Gruppe können die folgenden konkreten Methoden zugeordnet
	werden: Sensitivitätsanalyse, LRP, DeepLIFT, Integrated Gradients, Grad-CAM, Guided Backpropagation und
	Deconvolution.\\
	
	
	Bei \textbf{SHAP} handelt es sich um einen Ansatz aus der Spieltheorie. Bei der Anwendung der Methode wird jedes Feature bzw. jeder Inputwert im Hinblick auf ein 
	konkretes Klassifikationsergebnis gewichtet. Diese 
	Gewichte werden auch als Shapley Values bezeichnet. Die Idee dahinter ist, dass alle möglichen Kombinationen von Features beachtet werden, um die Wichtigkeit eines einzelnen Features zu bestimmen. Jedem Ein-gabefeature wird so ein positiver oder negativer Wert 
	zugeordnet, der den Einfluss des einzelnen Features auf 
	das Ergebnis angibt. Die Methode kann genutzt werden, um Entscheidungserklärungen zu generieren. TreeSHAP 
	ist eine Variante von SHAP, die besonders effizient auf baumbasierte Modelle angewendet werden kann.\\
	
	Die Grundidee von \textbf{LIME} ist das Erlernen eines lokal approximierten, interpretierbaren Modells für ein konkretes 
	Klassifikations­ oder Regressionsergebnis. Dadurch 
	kann mithilfe eines einfacheren, oft linearen Modells ein konkretes Ergebnis nachvollzogen werden, obwohl das ursprüngliche Modell nur schwer nachvollziehbar ist. LIME „sampelt“ mehrere Ergebnisse (bzw. Entscheidungen) und gewichtet diese entsprechend ihrer Nähe zum zu erklärenden Ergebnis. Auf dieser Basis kann ein lokales Modell entwickelt werden, das mit den betrachteten Samples gut funktioniert und nachvollziehbar ist.\\
	
	Bei der Erstellung von \textbf{Surrogat-Modellen} geht es darum, auf Grundlage eines Black-Box-Modells ein zweites Modell zu erstellen, z. B. ein lineares Modell oder einen Entscheidungsbaum, das besser nachvollziehbar ist und zur Erklärung der Entscheidungen genutzt werden kann. Aufbauend auf den Ein- und Ausgaben des ursprünglichen Modells, wird die Vorhersagefunktion des Surrogat-Modells abgeleitet. So können Regeln aus trainierten 
	neuronalen Netzen extrahiert und, darauf aufbauend, nachvollziehbare Entscheidungsbäume erstellt werden, etwa mit dem Algorithmus TREPAN (Touretzky 1996). Insbesondere für Bilddaten ist die Erstellung derartiger Bäume nicht trivial.\\
	
	Weitere Bereiche für Lokale Methoden sind in \cite{kistudie} angegeben.
	

	
	\subsection{Globale Methoden}
	
	Während die bisher vorgestellten Methoden den Fokus auf die Erklärbarkeit von Einzelentscheidungen eines Modells richten, befassen sich die Methoden in diesem
	Abschnitt damit, das Modell als Ganzes zu verstehen. Diese Methoden versuchen allgemeine
	Muster aus dem Klassifizierungsverhalten des Modells zu extrahieren, indem einzelne Entscheidungen zusammengefasst und anschließend analysiert werden.[30, S. 14]\\
	In diesem Abschnitt werden die Methoden Spectral Relevance Analysis (SpRAy),
	Feature Visualization, Network Dissection und Testing with Concept Activation
	Vectors (TCAV) vorgestellt.\\
	
	\noindent \textbf{Spectral Relevance Analysis (SpRAy)} ist eine Weiterentwicklung von LRP. Mit
	dieser Methode werden zunächst Relevanzklassen für interessante Datensätze und
	Objektklassen über LRP bestimmt. Die Ergebnisse werden in Heatmaps dargestellt
	und anschließend über eine Spectralanalyse geclustert. Jedes Cluster entspricht einer
	durch das Modell erlernten Vorhersagestrategie. Auf diese Weise werden die verwen-
	deten Vorhersagestrategien für Objekte aus den erzeugten Clustern ermittelt. \cite{unmaskingCH}[S.3ff] Mit dieser Methoden lassen sich Schwachstellen in Datensätzen und Modellen erkennen. Es wird zum Beispiel erkannt, wenn eine Klassifizierung aufgrund der
	Metadaten eines Bildes vorgenommen wurde.\\
	%TODO:Samek Buch S.14
	
	\noindent \textbf{Feature Visualization} arbeitet sich ebenso schrittweise durch das Neuronale Netz,
	um zu verstehen, wie das Modell sein Verständnis über das Ausgangsbild erstellt.
	Es wird erkundet, welche Eingabedaten die Ursachen für ein bestimmtes Verhalten
	(zum Beispiel eine Neuronen Aktivierung oder die endgültige Ausgabe) verantwort-
	lich sind. Über eine Optimierungstechnik wird ein Verständnis darüber aufgebaut,
	wonach ein Modell sucht, dies können zum Beispiel Neuronen, Kanäle, Layer oder
	Klassenwahrscheinlichkeiten sein. [23]\\
	
	
	\noindent \textbf{Network Dissection} ermöglicht zu verstehen, was in den einzelnen Layern ei-
	nes vielschichtigen Convolutional Neural Networks (CNN) geschieht. Die Methode
	gleicht die Ausgabe jedes Layers mit visuellen semantischen Konzepten eines Ver-
	gleichsdatensatzes ab. Zum Vergleich wird der Broden-Datensatz eingesetzt, der
	viele Bilder und Konzepte enthält. Dieses Vorgehen ermöglicht die Zuordnung von
	Konzepten aus der realen Welt (zum Beispiel: unterschiedliche Materialien, Farben,
	Oberflächenstrukturen, Objekte, Szenen) zu jeder Schicht des CNN. Auf diese Weise
	werden die verborgenen Bereiche eines CNN interpretierbar gemacht werden und es
	können Erkenntnisse über den hierarchischen Aufbau des CNNs erlangt werden. \cite{networkdissection}[
	S. 1 und 12]\\
	\\
	Für die Detektion von Poisoning-Angriffen werden im Rahmen dieser Arbeit die Layer-wise Relevance-Propagation sowie die Spektrale Relevanz-Analyse verwendet. Deshalb gehen wir im folgenden Abschnitt näher auf die Layer-wise Relevance Propagation ein.
	
	\section{Layer-wise Relevance Propagation} \label{chapter_lrp}
	
	
	
	In diesem Abschnitt stellen wir die Layer-wise Relevance Propagation vor, die für einzelne Eingabebilder eine Heatmap (oder: Relevanzkarte) berechnet, die den Eingabebereichen verschiedene Relevanzwerte bezüglich einer Netzwerk-Entschdiung zuordnet. Im Fall eines Bildes als Eingabegröße kann die Heatmap sehr einfach visualisiert werden. Wie bereits oben erwähnt gehört dieses Verfahren zu den Lokalen Methoden.
	
	
	\subsection{Idee}
	Die \gls{lrp} wird in \cite{LRP_first_paper} erstmalig vorgestellt. Die Idee besteht darin, einen Zusammenhang zwischen der Ausgabe eines Klassifikators $f_{\theta}: \mathbb{R}^d\to \mathbb{R^{+}}$ und der Eingabe $x$ herzustellen. Dabei wird eine Funktion definiert, die über gewisse Eigenschaften eingeschränkt wird. Die Autoren bezeichnen die Herangehensweise hier selbst als heuristisch und liefern in \ref{dtd} eine Verallgemeinerung des Konzepts, die gleichzeitig die mathematische Grundlage bildet.\\
	
	Wir betrachten eine nicht-negative Funktion $f: \mathbb{R}^d \to \mathbb{R}^{+}$. Im Bereich der Bild-Klassifizierung ist die Eingabe $x \in \mathbb{R}^d$ ein Bild, das wir als Menge von Pixelwerten $x=\lbrace x_p \rbrace$ auffassen können. Dabei beschreibt der Index p einen genauen Pixelpunkt. Während für schwarz-weiß Bilder $x_p \in \mathbb{R}$ gilt, gilt im Fall von RGB-Bildern $x_p \in \mathbb{R}^3$ für die einzelnen Farbkanäle Rot, Grün und Blau. Die Funktion $f(x)$ ist ein Maß dafür, wie präsent ein oder mehrere Objekte in der Eingabe/im Eingabebild vorhanden sind. Ein Funktionswert $f(x)=0$ beschreibt die Abwesenheit. Gilt andererseits $f(x) >0$, so wird die Präsenz mit einem gewissen Grad an Sicherheit oder eine gewisse Menge zum Ausdruck gebracht.\\
	
	Mit Hilfe der \gls{lrp} soll nun jedem Pixel $p$ im Eingabebild eine Relevanz $R_p(x)$ zugeordnet werden, die für jedes Pixel $x_p$ angibt, mit welcher Größe es für das Entstehen einer Entscheidung $f(x)$ verantwortlich ist. Die Relevanz eines jeden Pixels wird dabei in einer Heatmap $R(x) = \lbrace R_p(x) \rbrace$ zusammengefasst.
	
	Die Heatmap besitzt dieselbe Größe wie $x$ und kann als Bild visualisiert werden.
	
	Wir definieren die folgenden Eigenschaften:
	
	\begin{definition}\label{def_konservativ}
		Eine Heatmap $R(x)$ heißt \emph{konservativ}, falls gilt:
		\begin{equation}
		\forall x: f(x) = \sum_p R_p(x),
		\end{equation}
		
		d.h. die Summe der im Pixelraum zugeordneten Relevanz entspricht der durch das Modell erkannten Relevanz.
	\end{definition}
	
	
	\begin{definition} \label{def_pos}
		Eine Heatmap $R(x)$ heißt \emph{positiv}, falls gilt:
		
		\begin{equation}
		\forall x,p: R_p(x) \geq 0,
		\end{equation}
		
		d.h. alle einzelnen Relevanzen einer Heatmap sind nicht-negativ.
		
	\end{definition}
	
	Die erste Eigenschaft verlangt, dass die umverteilte Gesamtrelevanz der Relevanz entspricht, mit der ein Objekt im Eingabebild durch die Funktion $f(x)$ erkannt wurde.
	
	Die zweite Eigenschaft beschreibt, dass keine zwei Pixel eine gegensätzliche Aussage über die Existenz eines Objektes treffen können. Beide Definitionen zusammen ergeben die Definition einer \textit{konsistenten} Heatmap:
	
	\begin{definition}
		Eine Heatmap $R(x)$ heißt \emph{konsistent}, falls sie konservativ und positiv ist, d.h Definition \ref{def_konservativ} und Definition \ref{def_pos} gelten.
	\end{definition}
	
	Für eine konsistente Heatmap gilt dann $(f(x) = 0 \Rightarrow R(x) = 0)$, d.h. die Abwesenheit eines Objektes hat zwangsläufig auch die Abwesenheit jeglicher Relevanz in der Eingabe zur Folge, eine Kompensation durch positive und negative Relevanzen ist folglich nicht möglich.
	
	\begin{remark}
		Die geforderten Eigenschaften an eine Heatmap definieren diese nicht eindeutig. Es sind also mehrere Abbildungen möglich, die die genannten Forderungen erfüllen. Beispiele dafür sind eine natürliche Zerlegung und Taylor-Zerlegungen \cite{dtd_paper}.
	\end{remark}
	
	Die \gls{lrp} liefert nun ein Konzept, mit dem eine Zerlegung 
	\begin{equation}
	f(x) = \sum_dR_d
	\end{equation}
	bestimmt werden kann.\\
	
	
	
	Wir gehen nun davon aus, dass die Funktion $f$ ein \gls{nn} repräsentiert, dass aus mehreren Schichten mit mehreren Neuronen pro Schicht und dazwischengeschalteten nicht-linearen Aktivierungsfunktionen aufgebaut ist.
	Die erste Schicht ist die Eingabe-Schicht, bestehend aus den Pixeln eines Bildes. Die letzte Schicht ist die reellwertige Ausgabe von $f$. Die l-te Schicht ist durch einen Vektor $z = (z_d^{l})_{d=1}^{V(l)}$ der Dimension $V(l)$ dargestellt. Sei also eine Relevanz $R_d{(l+1)}$ für jede Dimension $z_d^{(l+1)}$ des Vektors $z$ in der Schicht $l+1$ gegeben. Die Idee besteht nun darin, eine Relevanz $R_d^{(l)}$ für jede Dimension $z_d^{(l)}$ des Vektors $z$ in der Schicht $l$ zu finden, die einen Schritt näher an der Eingabeschicht liegt, sodass die folgende Abfolge von Gleichungen gilt:
	\begin{equation}
	f(x) = ... = \sum_{d\in l+1}{R_d}^{(l+1)} = \sum_{d\in l}{R_d}^{(l)} = ... = \sum_d{R_d^{(1)}}.\label{erhaltungseigenschaft}
	\end{equation}
	
	
	Für diese Funktion benötigen wir eine Regel, mit der die Relevanz eines Neurons einer höheren Schicht $R_j^{(l+1)}$ auf ein Neuron einer benachbarten, näher an der Eingabeschicht liegendes Neuron, übertragen werden kann.
	Die Übertragung der Relevanz zwischen zwei solchen Neuronen wird mit $R_{i\leftarrow j}$ bezeichnet. Auch hier muss die übertragene Relevanz erhalten bleiben. Es wird also gefordert:
	\begin{equation}
	\sum_i{R_{i\leftarrow j}^{(l,l+1)}} = R_j^{(l+1)}.
	\end{equation}
	
	D.h. die gesamte Relevanz eines Neurons der Schicht $l+1$ verteilt sich komplett auf alle Neuronen der Schicht $l$, es geht weder Relevanz verloren noch entsteht mehr Relevanz als zuvor vorhanden war.
	Im Falle eines linearen Neuronalen Netzwerkes $f(x) = \sum_i{z_{ij}}$ mit der Relevanz $R_j = f(x)$ ist eine Zerlegung gegeben durch $R_{i\leftarrow j} = z_{ij}.$
	Im allgemeineren Fall ist die Neuronenaktivierung $x_j$ eine nicht-lineare Funktion abhängig von $z_j$.\\
	Für die beiden Aktivierungsfunktionen $tanh(x)$ und $ReLU(x)$ - beide monoton wachsend mit $g(0)=0$ - bieten die Vor-Aktivierungen noch immer ein sinnvolles Maß für den relativen Beitrag eines Neurons $x_i$ zu $R_j$.
	
	Eine erste Mögliche Relevanz-Zerlegung, basierend auf dem Verhältnis zwischen lokalen und globalen Vor-Aktivierung, ist gegeben durch:
	
	\begin{equation}
	R_{i\leftarrow j}^{(l,l+1)} = \frac{z_{ij}}{z_j} \cdot R_j^{(l+1)}. \label{eq:lrp_regel}
	\end{equation}
	\begin{comment}
	
	Für diese Relevanzen $R_{i \leftarrow j}$ gilt die Erhaltungseigenschaft \ref{erhaltungseigenschaft}, denn:
	
	\begin{equation}
	\sum_i{R_{i \leftarrow j}}^{(l,l+1)} = R_{j}^{l+1} \cdot (1-\frac{b_j}{z_j}).
	\end{equation}
	
	Dabei steht der rechte Faktor für die Relevanz, die durch den Bias-Term absorbiert wird.
	Falls notwendig, kann die verbleibende Bias-relevanz auf jedes Neuron $x_i$ verteilt werden(?,s.Abschnitt über Biases Promotion, S.Lapuschkin).
		content...
	\end{comment}
	Diese Regel wird in der Liteartur als \textbf{LRP-0} bezeichnet.
	
	Ein Nachteil dieser ist, dass die Relevanzen $R_{i \leftarrow}$ für kleine globalen Voraktivierung $z_j$ beliebig große Werte annehmen können.
	
	Um dies zu verhindern, wird in der \textbf{LRP-$\varepsilon$}-Regel ein vorher festgelegter Parameter $\varepsilon > 0$ eingeführt:
	
	\begin{equation}
	R_{i\leftarrow j}^{(l,l+1)} = \begin{cases}
	\frac{z_{ij}}{z_j +\varepsilon} \cdot R_j^{(l+1)}, \; z_j \geq 0\\
	\frac{z_{ij}}{z_j -\varepsilon}\cdot R_j^{(l+1)}, \; z_j < 0\\
	\end{cases}
	\end{equation}
	bzw.
	
	\begin{equation}
	R_{i\leftarrow j}^{(l,l+1)} = 
	\frac{z_{ij}}{z_j + sign(\varepsilon)} \cdot R_j^{(l+1)}
	\end{equation}
	
	Es gilt $z_{ij} = x_i^{(l)}w_{ij}^{l,l+1}$. und $z_j = \sum_i{z_{ij}}$.
	
	Eine weitere Regel, um die Relevanzen einer Schicht auf die vorherige zu übertragen, ist die $\beta$- oder $\alpha/\beta$-Regel mit:
	
	Dabei werden die positiven und negativen Anteile der Aktivierungen unterschiedlich stark gewichtetet:
	
	\begin{equation}
		R_{i\leftarrow j}^{(l,l+1)} = \sum_j{\left( \alpha \cdot \frac{z_{ij}^+}{z_j^+} + \beta \cdot \frac{z_{ij}^-}{z_j^-}\right)R_j^{(l+1)}},
	\end{equation}
	wobei $z_{ij}^+, z_j^+ = \sum_i{z_{ij}^+}, z_{ij}^-, z_j^- = \sum_i{z_{ij}^-}$ die Positiv- bzw- Negativteile sind, d.h. es gilt $z_{ij}^+ z_{ij}^- = z_{ij}$. Es wird $\alpha + \beta = 1, \alpha > 0, \beta \leq 0$ gefordert, um eine konservative Relevanz-Übertragung ziwschen zwei Netzwerkschichten zu erhalten. Aufgrund dieser Forderung lässt sich der Parameter $\alpha$ schreiben als $\alpha = 1- \beta$ und wir sprechen von der $\beta$-Regel.  
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=0.3\textheight]{LRP_scheme.png}
		\caption[LRP-Schema]{Forward- und LRP-Backward-pass}
		\source{\cite{Lapuschkin2019OpeningTM}}
		\label{im:lrp_schema}
	\end{figure}
	
	\textbf{Gamma-Regel (LRP-$\gamma$)}. Bei dieser Regel werden positive Gewichte ziwschen den Netzwerkschichte höher bewertet. Zusätzlich zum Positivteil in $z_{ij}$ wird ein mit $\gamma$ gewichtetes Vielfaches des Positivteils addiert. Es ergibt sich:
	
	\begin{equation}
		R_{i\leftarrow j}^{(l,l+1)} = \sum_j{\frac{x_j \cdot (w_{ij}+ \gamma w_{ij}^+)}{\sum_j{x_i \cdot (w_{ij} + \gamma w_{ij}^+)}}R_j^{(l+1)}}
	\end{equation}
	
	Durch die Wahl von $\gamma$ lassen sich hier die positven Anteile steuern. Für größere Werte $\gamma$ verschwinden die negativen Anteile. Mit dieser Formulierung bleiben die positiven und negativen Anteile der Relevanz beschränkt und es ergeben sich robustere Ergebnisse. Dieser asymmetrisch gewichtete Ansatz ist verwandt mit der LRP-$\alpha\beta$-Regel. Für $\gamma \to \infty$ erhalten wir die LRP-$\alpha \beta-Regel$ mit $\alpha=1,\beta=0$.
	In \cite{LRP_first_paper} wird die Layer-wise Relevance Propagation erstmalig vorgestellt. Zudem wird eine Taylor Zerlegung präsentiert, die eine Approximation der LRP darstellt. 
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=0.3\textheight]{composite_lrp.png}
		\caption[Composite-LRP]{Composite-LRP, $\varepsilon=0.25std, \gamma=0.25$}
		\source{\cite{samek2019explainable}}
		\label{im:composite_lrp}
	\end{figure}
	
	
	Hier\footnote{https://towardsdatascience.com/indepth-layer-wise-relevance-propagation-340f95deb1ea} werden einige Bereiche vorgestellt, in denen LRP angewendet wurde.
	\begin{comment}
	
	
	The overall idea of pixel-wise decomposition is to understand the contribution of a single pixel
	of an image x to the prediction f(x) made by a classifier f in an image classification task. We
	would like to find out, separately for each image x, which pixels contribute to what extent to a
	positive or negative classification result. Furthermore we want to express this extent quantita-
	tively by a measure. We assume that the classifier has real-valued outputs which are thre-
	sholded at zero. In such a setup it is a mapping f : R V ! R 1 such that f(x) > 0 denotes presence
	of the learned structure. Probabilistic outputs can be treated without loss of generality by sub-
	tracting 0.5. We are interested to find out the contribution of each input pixel x (d) of an input
	image x to a particular prediction f(x). The important constraint specific to classification con-
	sists in finding the differential contribution relative to the state of maximal uncertainty with
	respect to classification which is then represented by the set of root points f(x 0 ) = 0. One possi-
	ble way is to decompose the prediction f(x) as a sum of terms of the separate input dimensions
	
	x d respectively pixels:
	f 
	V
	X
	R d
	ð1Þ
	d1⁄41
	The qualitative interpretation is that R d < 0 contributes evidence against the presence of a
	structure which is to be classified while R d > 0 contributes evidence for its presence. In terms
	of subsequent visualization, which however will not be the scope of this paper, the resulting rel-
	evances R d for each input pixel x (d) can be mapped to a color space and visualized in that way
	as a conventional heatmap. One basic constraint will be in the following work that the signs of
	R d should follow above qualitative interpretation, i.e. positive values should denote positive
	contributi
	
	feedforward-Netzwerke
	Feedforward neural networks constitute a popular architec-ture type, ranging from simple multi-layer perceptrons andshallower convolutional architectures such as the LeNet-5[21]to deeper and more complex Inception [22] and VGG-likearchitectures [23]. These types of neural network commonlyuse ReLU non-linearities and first pass information throughastack of convolution and pooling layers, followed by severalfully connected layers. The good performance of feedforwardarchitectures in numerous problem domains, and the avail-ability as pre-trained models makes them a valuable standardarchitecture in neural network design.
	content...
	\end{comment}
	
	
	\begin{algorithm}
		\hspace*{\algorithmicindent} \textbf{Input: } $R^{(L)} = f(x)$, model parameters \newline
		\hspace*{\algorithmicindent} \textbf{Output: } $\forall i,l: R_i^{(l)}$. 
		
		\caption{Layer-wise Relevance Propagation}
		\label{alg:lrp}
		
		\begin{algorithmic}
			\FOR{$l\in \lbrace L-1, ..., 1 \rbrace $}
				\STATE{$\forall i,j: R_{i\leftarrow j }^{(l,l+1)} = \frac{z_{ij}}{z_j}\cdot R_j^{(l+1)}$}
				\STATE{$\forall i: R_i^{(l)} \hphantom{=}= \sum_j{R_{i \leftarrow j}^{l,l+1}}$}			
			\ENDFOR
		\end{algorithmic}
	\end{algorithm}	

	

	
	
	
	\subsection{LRP für Tiefe Neuronale Netzwerke}
	In diesem Abschnitt gehen wir darauf ein, wie wir die oben vorgestellten LRP-Regeln auf ein Tiefes Neuronales Netzwerk und damit die einzelnen unterschiedlichen Schichten dieses Netzwerkes anwenden können.
	
	Wir bezeichnen mit $\sum_i$ die Sumamtion über alle Neuronen einer bestimmten Schicht und mit $\sum_j$ die Sumamtion über die Neuronen einer anderen Schicht. 
	
	Um innerhalb eines Netzwerkes Information von einer auf die darauffolgende Schicht abzubilden, werden häufig lineare Projektionen
	
	\begin{align}
		z_{ij} &= x_iw_{ij}\\
		x_j &= \sum_i{z_{ij} + b_j} \label{eq:linear_projection}
	\end{align}
	 oder komponenten-weise Aktivierungsfunktionen
	 \begin{equation}
	 	x_j = \sigma(x_i)
	 \end{equation}
	 verwendet.
	 Der erste Fall beschreibt die häufig verwendeten vollständig verknüpften Netzwerk-Schichten, während der zweite Fall die Verwendung nicht-linearer Aktivierungsfunktionen oder Normalisierungsoperationen darstellt.
	 
	 Tiefe Neuronale Netzwerke führen nun eine Vielzahl solcher Schichten hintereinander aus.
	 
	 Eine häufig verwendete Aktivierungsfunktion ist die sogenannte ReLU-Aktivierungsfunktion  $\sigma(x) = \max{(0,x)}$, wobei die Abkürzung ReLU für rectified linear unit steht.
	 Diese wird in einer Vielzahl von Netzwerkarchitekturen verwendet.
	 
	 Im Folgenden beschreiben wir, wie die LRP-Regel \autoref{eq:lrp_regel} für die einzelnen Schichten, die in unserem Inception-Netzwerk auftreten, umgesetzt werden kann.\\
	 
	 \noindent\textbf{Lineare Schichten:}\\
	 Netzwerk-Schichten, die lineare Transformationen über einen Gewichtskernel implementieren, d.h. vollständig verknüpfte Schichten und alle Varianten von Convoultional-Schichten, implementieren die Funktion in \autoref{eq:linear_projection}.
	 
	 Seien mit i die Eingabe- und mit j die Ausgabe-Neuronen bezeichnet. Sei eine Relevanz $R_j^{(l+1)}$ gegeben. Eine Relevanz-Zerlegung erhalten wir nun durch die Wahl von $z_{ij}=x_iw_{ij}$ wie in \autoref{eq:linear_projection} und $z_j = x_i$, d.h. die Aktivierungen der Schicht l+1. Damit erhalten wir die rückwärts-gerichtete Relevanz-Nachricht 
	 \begin{equation}
	 	R_{i\leftarrow j}^{(l,l+1)} = \frac{x_iw_{ij}}{\sum_i{x_iw_{ij}+b_j}}\cdot R_j^{(l+1)} = \frac{z_{ij}}{z_j}\cdot R_j^{(l+1)},
	 \end{equation}
	wobei der Bias $b$ als konstant aktivierendes Neuron, das über die Gewichte $b_j$ mit den Ausgabe-Aktivierungen $x_j$ verbunden ist, interpretiert wird.
	Durch diese Interpretation des Bias als eigenes Neuron, geht in jedem Rückwärtsschritt etwas Relevanz verloren. Eine Möglichkeit, dies zu beheben, wird in \cite{lapuschkin}[Kapitel 2.2.4] diskutiert.\\
	
	
	
	\noindent\textbf{Pooling-Schichten}\\
	Zu den Poling-Schichten gehören das Sum-, Average-. und Max Pooling. Für alle drei lässts ich auch hier eine entsprechende LRP-Regel direkt anwenden.
	Sowohl das Sum- als auch das Average Pooling lassen sich als Convolutional-Schicht verallgemeinern. Dafür wird $w_{ij}=1$ für das Sum-Pooling und $w_{ij}=1/n$ für das Average Pooling gewählt.
	
	In unserer Version des Inception-Netzwerkes verwenden wir das Max Pooling. Dieses implementiert die Funktion
	\begin{equation}
		x_j = \max_i{(x_i)}
	\end{equation}
	für jedes Ausgabe-Neuron $j$ über alle Eingabe-Neuronen $i$. Für den LRP-Backward-pass muss die Relevanz nun an das maximal aktivierende Eingabe-Neuron übertragen werden, d.h.:
	\begin{equation}
	R_{i \leftarrow j}^{(l,l+1)} = \begin{cases}
	R_j^{(l+1)} & \text{falls  }\argmax_i{(x_i)}\\
	0			& \text{sonst.}
	\end{cases}
	\end{equation}
	Die Vorschrift für den Fall, dass mehrere Neuronen dasselbe Maximum annehmen, lässt sich leicht einschließen.\\
	
	
	\noindent\textbf{Aktivierungsschichten}\\
	Für die komponenten-weise angewandten Aktivierungsfunktionen werden keine Eingabe-Aktivierungen untereinander kombiniert. Es ergibt sich für die Relevanz-Nachricht
	
	\begin{equation}
		R_{i\leftarrow j}^{(l,l+1)} = \begin{cases}
		R_j^{(l+1)} & \text{falls  } i=j\\
		0 &\text{sonst,}
		\end{cases}
	\end{equation} d.h. die eigehende Relevanz wird unverändert als Ausgabe weitergegeben.\\
	
	
	
	\noindent\textbf{Merge-Schichten}\\
	In \autoref{chapter:inception} hatten wir den Aufbau von Inception-Netzwerken und auch den verwendeten Inception-Modulen besprochen. Hierbei treten sogenannte Merge-Schichten auf, bei denen Information von verschiedenen Netzwerk-Schichten zusammengeführt werden.
	
	In \cite{sebastianlapuschkin} wird dabei zwischen \textit{Merge by aggregation} und \textit{Merge by concatenation} unetrschieden. Dabei beschreibt ersteres die Zusammenführung verschiedener Netzwerk-Aktivierungen durch Addition oder Subtraktion. Diese Netzwerk-Schicht implementiert die Funktion
	\begin{equation}
		x_j = x_{1,j} + x_{2,j} + ... + x_{n,j},
	\end{equation}
	wobei die Eingabe-Tensoren $x_1, ..., x_n$ dieselbe Dimension besitzen und komponenten-weise am Index $j$ zusammengeführt werden sollten. Analog zu den komponenten-weise Aktivierungsfunktionen tritt hier keine Vermischung an Information auf und die Relevanz-Zerlegung kann analog zum linearen Fall mit 
	\begin{align}
		z_{ij} &= x_{ij}\\
		x_j &= \sum_i{z_{ij}}
	\end{align} umgesetzt werden. Folglich kann \autoref{eq:lrp_regel} ohne Abänderung un dmit der Wahl $x_j= z_j$ verwendet werden. Der für uns ebenfalls interesannte zweite Fall beschreibt die Konkatenierung am Ende eines Inception-Moduls. Auch hier entsteht aufgrund der Konkatenierung entlang einer Tensor-Achse keine Interaktion zwischen den einzelnen Netzwerk-Schichten. Zum forward-pass
	\begin{equation}
		x_j = [x_{1,j}, x_{2,j}, ... , x_{n,j}],
	\end{equation}
	wobei $j$ die Tensor-Achse orthogonal zur Konkatenierungs-Achse bezeichnet, ergibt sich die einfache Relevanz-Zerlegung
	
	\begin{equation}
		[R_{1,j}^{(l)}, R_{2,j}^{(l)}, ..., R_{n,j}^{(l)}] = R_j^{(l+1)}.
	\end{equation}
	
	\noindent\textbf{Normalisierungsschichten}\\
	Häufig werden Netzwerk-Schichten benutzt, die eine Normalsierung während des Trainings durchführen. Bei der sogenannten Batch-Normalisierung wird eine Normalisierung über dem Mini-Batch an ausgewählten Trainingsdaten durchgeführt. Durch die Verwendung der Batch-Normalisierung wird die Konvergenz und damit die Trainingszeit des Netzwerkes verbessert.
	
	Die Batch-Normalisierung führt eine komponenten-weise definierte Funktion 
	\begin{equation}
		z = \frac{x -\mu_\mathcal{B}}{\sqrt{\sigma_\mathcal{B}^2 + \epsilon}}\gamma + \beta
	\end{equation}
	aus. Dabei sind $\gamma$ und $\beta$ zwei Parameter, die die Datenpunkte skalieren und verschieben und während des Trainings gelernt werden. $\mu_\mathcal{B}$ und $\sigma_\mathcal{B}^2$ sind Mittelwert und Varianz des aktuellen Mini-Batches. Nach dem abgeschlossenen Training werden $\mu_\mathcal{B}$ und $\sigma_\mathcal{B}^2$, fixiert, indem sie über den gesamten Datensatz berechnet werden. Die Skalierungsoperation können wir schreiben als $s=\gamma \cdot (\sigma_\mathcal{B}^2 + \epsilon)^{\frac{1}{2}}$ Für die Batch-Normalisierung während der Inferenz ergibt sich dann die Abfolge von (komponenten-weise) Additionen und Multiplikationen:
	\begin{align}
		x' &= x- \mu_\mathcal{B},\\ \label{eq:translation1}
		x'' &= x' \cdot s\\
		z &= x'' + \beta \\ \label{eq:translation2}
	\end{align}
	Betrachten wir die Translationen (\autoref{eq:translation1, eq:translation2}) als additive Merge-Operationen lässt sich die Relevanz-Übertragung analog zum Merge- und Aktivierungs-Abschnitt formulieren als:
	
	\begin{equation}
		R^{(l)} = \frac{x \odot s \odot R^{(l+1)}}{z}
	\end{equation}
	
	Damit haben wir LRP-Regeln für alle Netzwerkschichten im Inception-Netzwerk besprochen, sodass wir durch das Hintereinanderausführen der LRP-Regeln zu einer Netzwerkeingabe eine Heatmap erhalten.
	
	
	\subsection{Implementierungen}
	Es existieren mehrere LRP-Implementierungen sowohl für pytorch als auch TensorFlow. Da wir mit pytorch-Netzwerken arbeiten, haben wir uns für ein Version von moboehle\footnote{\url{https://github.com/moboehle/Pytorch-LRP}} entschieden. Diese entstand im Rahmen der Forschungsarbeit \cite{lrp_alzheimer}, in der eine Alzheimer-Festellung aufgrund von Bilddaten vorgenommen wird. Dabei werden sogenannte pytorch hooks verwendet, um auf einzelne Netzwerkschichten zuzugreifen. Der Programmcode überzeugt dadurch, dass einzlne Arten von Netzwerkschichten leicht ergänzt werden können. Eine modifizierte Version ermöglicht es uns, die Implementierung auch für das Inception-Netzwerk zu benutzen. Dabei haben  wir die LRP-Regeln für die Inception-Module sowie die Batch-Normalisierungsschichten implementiert.
	
	Weitere Implementierungen sind beispielsweise das LRP-Tutorial in pytorch für VGG16\footnote{\url{https://git.tu-berlin.de/gmontavon/lrp-tutorial}}, eine Implementierung in pytorch von GiorgioML\footnote{\url{https://giorgiomorales.github.io/Layer-wise-Relevance-Propagation-in-Pytorch/}} als Alternative zur ursprünglichen Tensorflow-Implementierung im ersten LRP-Paper, fhvilshoj\footnote{\url{https://github.com/fhvilshoj/TorchLRP}} oder Zennit\footnote{\url{https://github.com/chr5tphr/zennit}}.
	
	 



\subsection{Verarbeitung der Heatmaps}

Die LRP-Ausgabe zu einer Bildeingabe der Größe $[32 \times 32 \times 3]$, wobei 3 für einzelnen Farbkanäle steht wird bezüglich einer bestimmten Klasse generiert. Es sind sowohl positive als auch negative Relevanz-Werte möglich. Dabei deutet ein positiver Wert darauf hin, dass dieser Bereich entscheidend für die Einordnung in diese Klasse ist. Wir addieren die Relevanzen auf allen 3 Farbkanälen und normalisieren das Ergebnis anschließend auf das Intervall $[0,1]$. Die so modifizierte LRP-Ausgabe zu einem originalen korrumpierten Bild ist in \autoref{vergleich_original_lrp} abgebildet. Dabei wird die default colormap Option D (Viridis)\footnote{\url{https://bids.github.io/colormap/}} verwendet.


\begin{figure}
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.4\linewidth]{1450_poison}
		%\caption{Verkehrsschild der Klasse 'Höchstgeschwindigkeit: 50km/h' versehen mit einem 3x3 Sticker und dem Label 'Höchstgeschwindigkeit: 80km/h'}
		
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{1450_poison_lrp.png}
		%\caption{Zugehörige Heatmap bezüglich der Klasse 'Höchstgeschwindigkeit: 80km/h'}
		
	\end{subfigure}
	\caption[(Optischer) Vergleich von korrumpiertem Datenpunkt und berechnter Heatmap.]{(Optischer) Vergleich von korrumpiertem Datenpunkt und berechnter Heatmap. Links: Verkehrsschild der Klasse 'Höchstgeschwindigkeit: 50km/h' versehen mit einem 3x3 Sticker und dem Label 'Höchstgeschwindigkeit: 80km/h'. Rechts: Zugehörige Heatmap bezüglich der Klasse 'Höchstgeschwindigkeit: 80km/h'.}
	\source{\cite{AC}}
	
	\label{vergleich_original_lrp}
\end{figure}

\section{Heatmap Clustering} 
In diesem Kapitel stellen wir das Heatmap Clustering vor, mit dem wir die Präsenz von Poisoning-Angriffen detektieren und die korrumpierten Datenpunkte anschließend aus dem Datensatz entfernen können.

Die Idee besteht darin, ein kMeans-Clustering auf einer Klasse durchzuführen, die in dem Sinne für verdächtig gehalten wird, dass innerhalb dieser Klasse Datenpunkte eingefügt wurden, die nicht zum ursprünglichen Datensatz gehören und eine Hintertür im Netzwerk implementieren sollen.

Wichtig für das Clustering sind hierbei die Repräsentation der Daten, auf denen geclustert wird, sowie die Metriken, die eine Distanz und damit auch einen Mittelwertbegriff für mehrere Datenpunkte definieren.

Als Repräsentation benutzen wir die Heatmaps, die mit der LRP, wie in \autoref{chapter_lrp} beschrieben, erzeugt werden.

Dieses Verfahren besteht also darin, eine Spektrale Relevanz Analyse durchzuführen \cite{unmaskingCH}, die aus einem Spektralen Clustering auf Heatmaps durchgeführt wird, die mit der LRP berechnet wurden.
	\subsection{kMeans-Clustering}
	Das k-means-Clustering gehört zu den unüberwachten Clustering-Verfahren. In der ursprünglichen Formulierung sind $n$ Datenpunkte $x_1,...,x_n \in \mathbb{R}^d$ und $k \in \mathbb{Z}_{>0}$ gegeben. Die Datenpunkte sollen so auf, die einzelnen Cluster verteilt werden, dass die Distanzen innerhalb eines Clusters zum Cluster-Zentrum minimal sind. 
	
	Für das kMeans-Clustering müssen wir im Vorfeld eine Clusteranzahl k fixieren und die Mittelpunkte der k Cluster initialisieren.
	
	In Lloyd's Formulierung \cite{lloyd1982least} wird mit einer gleich-verteilten zufälligen Initialisierung von $k$ Cluster-Zentren begonnen. Jeder Punkt im Datensatz wird anschließend dem nächstgelegenen Cluster-Zentrum zugeordnet. Für jedes Cluster wird anschließend ein neues Zentrum als Mittelwert berechnet.
	Diese beiden Schritte aus Zuordnung und Mittelpunktberechnung werden so lange wiederholt, bis sich die Cluster-Zentren nicht mehr ändern oder eine maximale Iterationszahl erreicht ist. Dieses Vorgehen wird als $k$-Means bezeichnet.
	
	Eine Variation des k-Means-Algorithmus, der sowohl die Laufzeit als auch die Genauigkeit verbessert, ist der sogenannte $kmeans++$-Algorithmus \cite{kmeans++}. Dabei wird die Initalisierung in abgewandelter Form durchgeführt. Nach gleich-verteilter, zufälliger Bestimmung des ersten Cluster-Zentrums, werden die übrigen $k-1$ Zentren wie folgt gewählt:
	Die Wahl erfolgt proportional zur maximalen quadratischen Distanz zu allen vorher bestimmten Cluster-Zentren. Damit sind die Zentren so über den Datensatz verteilt, dass sie maximal weit auseinander liegen.
	
	Anschließend werden die im kMeans-Algorithmus üblichen Schritte aus Distanzberechnung und Mittelwert-Berechnung wiederholt.
	
	Dieses $kMeans++$-CLustering ist nochmals in Algorithmus \autoref{alg:kmeans} dargestellt.
	
	\begin{algorithm}
		\hspace*{\algorithmicindent} \textbf{Input: } Data points $\mathcal{X} = \lbrace x_1,...,x_n \rbrace$, Number of Clusters $k$.		\newline
		\hspace*{\algorithmicindent} \textbf{Output: } $k$ Clusters. 
		
		\caption{kMeans-Algorithmus}
		\label{alg:kmeans}
		
		\begin{algorithmic}
			
			\STATE{Choose an initial center $c_1$ uniformly at random from $\mathcal{X}$.}
			\REPEAT
			\STATE{Choose the next center $c_i$, selecting $c_i = x' \in \mathcal{X}$ with probability $\frac{D(x')^2}{\sum_{x\in\mathcal{X}}{D(x)^2}}$.}
			
			\UNTIL{we have choosen a total of k centers}
		\end{algorithmic}
	\end{algorithm}	
	
	Die Initialisierung für den kMeans++-Algorithmus ist in \autoref{alg:kmeans++_init} notiert.
	
	
	
	\begin{algorithm}[h]
		\hspace*{\algorithmicindent} \textbf{Input: } Data points $\mathcal{X} = \lbrace x_1,...,x_n \rbrace$, Number of Clusters $k$, distance function $d$, where $D(x)$ is the minimal distance $d(x,c)$, where $c$ are the already choosen cluster centers.		\newline
		\hspace*{\algorithmicindent} \textbf{Output: } $k$ Cluster centers $\mathcal{C}=\lbrace c_1,...,c_k\rbrace$. 
		
		\caption{kMeans++-Initalisierung}
		\label{alg:kmeans++_init}
		
		\begin{algorithmic}
			\STATE{Arbitrarily choose $k$ initial centers $\mathcal{C}={c_1,...,c_k}$}
			\REPEAT
			\STATE{For each $i \in \lbrace 1,...,k \rbrace$, set the cluster $C_i$ to be the set of points in $\mathcal{X}$ that are closer to $c_i$ than they are to $c_j$ for all $j\neq i$.}
			\STATE{For each $i \in \lbrace 1,...,k \rbrace$, set $c_i$ to be the centere of mass of all points in $C_i: c_i = \frac{1}{|C_i|}\sum_{x \in C_i}{x}$.}
			\UNTIL{convergence}
		\end{algorithmic}
		
		
	\end{algorithm}
	
	Es bleibt also die Bestimmung des Wertes $k$.
	Dafür benutzen wir die eine Spektralzerlegung, die wir im nächsten Abschnittt vorstellen.
	
	
	\subsection{Spektrales Clustering/Spektrale Zerlegung}
	Wir folgen \cite{spectralClustering_tut} und \cite{unmaskingCH}.
	
	Wir gehen wieder davon aus, dass uns ein metrischer Raum $(X,d)$ gegeben ist, wobei $X = \lbrace x_i, ..., x_n \rbrace$ gilt.
	
	In \cite{spectralClustering_tut} wird dier metrische Raum als Graph $G=(V,E)$ interpretiert. Damit wird aus dem Clustering-Problem ein äquivalentes Partitionierungsproblem in $k$ Partitionen:
	\begin{center}
		\textit{Finde eine Partitionierung des Graphen $G$, sodass die Kantengewichte \\innerhalb eines Clusters minimal sind.}
	\end{center}
	Um aus dem metrischen Raum $(X,d)$ einen Graphen zu erhalten, müssen zwischen den Knoten des Graphen Kanten definiert werden. Dafür existieren die folgenden drei Möglichkeiten:
	
	\begin{itemize}
		\item $\varepsilon$-Nachbarschaft-Graph: Hier wird eine Kanten zwischen zwei Knoten $u$ und $v$ gesetzt, falls $d(u,v) \leq \varepsilon$ für $\varepsilon > 0$ gilt.\\
		\item kNN-Graph: Hier wird eine Kanten zwischen zwei Knoten $u$ und $v$ gesetzt, falls $v$ zu $k$ vielen Knoten gehört, die am nächsten an $u$ liegen.\\
		\item Vollständiger Graph: Hier wird eine Kanten zwischen allen Knoten im Graphen gesetzt.
	\end{itemize}
	
	Analog zu \cite{unmaskingCH} entscheiden wir uns für einen $kNN$-Graphen mit $k=10$. Damit lasst sich die sogenannte Adjazenzmatrix $A = (a_{ij})_{ij}$ eines Graphen $G$ definieren mit
	\begin{equation}
	a_{ij} = \begin{cases}
	1, \text{ falls  } u \text{ und } v \text{ verbunden sind,}\\
	0, \text{ sonst.}
	\end{cases}
	\end{equation}
	
	
	
	Ausgehend davon lässt sich die zu einem Graphen G gehörige Laplace-Matrix definieren:
	
	\begin{definition}[Laplace-Matrix]
		Sei $G=(V,E)$ ein Graph mit Adjazenzmatrix $A$. Sei $D = (d_{ij})_{ij}$ eine Diagonalmatrix mit $d_{i} = \sum_{j=1}^n{a_{ij}}$. Sei $L=D-A$ die \emph{nicht normalisierte Laplace Matrix}. Dann lässt sich die symmetrische und normalisierte Laplace-Matrix $L_{sym}$ definieren als
		\begin{equation}
		L_{sym} = D^{-1/2}LD^{-1/2}.
		\end{equation}
	\end{definition}
	
	
	Wir zitieren das folgende Resultat:
	
	\begin{theorem}[Anzahl an zushg. Komponenten und Spektum von $L_{sym}$ \cite{spectralClustering_tut}]
		Sei $G$ ein ungerichteter Graph mit nicht-negativen Gewichten. Dann gibt die Vielfachheit der Eigenwerte $0$ von $L_{sym}$ die Anzahl an zusammenhängenden Komponenten $A_1,..., A_k$ an.
	\end{theorem}
	
	Damit können wir also die Clusteranzahl $k$ durch eine spektrale Zerlegung bestimmen und anschließend das Clustering durchführen.
	
	
	
	
	
	
	
	
	
	
	
	\subsection{Verwendete Distanzen \& Approximationen}
	Bisher sind wir nicht nähers auf die Distanz zwischen zwei Relevanzkarten/Heatmaps eingegangen. Um die Struktur innerhalb einer Klasse zu analysieren, benötigen wir jedoch eine Metrik.
	
	Die naheliegenste Möglichkeit von einer Distanz zwischen zwei Relevanzkarten zu sprechen, ist vermutlich eine $L^p$-Distanz, bei der die Pixelwerte die einzelnen Komponenten darstellen. 
	
	Eine andere Idee ist die Verwednung eines Distanzbegriffs, der im Unterschied zur $L^p$-Distanz auch rotations- und translations-invariant ist. Die Vermutung ist hier, dass wir dadurch einen Distanzbegriff erhalten, der eher mit der menschlichen Wahrnehmung übereinstimmt.
	
	Im Folgenden Abschnitt werden wir die sogenannte p-Wasserstein-Distanz herleiten, bei der die einzelnen Relevanzkarten als sogenannte metrische Maßräume betrachtet werden. Dabei besitzt jeder Punkt eines Raumes zusätzlich zum Abstand zu allen anderen Punkten ein Maß. Dieses Maß ist in unserem Fall die durch die LRP berechnete Relevanz.  
	
	Wie in \cite{imagenet_unhansed_v1} summieren wir über die Farbkanäle, um einen einzelnen Relevanzwert pro Pixelpunkt zu erhalten. Wir benötigen also eine Metrik zur Berechnung der Distanz zwischen 32x32 großen Heatmaps.\\
	Wir normalisieren die Relevanzen zusätzlich auf das Intervall $[0,1]$.\\
	Die Wahl der Pixel mit 99 Prozent der Gesamtmasse und anschließende Normalisierung wird vermutlich durchgeführt, um die Bedingung \autoref{eq:bed_mmspaces} zu erhalten und auch deshalb oder eher nur um zwei verschiedene metrsiche Maßräume zu erhalten, d.h. für zwei MMR $X_1=(X_1,d_1,\mu_1)$ und $X_2=(X_2,d_2,\mu_2)$ gilt $(X_1,d_1) \neq (X_2,d_2)$. Erhalten wir dadurch die Translationsinvarianz?\\
	%TODO: Das sollte vermultich eher an das Ende von OPTIMAL Transport
	
	
	\begin{remark}
		Um von einer verdächtigen Klasse in einem Datensatz sprechen zu können, muss auch diese erst einmal identifiziert werden.
		In \cite{imagenet_unhansed_v1} Kapitel '2.3. Fisher Discriminant Analysis for Clever Hans
		identification' wird ein Verfahren vorgestellt, mit dem verdächtige Klassen indentifiziert werden können. Für diese würde man anschließend das Heatmap-Clustering durchführen. Wir gehen im Folgenden davona aus, dass wir die verdächtige Klasse bereits festgelegt haben.
		%TODO: Sollte ich diese Bemerkung lieber in das Kapitel Poisoning-Angriffe:Verteidigungen packen?
	\end{remark}
	
	In diesem Abschnitt haben wir die einzelnen Schritte ausgeführt, die für die Detektion von Poisoning-Angriffen basierend auf den durch die LRP erzeugten Heatmaps nötig sind.
	
	Diese lassen sich wie folgt zusammenfassen:	
	\begin{itemize}
		\item Berechnung der Heatmaps mithilfe der LRP\\
		\item Berechnung einer Distanzmatrix \\
		\item Spektrale Zerlegung
		\\ (Bestimmung der verschiedenen Cluster innerhalb einer Klasse)\\
		\item kMeans-Clustering zur Bestimmung der korrumpierten Datenpunkte\\
	\end{itemize}
	
	\section{Theorie des Optimalen Transports}
	\begin{comment}
	
	Optimal Transport is an interesting topic which connects many fields and has
	interesting applications
	Applications in image analysis
	Interplay between geometry, probability and PDEs
	Convexity, duality
	Numerical optimization
	Statistics and Machine Learning\footnote{\url{https://indico.cern.ch/event/845380/attachments/1915103/3241592/Dvurechensky_lectures.pdf}}
	
	Optimal transport can deal with smooth and discrete measures and it has proved to be very useful
	for comparing distributions in a shared space, but with different (and even non-overlapping) supports\cite{vayer2020fused}.
	Einführung OT Villani%\footnote{\url{https://books.google.de/books?hl=en&lr=&id=idyFAwAAQBAJ&oi=fnd&pg=PR11&dq=villani+2003&ots=YRvDCQXIIn&sig=XqyOf4Qqsw-otlBm0_4L3YoU6pA&redir_esc=y#v=onepage&q=villani\%202003&f=false}}
	OT hebt Distanzen von metrischen Räumen auf den Raum der metrischen Räume \cite{memoli2011gromov}.
		content...
	\end{comment}
	In diesem Kapitel betrachten wir einige Konzepte aus dem Bereich Optimal Transport, um einen Distanzbegriff zu entwickeln, der im Unterschied zur pixel-weisen euklidischen Distanz besser für das kMeans-Clustering geeignet sein könnte.
	Ausgehend von Gaspard Monge's ursprünglicher Transportproblme-Formulierung betrachten wir die durch Kantorobich eingeführte Relaxierung dieses Problems.
	Die Optimale Lösung wird für die Definition der p-Wasserstein-Distanz verwendet.
	Für eine Verallgemeinerung auf verschiedene Grundräume wird die Gromov-Wasserstein-Distanz definiert. Damit können wir zwei Heatmaps als sogenannte metrische Maßräume auffassen.
	Abschließend definieren wir sogenannte Gromov-Wasserstein-Baryzentren, die im Rahmen des kMeans-Clustering als Mittelwerte fungieren.
	
	Wir beschäftigen uns im Folgenden ausschließlichmit diskreten Wahrscheinlichkeitsverteilungen. Grundlegend dafür sind die folgenden Definitionen.
	\begin{comment}
	\subsection{Einführung}
	\subsubsection{Frage:}
	Was ist ein registration problem?
	Warum brauchen wir Gromov-Wasserstein? Warum reicht nicht Wasserstein? Weil wir Matrizen unterschiedlicher Größer vergleichen? Nein. Wir benutzen ja immer dieselbe Distanz für alle Pixel-Werte.
	Wenn wir eine Pixel-Wolke auswählen, sind das nicht dieselben Räume, da dann gewisse Koordinaten nicht zum Raum gehören. Wenn wir aber alle Pixel als Koordinaten im Raum auswählen würden, dann würden die metrischen Räume $(X,d_X)$ und $(Y,d_Y)$ übereinstimmen. Liegt das an der Definition der Baryzentren? Wie würde man das mit Baryzentren auf demselben Raum machen? s. \cite{COTcuturi}
	Translationen und Rotationen könnte ein wichtiger Punkt sein!!!
	verwendung von Grafiken aus anderen Papern??
	Kann man ein anderes Netzwerk zur Detektion nutzen?
	
	\url{https://arxiv.org/pdf/1705.09634.pdf}
	\url{https://arxiv.org/pdf/1412.5154.pdf}
	Für die Grudnlagen im Bereich des Optimalen Transports zitieren wir \cite villani2009optimal.
	
	Entscheidend für die Numerischen Resultate ist die Arbeit von Marco Cuturi \cite{cuturi2013sinkhorn, computationalOT}
	
	\cite{COTcuturi} Remark 2.19 (Translations). zeigt dass die Unabhängigkeit gegenüber Translationen? Kann ich das auch für die Gromov-Wasserstein-Distanz zeigen?
	\subsubsection{Anwendungsgebiete}
	Optimal transport is also used widely in domain adaptation \cite{courty2016optimal}. In domain adaptation, one has
	access to labeled examples from a source domain and unlabeled examples from a target domain.
	The goal is to predict labels for examples from the target domain. This is different from the typical
	train-test paradigm in machine learning, because covariate shift between the two domains is allowed.
	
	
	Ein weitere Anwendung von Optimal Transport sind Wasserstein Generative Adversarial Networks (WGANs) \cite{wgan}. WGANs gehören zur Familie der Modelle namens Generative Adversarial Networks (GANs) \cite{gan}. Zu einem GAN gehören zwei Modelle, von denen beide typischerweise Neuronale Netzwerke sind. Das erste Netzwerk (generator) erzeugt Datenpunkte innerhalb des Datensatzes, die so realsitisch wie möglich sein sollen. Das zweite Netzwerk (discriminator network) versucht, zwischen den realen und den erzeugten Datenpunkten zu unterscheiden. Damit kann der Trainingsprozess von GANs als ein Spiel zwischen den beiden Netzwerken betrachtet werden, bei dem der Generator den Diskriminator täuschen und der Diskriminator die korrumpierten Datenpunkte aufdecken möchte.
	
	Durch die Verwendung von WGANs ansatts GANs wurde ein stabilerer Trainingsprozess erreicht, da diese weniger anfällig für abrupte Trainingsabbrüche sind. Die ursprünglichen GANs benutzten eine Jensen-Shannon-Divergenz als Verlustfunktion, die nicht überall stetig und fast überall differenzierbar ist. Auch andere Verlustfunktion wie besipielsweise die KL-Divergenz weisen ähnliche Schwierigkeiten auf. Durch die Verwendung der Wasserstein-Verlustfunktion, basierend auf der 1-Wasserstein-Distanz, die überall stetig und fast überall differenzierbar ist, konnte der Trainingsprozess der GANs somit deutlich verbessert werden \cite{mauryaoptimal}.
	
\end{comment}
	
	\begin{definition}[\cite{burago2001course}]
		Sei $X$ eine beliebige Menge. Eine Funktion $d:X \times X \to \mathbb{R} \cup \lbrace \infty \rbrace$ heißt \emph{Metrik} auf $X$, falls die folgenden Bedingungen für alle $x,y,z \in X$ gelten:
		\begin{enumerate}[label={(\arabic*)}]
			\item Positive Definitheit: $d(x,y) > 0 \text{ für } x \neq y \text{ und } d(x,y)=0 \text{ für } x=y$,
			\item Symmetrie: $d(x,y)=d(y,x)$,
			\item Dreiecksungleichung: $d(x,z) \leq d(x,y) + d(y,z)$.	
		\end{enumerate}
	\end{definition}
	Ein \emph{metrischer Raum} ist eine Menge, versehen mit einer Metrik. Formal gesehen ist ein metrischer Raum ein Paar $(X,d)$, wobei $d$ eine Metrik auf $X$ ist. Elemente von $X$ heißen Punkte und $d(x,y)$ bezeichnet die Distanz zwischen $x$ und $y$.
	
	
	\begin{definition}[Histogramm]
		Als Histogramm (oder: Zufallsvektor) bezeichnen wir ein Element $\boldsymbol{a} \in \Sigma_n$, das zum folgenden Wahrscheinlichkeits-Simplex gehört:
		
		\begin{equation*}
		\Sigma_n := \lbrace \boldsymbol{a} \in \mathbb{R}_{+}^n | \sum_{i=1}^n{\boldsymbol{a_i} = 1} \rbrace
		\end{equation*}
	\end{definition}
	
	\begin{definition}[Diskretes Maß]
		Ein diskretes Maß mit Gewichtung $\boldsymbol{a}$ und Punkten $x_1,...,x_n \in X$ wird geschrieben als
		\begin{equation}
		\alpha = \sum_{i=1}^n{\boldsymbol{a}_i\delta_{x_i}},
		\end{equation}
		wobei $\delta_x$ das Dirac-Maß and Position $x$ ist. Im dem Fall, dass $\boldsymbol{a} \in \Sigma_n$ und $\boldsymbol{a}_i >0$ f.a. $i$ git, sprechen wir von einem diskreten Wahrscheinlichkeitsmaß.
	\end{definition}
	
	\begin{definition}[\cite{gromov2007metric}]
		Ein \emph{metrischer Maßraum} ist ein Tripel $(X,d_X,\mu_X)$ mit
		\begin{itemize}
			\item $(X, d_X)$ ist ein kompakter metrischer Raum
			\item $\mu_X$ ist ein Borel-Maß auf $X$ mit vollem Support, d.h. 
			\begin{equation}
			supp[\mu_X] = X.\label{eq:bed_mmspaces}
			\end{equation} 
		\end{itemize}
	\end{definition}
	
	\begin{definition}[Isometrie]
		Seien zwei metrische Räume $(X, d_X)$ und $(Y,d_Y)$ gegeben. Wir nennen die Abbildung $\phi:X \to Y$ Isometrie, falls $\phi$ surjektiv ist und $d_X(x,x')= d_Y(\phi(x),\phi(x'))$ f.a. $x, x' \in X$ gilt. Für den Fall, dass eine solche Abbildung $\phi$ existiert, nennen wir $X$ und $Y$ isometrisch.
	\end{definition}

	\begin{definition}[Bildmaß]
		Seien $X,Y$ zwei Maßräume, $T: X \to Y$ eine messbare Abbildung und $\mu$ ein Maß auf X. Dann ist das Bildmaß (oder: pushforwad-Maß) $T^\# \mu $ ein Maß auf Y, definiert durch \begin{equation}
		T^\# \mu (A) = \mu (T^{-1}(A))
		\end{equation}
		für alle $A \subset Y$.
	\end{definition}

%\begin{definition}[Bildmaß]
%	Für zwei Maßräume $(X,\Sigma_X)$ und $(Y,\Sigma_Y)$ und eine messbare Abbildung $f:X\to Y$ ist das Bildmaß $f_\#\mu$ auf $(Y,\Sigma_Y)$ definiert als $f_\#\mu = \mu (f^{-1(B)})$ für alle $B \in \Sigma_Y$.
%\end{definition}

	\begin{definition}[Isomorphie]
		Zwei metrische Maßräume $(X,d_X,\mu_X)$ und $(Y,d_Y,\mu_Y)$ heißen isomorph, falls eine Maß-erhaltende Abbildung $f:X \to Y$ existiert, die $f_\#\mu_X = \mu_Y$ erfüllt.
	\end{definition}
	
	Mit $\mathcal{G}_\mathcal{W}$ bezeichnen wir die Menge aller metrischen Maßräume.
	
	\begin{example}
		Wir betrachten die beiden metrischen Maßräume $(\lbrace a,b \rbrace, (\begin{pmatrix}
		0 & 1\\
		1 & 0 \\
		\end{pmatrix}), \lbrace \frac{1}{2},\frac{1}{2})$ und 
		$(\lbrace a',b' \rbrace, (
		\begin{pmatrix}
		0 & 1\\
		1 & 0 \\
		\end{pmatrix}, \lbrace \frac{1}{4},\frac{3}{4})$
		Dann sind diese Räume isometrisch, jedoch nicht isomorph, vergleich dazu \autoref{im:example_mmspaces}.
	\end{example}
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=0.3\textheight]{example_mmspaces.png}
		\caption[Beispiel isometrischer metrischer Maßräume]{Die beiden metrischen Maßräume sind isometrisch, aber nicht isomorph.}
		\source{\cite{COTcuturi}}
		\label{im:example_mmspaces}
	\end{figure}
	
	
	\begin{definition}[Kopplung]
		Ein Wahrscheinlichkeitsmaß $\mu$ auf $X \times Y$ heißt Kopplung zwischen $\mu_x$ und $\mu_Y$, falls $(\mu_1)_\#\mu = \mu_X$ und $(\mu_2)_\#\mu = \mu_Y$ gilt. Wir benzeichnen mit $\Pi(\mu_X,\mu_Y)$ die Menge aller Kopplungen ziwschen $\mu_X$ und $\mu_Y$.
	\end{definition}
	
	
	%Einführung W-Theorie am KIT \footnote{\url{https://www.math.kit.edu/stoch/~henze/media/wt-ss15-henze-handout.pdf}}
	\begin{definition}[Kopplungen zwischen Histogrammen]
		Seien die beiden Histogramme $p \in \Sigma_{N_1}$ und $q \in \Sigma_{N_2}$ gegeben.
		Als Menge der Kopplungen zwischen beiden Histogrammen definieren wir
		
		\begin{equation*}
		\Pi (p,q) := \lbrace T \in (\mathbb{R}_+)^{N_1 \times N_2} | T \boldsymbol{1}_{N_2} = p, T^\top \boldsymbol{1}_{n_1} = q \rbrace,
		\end{equation*}	
		
		wobei $\boldsymbol{1}_N := (1,...,1)^\top \in \mathbb{R}^{N}$ gilt.
	\end{definition}
	
	
	
	
	
	
	
	
	%Geodesic Space \footnote{\url{http://www.math.toronto.edu/mccann/papers/FiveLectures.pdf}}
	
	
	
	
	

	

	
	
	%\subsection{Notation}
	%siehe: Introduction to Optimal Transport
	%Matthew Thorpe
	
	%\url{http://inis.jinr.ru/sl/vol2/Ax-books/Disk_01/Gromov-Metric-structures-Riemann-non-Riemann-spaces.pdf}
	\subsection{Kantorovichs Optimal Transport}
	In diesem Abschnitt wollen wir eine Ähnlichkeitsbegriff für Maße einführen.
	
	Der Bereich des Optimalen Transports beschäftigt sich mit der Frage, wie mehrere Objekte, die sich in einer bestimmten Verteilung an einem Startpunkt befinden, auf optimale Weise zu einem Zielpunkt transportiert werden können. Dabei wird die Verteilung der Objekte als Wahrscheinlichkeitsverteilung interpretiert. 
	
	
	\subsubsection{Optimaler Transport (Monge Formulierung)}
	
	Dieses Problem wurde zuerst von Gaspard Monge im Jahr 1781 formuliert. In dieser Formulierung wurde Abbildung gesucht, die jedem Punkt in der Ausgangsverteilung einen Punkt in der Zielverteilung zuordnet. Dabei wird die gesamte Masse eines Punktes in der Startverteilung an einen Punkt in der Zielverteilung verschoben. Eine solche Abbildung ist in \autoref{im:monge_mapping} dargestellt.
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=0.3\textheight]{monge_mapping.png}
		\caption[Monge-Abbildung]{\textbf{Links:} Fehlende Eindeutigkeit in der Zuordnung. Die beiden Punkte $x_1$ und $x_2$ können sowohl den Punkten $y_1$ bzw. $y_2$ zugeordnet werden, um eine zulässige Abbildung zu erhalten. \textbf{Rechts:} Die Monge-Abbildung assoziiert das blaue Maße $\boldsymbol{\alpha}$ mit dem roten Maß $\boldsymbol{\beta}$. Dabei ist die Masse in den jeweiligen Punkten über den Flächeninhalt der Kreise dargestellt.}
		\source{\cite{COTcuturi}}
		\label{im:monge_mapping}
	\end{figure}
	
	
	
	
	
	Für den Fall zweier diskreter Maße
	
	\begin{equation}
	\alpha = \sum_{i=1}^n{\boldsymbol{a}_i\delta_{x_i}} \text{ und } \beta = \sum_{j=1}^m{\boldsymbol{b}_j\delta_{y_j}}
	\end{equation}
	können wir das Monge-Problem  wie folgt formulieren:
	
	Gesucht ist eine Abbildung $T:\lbrace x_1, ..., x_n \rbrace \to \lbrace y_1,...,y_m \rbrace$, die die Bedingung 
	\begin{equation}
	\forall j \in \lbrace 1,...,m \rbrace \boldsymbol{b}_j= \sum_{i:T(x_i)=y_i}{\boldsymbol{a}_i}
	\end{equation}
	erfüllt, die wir in Kurzform als $T_\#\alpha = \beta$ schreiben. Aufgrund der Positivität von $\boldsymbol{b}$ ist die Abbildung notwendigerweise surjektiv.
	Als weitere Forderung gilt, dass die Abbildung $T$ minimal bezüglich einer Transportkostenfuktion $c(x,y)$ für $x,y \in \mathbb{R} \times \mathbb{R}$ sein soll:
	\begin{equation}
	\min_T{\sum_i{c(x_i, t(x_i)) : T_\#\alpha =  \beta}}.
	\end{equation} 
	
	Neben der fehlenden Eindeutigkeit einer solchen Abbildung ist auch die Existenz nicht immer gegeben.
	
	\subsubsection{Optimaler Transport nach Kantorovich}
	%\cite{santambrogio2010introduction} ist eine gute, einfache Einführung. Damit kann ich vermutlich Monge und Kantorovich beschreiben.
	
	Das Optimal Transport Problem nach Kantorovich gehört zu den typischen Optimal Transport Problemen. Es stellt einer Relaxierung der Formulierung von Gaspard Monge dar, bei der nun auch das Aufteilen von Masse (mass splitting) zulässig ist, d.h. die Masse an einem Startpunkt, kann auf mehrere Zielpunkte abgebildet werden.
	
	In Kantorovichs Formulierung ist eine Kopplung (oder: Transportabblidung) $\boldsymbol{P}$ gesucht, die die Kosten, die bei der Verschiebung eines diskreten Maßes $\boldsymbol{a}$ auf ein anderes diskretes Maß $\boldsymbol{b}$ bezüglich der Kosten $\boldsymbol{M} \in \mathbb{R}^{n_1 \times n_2}$ entstehen, minimiert.
	Damit $\boldsymbol{P}$ eine Transportabbildung ist, muss $\boldsymbol{P} \in \Pi(a,b) = \lbrace \boldsymbol{P} \geq \boldsymbol{0}, \boldsymbol{P}\boldsymbol{1}_{n_2} = \boldsymbol{a}, \boldsymbol{P}^\top\boldsymbol{1}_{n_1} = \boldsymbol{b} \rbrace$ gelten.
	
	Ein solcher Transportplan ist für drei verschiedene Ausgangssituationen in \autoref{im:coupling_cont_disc} dargestellt.
	
	\begin{figure}[ht]
		\centering
		\includegraphics[width=0.4\textheight]{coupling_disc_semid_cont.png}
		\caption[Transportpläne im diskreten, semi-diskreten und kontinuierlichen Fall]{\textbf{Links: }Kopplung zwischen zwei diskreten Wahrscheinlichkeitsverteilungen. \textbf{ Mitte: }Kopplung zwischen einer kontinuierlichen W-Verteilung $\boldsymbol{\alpha}$ und einer diskreten W-Verteilung $\boldsymbol{\beta}$. \textbf{Rechts: }Kopplung im kontinuierlichen Fall.}
		\source{\cite{COTcuturi}}
		\label{im:couplings}
	\end{figure}
	
	
	
	Für den Fall, dass die Grundkosten eine Metrik darstellen, ist auch die optimale Lösung des Optimal Transport Problems wieder eine Metrik \cite{cuturi2014ground} und definiert die \textit{Wasserstein Distanz}. Das OT Problem ist definiert als
	\begin{equation}
	W_M(\boldsymbol{a},\boldsymbol{b}) = \min_{P \in \Pi(\boldsymbol{a}, \boldsymbol{b})}{\langle \boldsymbol{P}, \boldsymbol{M} \rangle},
	\end{equation}
	
	wobei ${\langle \boldsymbol{P}, \boldsymbol{M} \rangle} = \sum_{ij}{t_{ij}m_{ij}}$ gilt.
	
	Die Lösung des Problems ist eine Kopplung/Kopplungsmatrix, die beschreibt, wie viel Masse von einem Punkt zum anderen Punkt fließt. In einer Kostenmatrix derselben Größe sind die Kosten abgespeichert, um von einem zum anderen Punkt zu kommen.
	
	Die Menge der Matrizen $\Pi(\boldsymbol{a}, \boldsymbol{b})$ ist beschränkt und durch $n+m$ Gleichungen gegeben und damit ein konvexes Polytop (die konvexe Hülle einer endlichen Menge von Matrizen). Zudem ist die Formulierung von Kantorovich im Unterschied zu Monges Formulierung immer symmetrisch in dem Sinne, dass $\boldsymbol{P} \in \Pi (\boldsymbol{a}, \boldsymbol{b})$ genau dann gilt, wenn $\boldsymbol{P}^\top \in \Pi (\boldsymbol{b}, \boldsymbol{a})$.
	
	Kantorovichs Optimal Transport Problem lässt sich nun schreiben als 
	\begin{equation}
	L_C(\boldsymbol{a}, \boldsymbol{b}) := \min_{P \in \Pi(\boldsymbol{a}, \boldsymbol{b})} \langle \boldsymbol{C}, \boldsymbol{P} \rangle := \sum_{i,j}{\boldsymbol{C}_{i,j}\boldsymbol{P}_{i,j}} \label{KOTP}
	\end{equation}
	
	Diese Problem ist ein lineares Problem. Für diese Art von Problemen ist die optimale Lösung nicht notwendigerweise eindeutig. Kantorovich gilt als Erfinder der linearen Optimierung\footnote{OTNotes\_campride.pdf}.
	\begin{comment}
	
	Im Fall beliebiger Maßer egibt sich die folgende
	
	\begin{definition}[Formulierung für beliebige Maße]
	Im Fall beliebiger Maße betrachten wir die Kopplungen $\pi \in \mathcal{M}_+^1(\mathcal{X} \times \mathcal{Y})$, die die gemeinsame Verteilung auf dem Produktraum $\mathcal{X} \times \mathcal{Y}$ ist. Im diskreten Fall verlangen wir, dass das Produktmaß die Form $ \pi = \sum_{i,j}{\boldsymbol{P}_{i,j}\delta_{(x_i, y_j)}}$ besitzt. Im Allgemeinen Fall wird die Massenerhaltung als Randbedingung an die gemeinsame W-Verteilung geschrieben:
	
	\begin{equation}
	\Pi(\alpha, \beta) := \lbrace \pi \in \mathcal{M}_+^1(\mathcal{X} \times \mathcal{Y}): P_{\mathcal{X}_\#} \pi = \alpha \text{ und } P_{\mathcal{Y}_\#} \pi = \beta \rbrace,
	\end{equation}
	wobei $P_{\mathcal{X}_\#}$ und $P_{\mathcal{Y}_\#}$ die Bildmaße der Projektionen $P_\mathcal{X}(x,y) = x$ und $P_\mathcal{Y}(x,y) = y$ sind. Nach \autoref{eq_pushforward} sind diese Randbedingungen äquivalent zu den Bedingungen $\pi(A \times \mathcal{Y}) = \alpha (A)$ und $\pi (\mathcal{X} \times B) = \beta (B)$ für die Mengen $A \subset \mathcal{X}$ und $B \subset \mathcal{Y}$.
	Als Verallgemeinerung erhalten wir dann
	\begin{equation}
	\min_{\pi \in \Pi (\alpha, \beta)}\int_{\mathcal{X} \times \mathcal{Y}}{c(x,y) d\pi (x,y)}. \label{eq:kontorovich_allgemein}
	\end{equation}
	\end{definition}
	
	\end{comment}
	Problem \autoref{KOTP} ist ein unendlich-dimensionales lineares Optinmierungsproblem über einem Raum von Maßen. Falls $(\mathcal{X}, \mathcal{Y})$ kompakt und $c$ stetig ist, existiert immer eine Lösung.
	
	
	\subsubsection{Metrische Eigenschaften}
	Optimaler Transport definiert eine Distanz zwischen Histogrammen und W-Maßen, sofern die Kostenmatrix gewisse Eigenschaften erfüllt. Optimal Transport kann dabei als naheliegende Idee verstanden werden, um Distanzen zwischen Punkten auf Distanzen zwischen Histogrammen oder Maßen zu verallgemeinern.
	
	\begin{definition}[p-Wasserstein-Distanz auf $\Sigma_n$]
		Sei $n=m$ und für $p \geq$ gelte $\boldsymbol{C} = \boldsymbol{D}^p = (\boldsymbol{D}_{i,j}^p)_{i,j} \in \mathbb{R}^{n \times n}$, wobei $\boldsymbol{D} \in \mathbb{R}_+^{n \times n}$ eine Metrik ist.
		
		Dann definiert 
		\begin{equation}
		W_p(\boldsymbol{a}, \boldsymbol{b}) := L_{\boldsymbol{D}^p} (\boldsymbol{a}, \boldsymbol{b})^{1/p}
		\end{equation} 
		die $p$-Wasserstein-Distanz auf $\Sigma_n$
	\end{definition}
	
	\begin{lemma}
		$W_p$ ist eine Metrik
	\end{lemma}
	
	\begin{proof}
		Nach Voraussetzung besitzt $\mathcal{C} = \mathcal{D}^p$ eine Nulldiagonale. Somit gilt $W_p(\boldsymbol{a},\boldsymbol{a}) =0.$. Die zugehörige Transportmatrix ist $\boldsymbol{P}^\star = diag(\boldsymbol{a})$. Aufgrund der Positivität aller Nicht-Diagonalelemente von $\boldsymbol{D}^p$ gilt $W(\boldsymbol{a},\boldsymbol{b})$ für $\boldsymbol{a} \neq \boldsymbol{b}$, da in disem Fall jede zulässige Kopplungen und damit insbesonder die optimale Kopplungen ein Nicht-Diagonalelemnt ungleich $0$ besitzt. Die Symmetrie von $W_p(\boldsymbol{a},\boldsymbol{b})$ gilt wegen der Symmetrie von $\boldsymbol{D}^p$.
		
		Für den Nachweis der Dreiecksungleichung im Fall beliebiger Maße nutzt Villani \cite{villani2003topics} das sogenannte Gluing Lemma. Im diskreten Fall ist die Konstruktion dieser geklebten Kopplung etwas einfacher. Seien $\boldsymbol{a}, \boldsymbol{b}, \boldsymbol{c} \in \Sigma_n$. Seien $\boldsymbol{P}$ und $\boldsymbol{Q}$ zwei optimale Lösungen des Transportproblems zwischen $\boldsymbol{a}$ und $\boldsymbol{b}$ bzw. $\boldsymbol{b}$ und $\boldsymbol{c}$.
		Wir definieren $\tilde{\boldsymbol{b}}$, wobei $\tilde{\boldsymbol{b}}_j = \boldsymbol{b}_j$, falls $\boldsymbol{b}_j > 0$, und $\tilde{\boldsymbol{b}}_j = 1$ sonst gilt. Damit können wir 
		\begin{equation}
		\boldsymbol{S}:= \boldsymbol{P} diag(1/\tilde{\boldsymbol{b}})\boldsymbol{Q} \in \mathbb{R}_+^{n\times n}
		\end{equation}
		schreiben. Es gilt $\boldsymbol{S} \in \Pi (\boldsymbol{a}, \boldsymbol{c})$ wegen
		\begin{equation}
		\boldsymbol{S}\boldsymbol{1}_n = \boldsymbol{P} diag(1/\tilde{\boldsymbol{b}})\boldsymbol{Q}\boldsymbol{1}_n = \boldsymbol{P}(\boldsymbol{b}/\tilde{\boldsymbol{b}}) = \boldsymbol{P}\boldsymbol{1}_{supp[\boldsymbol{b}]} = \boldsymbol{a},	 	\end{equation}
		wobei $\boldsymbol{1}_{supp[\boldsymbol{b}]}$ den Vektor der Größe $n$ bezeichnet, der Einsen an den Stellen mit Indizes $j$ besitzt, für die auch $\boldsymbol{b}_j >0$ gilt, und sonst aus Nullen besteht.
		Außerdem wurde $\boldsymbol{P}\boldsymbol{1}_{supp[\boldsymbol{b}]} = \boldsymbol{P}\boldsymbol{1}_n = \boldsymbol{a}$ benutzt, denn es gilt notwendigerweise $\boldsymbol{P}_{i,j} = 0$ für diejenigen $j$ mit $\boldsymbol{b}_j = 0$. Analog folgt $\boldsymbol{S}^\top\boldsymbol{1}_n = \boldsymbol{c}$.
		
		Damit erhalten wir
		
		\begin{align}
		W_p(\boldsymbol{a},\boldsymbol{c}) &=\left(\min_{\boldsymbol{P \in \boldsymbol{\Pi}(\boldsymbol{a},\boldsymbol{b})}}{\langle \boldsymbol{P},\boldsymbol{P}^p \rangle}\right)^{1/p} \leq \langle \boldsymbol{S}, \boldsymbol{D}^p \rangle ^{1/p} \\
		&= \left( \sum_{ik}{\boldsymbol{D}_{ik}^p} \sum_j{\frac{\boldsymbol{P}_{ij}\boldsymbol{Q}_{jk}}{\tilde{\boldsymbol{b}}_j}}\right)^{1/p} \leq \left(\sum_{ijk}{(\boldsymbol{D}_{ij} + \boldsymbol{D}_{jk})^p \frac{\boldsymbol{P}_{ij}\boldsymbol{Q}_{jk}}{\tilde{\boldsymbol{b}}_j}}\right)^{1/p}\\
		&\leq \left(\sum_{ijk}{\boldsymbol{D}_{ij}^p}\frac{\boldsymbol{P}_{ij}\boldsymbol{Q}_{jk}}{\boldsymbol{\tilde{\boldsymbol{b}}_j}}\right)^{1/p} + \left(\sum_{ijk}{\boldsymbol{D}_{jk}^p \frac{\boldsymbol{P}_{ij}\boldsymbol{Q}_{jk}}{\tilde{\boldsymbol{b}}_j}}\right)^{1/p}.	 	\end{align}
	\end{proof}
	Dabei jaben wir in der ersten Ungleichung benutzt, dass $\boldsymbol{S}$ keine optimale Lösung ist. Für die zweite Ungleichung wurde die Dreiecksungleichung für $\boldsymbol{D}$ verwendet und die dritte Ungleichung folgt aus der Minkowski-Ungleichung.
	Nach Umstellen der beiden letzten Terme erhalten wir damit
	
	\begin{align*}
	W_p(\boldsymbol{a},\boldsymbol{c}) 
	&\leq \left(\sum_{ij}{\boldsymbol{D}_{ij}^p\boldsymbol{P}_{ij}}\sum_k{\frac{\boldsymbol{Q}_{jk}}{\boldsymbol{\tilde{\boldsymbol{b}}_j}}}\right)^{1/p} + \left(\sum_{jk}{\boldsymbol{D}_{jk}^p\boldsymbol{Q}_{jk}}\sum_i{ \frac{\boldsymbol{P}_{ij}}{\tilde{\boldsymbol{b}}_j}}\right)^{1/p}\\
	&= \left(\sum_{ij}{\boldsymbol{D}_{ij}^p\boldsymbol{P}_{ij}}\right)^{1/p}
	+
	\left(\sum_{jk}{\boldsymbol{D}_{jk}^p\boldsymbol{Q}_{jk}}\right)^{1/p}\\
	&= W_p(\boldsymbol{a},\boldsymbol{b})
	+ W_p(\boldsymbol{b},\boldsymbol{c})  
	\end{align*}
	und damit die Behauptung.
	\begin{remark}[Der Fall $0 < p \leq 1$]
		Für $0 < p \leq 1$ ist auch $D^p$ eine Distanz. Damit ist für $ p \leq 1$ $W_p(\boldsymbol{a}, \boldsymbol{b})^p$ eine Distanz au dem Simplex.
		
	\end{remark}
	
	\begin{remark}
		Für $p=1$ ist die p-Wasserstein-Distanz auch als Earth Movers's Distance \cite{rubner2000earth} bekannt
	\end{remark}
	\begin{comment}
			Wasserstein-MEtrik bildet einen metrischen Raum: siehe optimal Transport\_tübingen.pdf
		
		Das hatte ich ja eigentlich schon erwähnt, indem ich zeige, dass Wasserstein eine Metrik ist, die Konsequenz ist ja dann ein metrischer Raum. Die  Menge X muss ich noch angeben:
	\end{comment}
	Der Vollständigkeit halber geben wir auch die Definition im kontinuierlichen Fall an:
	
	\begin{definition}\cite{villani2009optimal}
		Sei $(\mathcal{X},d)$ ein Polnischer Raum. Sei $p\in [1, \infty)$. Für zwei Wahrscheinlichkeitsmaße $\mu, \nu$ auf $\mathcal{X}$ ist die \emph{Wasserstein-Distanz der Ordnung p} (oder kurz: p-Wasserstein-Distanz) zwischen $\mu$ und $\nu$ definiert durch
		
		\begin{equation}
		W_p(\mu, \nu) = \left( \inf_{\mu \in \Pi(\mu, \nu)}\int_{\mathcal{X}}{d(x,y)^pd\pi(x,y)}\right) ^{1/p}.
		\end{equation}	
	\end{definition}
	\subsubsection{Duale Formulierung}
	Kurzer Überblick hier\footnote{\url{https://arxiv.org/pdf/1609.04767.pdf}}
	oder hier\footnote{\url{text}} % (Herleitung der Dualen Formulierung mit Beweis)\footnote{\url{text}}.
	
	%The Kantorovich problem (2.11) is a constrained convex minimization problem, and as
	%such, it can be naturally paired with a so-called dual problem, which is a constrained
	%concave maximization problem. The following fundamental proposition explains the
	%relationship between the primal and dual problems.
	
	
	\subsubsection{Verfahren zur Berechnung der exakten Lösung}
	\begin{itemize}
		\item Network Simplex Algorithm
		\item Dual Ascent Methods
		\item Auction Algorithm
	\end{itemize}
	
	\subsubsection{Komplexitätsanalyse}
	Im Fall $n=m$ ist das Kantorovich-Problem und damit die Berechnung der Wasserstein-Distanz ein lineares Optimierungsproblem mit $\mathcal{O}(n)$ linearen Bedingungen. Für die Lösung kann beispielsweise der lineare Lee-Sinford-Algorithmus zur Berechnung einer Lösung in $\tilde{\mathcal{O}}(n^{2.5})$ \cite{lee2014path} verwendet werden, der den vorherigen Standard von $\mathcal{O}(n^{2.5})$ \cite{renegar1988polynomial} verbessert.
	\subsubsection{Wasserstein-Baryzentren}
	Für den Fall zweier Wahrscheinlichkeitsmaße wird die Interpolation zwischen diesen in \cite{maccann} betrachtet und ist als McCann's Interpolation bekannt. Eine Verallgemeinerung auf endlich viele Maße liefert \cite{bary_wasserstein_space}, wodurch sich eine Art Mittelwertsbegriff für Wahrscheinlichkeitsmaße ergibt. Das Problem lässt sich wie folgt formulieren:
	Seien die W-Maße $(\nu_1,...,\nu_S)$, definiert auf dem metrischen Raum $X$ gegeben. Dann definiert
	\begin{equation}
		\min_{\nu \in \mathcal{M}_+^1(\mathcal{X})}{{\sum_{s=1}^S{\lambda_s W_2^2(\nu , \nu_s)}}}.
	\end{equation}
	das Bary-Zentrum zu diesen $s$ Maßen auf $X$ bezüglich der 2-Wasserstein-Distanz..
	
	Im diskreten Fall seien $S$ Histogramme $(b_s)_{s=1}^S$ mit $b_s \in \Sigma_{n_s}$ und Gewichten $\lambda \in \Sigma_S$ gegeben. Für $n_s=n$ und $C_s=C=D^p$ erhalten wir:
	
	\begin{equation}
		\min_{a \in \Sigma_n}{\sum_{s=1}^S \lambda_s{W_p^p(a,b_s)}}.
	\end{equation}
	
	Existenz und Eindeutigkeit werden in \cite{bary_wasserstein_space} diskutiert.
	Zwei Algorithmen zur Berechnung der Bary-Zentren werden in \cite{carlier2015numerical} vorgestellt.
	
	\begin{comment}
		
	
	Fast Computation of Wasserstein Barycenters\footnote{\url{https://arxiv.org/pdf/1310.4375.pdf}}
	\end{comment}
	
	\subsection{Entropisch regularisierte Wasserstein-Distanz}
	In diesem Abschnitt betrachten wir die regularisierte Version der Wasserstein-Distanz mithilfe von Entropie. 
	Diese von Marco Cuturi vorgestellte Regularisierung \cite{cuturi2013sinkhorn} verhalf dem Gebiet des Computational Optimal Transport zu sehr großem in Interesse. Durch die Regularisierung mit Entropie entsteht eine Kullback-Leibler-Distanz, für die Standard-Verfahren wie beispielsweise der Sinkhorn-Algorithmus verwendet werden können.
	Andere Arten der Regularisierung sind Group Lasso [Courty et al., 2016a] und KL, Itakura Saito, $\beta$-divergences,
	[Dessein et al., 2016].\footnote{\url{https://www.damtp.cam.ac.uk/research/cia/files/teaching/Optimal_Transport_Syllabus.pdf}}\\
	
	Die Entropie einer Matrix ist wie folgt definiert:
	
	\begin{definition}[Entropie]
		Für $T \in \mathbb{R}_{+}^{n \times n}$ definieren wir die Entropie als
		\begin{equation}
		H(T) := - \sum_{i,j=1}^N{T_{i,j}(log(T_{i,j})-1)}.
		\end{equation}
	\end{definition}
	Entropic Regularization of Optimal Transport \cite{computationalOT}
	
	\begin{comment}
	
	Optimal Transport: Regularization and Applications
	\footnote{\url{https://www.otra2020.com/schedule}}
	Python Optimal Transport Toolbox\footnote{\url{https://pythonot.github.io/quickstart.html}}\footnote{\url{https://pythonot.github.io/auto_examples/gromov/plot_gromov.html}}
	
	Kapitel 2.1 im Paper: Vergleich von Histogrammen auf demselben metrischen Raum.
		content...
	\end{comment}
	\begin{lemma}
		\begin{equation}
		L_C(\boldsymbol{a}, \boldsymbol{b}):= \min_{P \in \Pi(\boldsymbol{a}, \boldsymbol{b})}{\langle \boldsymbol{P}, \boldsymbol{C} \rangle - \varepsilon \boldsymbol{H}(\boldsymbol{P})}\label{eq:reg_problem}	
		\end{equation}
		
		
		ist ein $\varepsilon$-streng konvexes Problem und besitzt deshalb eine eindeutige optimale Lösung.
		
	\end{lemma}
	
	\begin{proof}
		Die Entropie H ist wegen der Hesse-Matrix $\partial ^2 H (P) = -diag(1/P_{i,j})$ und $P_{i,j} \leq 1$ stark konkav.
		Durch die Multiplikation mit $\varepsilon$ und anschließender Subtraktion wird aus \autoref{eq:reg_problem} ein konvexes Problem. 
	\end{proof}
	
	\begin{figure}[!ht]
		\centering
		\includegraphics[width=0.3\textheight]{wd_Transportplan.png}
		\caption[Visualisierung der Wasserstein-Distanz und Transportplan]{\textbf{Links:} Visualisierung der Wasserstein-Distanz zwischen den Verteilungen $\mu_A$ und $\nu_B$ auf dem metrischen Raum $(\Omega,d)$. \textbf{Rechts:} Möglicher Transportplan $\pi$.}
		\source{\cite{vialard2019elementary}}
		\label{im:wasserstein_distance_visualization}
	\end{figure}
	
	
	
	
	\begin{remark}
		Für größere $\varepsilon$ wird mehr Entropie gefordert
	\end{remark}
	
	\begin{proposition}[Konvergenz in $\varepsilon$]
		Die eindeutige Lösung $P_\varepsilon$ von \autoref{eq:reg_problem} konvergiert gegen die optimale Lösung mit maximaler Entropie innerhalb der Menge aller optimalen Lösungen des Kantorovich Problems, d.h.
		\begin{equation}
		\boldsymbol{P}_\varepsilon \xrightarrow{\varepsilon \to 0} \argmin_{P} \lbrace -\boldsymbol{H}(\boldsymbol{P}) : \boldsymbol{P} \in \Pi (\boldsymbol{a}, \boldsymbol{b}), \langle \boldsymbol{P}, \boldsymbol{C} \rangle = L_{\boldsymbol{C}}(\boldsymbol{a}, \boldsymbol{b}) \rbrace, \label{eq:P_eps_0} 
		\end{equation}
		
	
		\begin{equation}
		L_{\boldsymbol{C}}^\varepsilon (\boldsymbol{a}, \boldsymbol{b}) \xrightarrow{\varepsilon \to 0} L_{\boldsymbol{C}}(\boldsymbol{a}, \boldsymbol{b})
		\end{equation}
		Zudem gilt
		\begin{equation}
		\boldsymbol{P}_\varepsilon \xrightarrow{\varepsilon \to \infty} \boldsymbol{a} \otimes \boldsymbol{b} = \boldsymbol{a} \boldsymbol{b}^\top = (\boldsymbol{a}_i \boldsymbol{b}_j)_{i,j}. \label{eq:P_eps_infty}
		\end{equation}
	\end{proposition}
	
	\begin{proof}
		Sei eine Folge $(\varepsilon_l)_l$ mit $\varepsilon_l \to 0$ und $\varepsilon_l > 0$ gegeben. Sei $P_l$ die Lösung von  \autoref{eq:reg_problem} für $\varepsilon = \varepsilon_l$. Da $\Pi(a,b)$ beschränkt ist, existiert eine Teilfolge $\varepsilon_k$ mit $P_k \to P^*$. Augfrund der Abgeschlossenheit von $\Pi(a,b)$ folgt $P^* \in \Pi(a,b)$.
		
		Sei $P \in \Pi (a,b)$ beliebig mit $\langle C, P \rangle = L_C(a,b)$. Aufgrund der Optimalität von $P$ und $P_l$ bezüglich $L_C(a,b)$ bzw. $L_C^{\varepsilon_l}(a,b)$ gilt
		
		\begin{equation}
		0 \leq \langle C, P_l\rangle - \langle C, P_\rangle \leq \varepsilon_l (H(P_l)-H(P)). \label{eq:abschätzung1}
		\end{equation}
		Aufgrund der Stetigkeit von $H$ folgt für $l \to +\infty$ in \autoref{eq:abschätzung1} $\langle C, P^* \rangle = \langle C, P \rangle$, womit $P^*$ ein zulässiger Punkt ist. Division durch $\varepsilon_l$ in \autoref{eq:abschätzung1} und Übergang zum Grenzwert liefert $H(P)\leq H(P^*)$. Folglich ist $P^*$ eine Lösung von \autoref{eq:P_eps_0}.
		
		Da die Lösung $P_0^*$ aufgrund der strikten Konvexität von $-H$ eindeutig ist, gilt $P^* = P_0^*$ und die gesamte Folge konvergiert.
		
		
	\end{proof}
	
	\begin{remark}
		\autoref{eq:P_eps_0} zeigt, dass die Lösung für kleine $\varepsilon$ gegen die Optimale Transport Kopplung mit maximaler Entropie konvergiert. Im Gegensatz dazu, bedeutet \autoref{eq:P_eps_infty}, dass die Lösung für große Regularisierungsparameter gegen die Kopplung mit maximaler Entropie zwischen zwei gegebenen Randverteilungen $\boldsymbol{a}$ und $\boldsymbol{b}$ konvergiert.\\
		
	\end{remark}
	
	\begin{remark}
		Für größere Werte von $\varepsilon$ ergibt sich eine beschleunigte Berechnung der optimalen Kopplung.
	\end{remark}
	
	\noindent \textbf{Interpretation als KL Problem:} \autoref{eq:reg_problem} kann außerdem als Spezialfall eines Kullback-Leibler-Minimierunsgproblems betrachtet werden, bei dem eine Kopplungsmatrix $\boldsymbol{P}_\varepsilon$ gesucht ist, die im Sinner einer Kullback-leibler-Divergenz möglichst nahe an einem Kernel K liegt.
	Wir definieren die Kullback-Leibler-Divergenz zwischen Kopplungen als
	
	\begin{equation}
	\boldsymbol{KL}(\boldsymbol{P}|\boldsymbol{K}) := \sum_{i,j} \boldsymbol{P}_{i,j} \log \left(\frac{\boldsymbol{P}_{i,j}}{\boldsymbol{K}_{i,j}} \right) - \boldsymbol{P}_{i,j} + \boldsymbol{K}_{i,j}. \label{eq:KL_div_discrete}
	\end{equation}
	Damit ist die eindeutige Lösung $\boldsymbol{P}_\varepsilon$ von \autoref{eq:reg_problem} eine Projektion des zur Kostenmatrix $\boldsymbol{C}$ gehörigen Gibbs-Kernels $\boldsymbol{K}_{i,j} := e^{-\frac{\boldsymbol{C}_{i,j}}{\varepsilon}}$ auf $\Pi (\boldsymbol{a}, \boldsymbol{b})$.
	
	Mit der obigen Definition erhalten wir
	
	\begin{equation}
	\boldsymbol{P}_\varepsilon = Proj_{\boldsymbol{\Pi} (\boldsymbol{a}, \boldsymbol{b})}^{\boldsymbol{KL}}(\boldsymbol{K}) := \argmin_{P \in \boldsymbol{\Pi} (\boldsymbol{a}, \boldsymbol{b})}{\boldsymbol{KL}(\boldsymbol{P}|\boldsymbol{K})}.
	\end{equation}
	
	\subsubsection{Algorithmus von Sinkhorn und Variationen}
	In diesem Abschnitt sehen wir, dass die Lösung des regularisierten Problems eine besondere Form besitzt, die auf den Algorithmus von Sinkhorn führt.
	
	Matrix Scaling + einige Theoreme und Bemerkungen zu Kullback-Leibler und mehr Info \cite{vialard2019elementary}
	
	\begin{comment}
	
	\begin{remark}[Formulierung für allgemeine Maße]
	Für beliebige Maße lässt sich ebenfalls eine regularisierte Formulierung \cite{COTcuturi} angeben. 
	Dazu wird die diskrete Entropie durch die relative Entropie bezüglich des Produktmaße $d\alpha \otimes d\beta (x,y) := d\alpha (x) d\beta (y)$. Als regularisierte Version von \autoref{eq:kontorovich_allgemein} ergibt sich 
	\begin{equation}
	\min_{\pi \in \Pi (\alpha , \beta)} \int_{\mathcal{X}\times \mathcal{Y}}{c(x,y)d\pi (x,y) + \varepsilon KL(\pi |\alpha \otimes \beta)}, 
	\end{equation}\label{eq:kantorovich_reg_allgemein}
	wobei die relative Entropie eine Verallgemeinerung der diskreten Kullback-Leibler-Divergenz \autoref{eq:KL_div_discrete} ist und die folgende Form besitzt:
	\begin{align}
	KL(\pi |\xi) &:=\int_{\mathcal{X} \times \mathcal{Y}} \log \left(\frac{d\pi}{d\xi}(x,y)\right) d\pi (x,y) \\
	´			& + \int_{\mathcal{X} \times \mathcal{Y}}(d\xi (x,y) - d\pi (x,y)).			 
	\end{align}
	Hierbei wird $KL(\pi | \xi) = +\infty$ gesetzt, falls $\pi$ keine Dichte $\frac{d\pi}{d\xi}$ bezüglich $\xi$ besitzt.
	\end{remark}
	
	Die folgende Proposition zeigt, dass die Lösung von \autoref{eq:kantorovich_reg_allgemein} unabhängig von der Wahl des Referenzmaßes für die Definition von $KL(\cdot | \alpha \otimes \beta)$ ist.
	
	\begin{proposition}
	Für $\pi \in \Pi(\alpha, \beta)$ und $(\alpha ', \beta ')$, mit den selben Nullmengen wie $(\alpha , \beta )$,
	gilt
	\begin{equation}
	KL(\pi |  \alpha \otimes \beta) = KL( \pi |\alpha ' \otimes \beta ') - KL(\alpha \otimes \beta | \alpha ' \otimes \beta ')
	\end{equation}
	\end{proposition}
	
	\autoref{eq:kantorovich_reg_allgemein} kann äquivalent als Projektionsproblem
	\begin{equation}
	\min_{\pi \in \Pi (\alpha, \beta)}{KL(\pi |\mathcal{K})} \label{eq:schrödinger}
	\end{equation}
	geschrieben werden, wobei $\mathcal{K}$ die Gibbs-Verteilung $d\mathcal{K}(x,y) := e^{-\frac{c(x,y)}{\varepsilon}}d\alpha (x) d\beta (y)$ besitzt.\\
	Diese Formulierung ist auch "Statisches Schrödinger Problem" bekannt.
	Für $\varepsilon  \to 0$ konvergiert die eindeutige Lösung von \autoref{eq:schrödinger} gegen die Lösung mit maximaler Entropie von \autoref{eq:kontorovich_allgemein} \cite{carlier2017convergence}.
	\footnote{\url{https://hal.archives-ouvertes.fr/hal-00849930/document}}	
	\end{comment}
	\begin{proposition}
		Die Lösung des regularisierten Problems \autoref{eq:reg_problem} besitzt die Form
		\begin{equation}
		\forall (i,j) \in \lbrace 1,...,n \rbrace \times \lbrace 1,...,m \rbrace : \boldsymbol{P}_{i,j} = \boldsymbol{u}_i \boldsymbol{K}_{i,j} \boldsymbol{v}_j \label{eq:reg_sol_factorized}
		\end{equation}
		für die beiden (unbekannten) Variablen $(\boldsymbol{u}, \boldsymbol{v}) \in \mathbb{R}_+^n \times \mathbb{R}_+^m.$
	\end{proposition}
	
	\begin{proof}
		Wir führen für jede der beiden Nebenbedingungen die dualen Variablen $\boldsymbol{f} \in \mathbb{R}^n$ und $g \in \mathbb{R}^m$ ein. Für die Lagrange-Funktion zu \autoref{eq:reg_problem} erhalten wir damit:
		\begin{equation}
		\mathcal{L}(\boldsymbol{P}, \boldsymbol{f}, \boldsymbol{g}) = \langle \boldsymbol{P}, \boldsymbol{C} \rangle -\varepsilon \boldsymbol{H}(\boldsymbol{P}) - 
		\langle \boldsymbol{f}, \boldsymbol{P}\boldsymbol{1}_m - \boldsymbol{a} \rangle -
		\langle \boldsymbol{g}, \boldsymbol{P}^\top \boldsymbol{1}_n - \boldsymbol{a} \rangle. 
		\end{equation}
		Mit der Optimalitätsbedingung erster Ordnung ergibt sich
		\begin{equation}
		\frac{\partial \mathcal{L} (\boldsymbol{P}, \boldsymbol{f}, \boldsymbol{g})}{\partial \boldsymbol{P}_{i,j}} = \boldsymbol{C}_{i,j} + \varepsilon \log (\boldsymbol{P}_{i,j}) -\boldsymbol{f}_i - \boldsymbol{g}_j = 0,
		\end{equation}
		
		womit wir für eine optimale Kopplung $\boldsymbol{P}$ für das regularisierte Problem den Ausdruck $\boldsymbol{P}_{i,j} = e^{\boldsymbol{f}_i/\varepsilon}e^{-\boldsymbol{C}_{i,j}/\varepsilon}e^{\boldsymbol{g}_j/\varepsilon}$, der in die gewünschte Form umgeschrieben werden kann.
	\end{proof}
	
	
	\begin{remark}[Algorithmus von Sinkhorn]
		Die Faktorisierung der Lösung in \autoref{eq:reg_sol_factorized} können in der folgenden Matrix-Form schreiben: $\boldsymbol{P} = diag(\boldsymbol{u}) \boldsymbol{K} diag(\boldsymbol{v})$. Die beiden Variablen $(\boldsymbol{u}, \boldsymbol{v})$ müssen deshalb die folgenden nichtlinearen Gleichungen erfüllen, die aufgrund der geforderten Massenerhaltungsbedingung in $\Pi (\boldsymbol{a},\boldsymbol{b})$ gelten:
		\begin{equation}
		diag(\boldsymbol{u}) \boldsymbol{K} diag(\boldsymbol{v})\boldsymbol{1}_m = \boldsymbol{a} \text{ und }
		diag(\boldsymbol{v}) \boldsymbol{K}^\top diag(\boldsymbol{u})\boldsymbol{1}_n = \boldsymbol{b}.
		\end{equation}
		Aufgrund der Beziehung $diag(\boldsymbol{v})\boldsymbol{1}_m =  \boldsymbol{v}$ und selbiger Beziehung für $\boldsymbol{u}$ erhalten wir die folgende Vereinfachung
		\begin{equation}
		\boldsymbol{u} \odot (\boldsymbol{K}\boldsymbol{v}) = \boldsymbol{a} \text{ und }
		\boldsymbol{v} \odot (\boldsymbol{K}^\top \boldsymbol{v}) = \boldsymbol{a}, \label{eq:sinkhorn_equations}
		\end{equation}  
		wobei $\odot$ für die Element-weise Multiplikation zweier Vektoren steht. Dieses Problem ist als \textit{Matrix Scaling Problem} \cite{matrix_scaling} bekannt.\\
		(? Sollte ich hier Bedingungen für die Lösbarkeit angeben?) \\
		Eine Möglichkeit zur Lösung dieses Problems ist ein iteratives Vorgehen(?Verfahren), bei dem zunächst $\boldsymbol{u}$ so modifiziert wird, dass die linke Seite in \autoref{eq:sinkhorn_equations} erfüllt ist, und anschließend die Modifikation von $\boldsymbol{v}$ vorgenommen wird, sodass die rechte Seite in \autoref{eq:sinkhorn_equations} gilt. Mit diesen beiden Modifikationen erhalten wir den Algorithmus von Sinkhorn, der aus den beiden folgenden Updates besteht:
		
		\begin{equation}
		\boldsymbol{u}^{(l+1)}:= \frac{\boldsymbol{a}}{\boldsymbol{K}\boldsymbol{v}^{(l)}} \text{ und }
		\boldsymbol{v}^{(l+1)}:= \frac{\boldsymbol{b}}{\boldsymbol{K}^\top \boldsymbol{u}^{(l+1)}},
		\end{equation} 
		wobei zu Beginn mit einem beliebigen positiven Vektor, beispielsweise $\boldsymbol{v}^{(0)} = \boldsymbol{1}_m$ initialisiert wird und $l$ den aktuellen Iterationsschritt bezeichnet. Die obigen Division muss ebenfalls elementweise verstanden werden.
		
		Die Konvergenz dieses Verfahrens wurde zuerst von Sinkhorn \cite{sinkhorn1964relationship} gezeigt und trägt deshalb den entsprechenden Namen.
	\end{remark}
	
	
	
	\begin{comment}
		The iterations (4.15) first appeared in [Yule, 1912,
		Kruithof, 1937]. They were later known as the iterative proportional fitting procedure
		(IPFP) Deming and Stephan [1940] and RAS [Bacharach, 1965] methods [Idel, 2016].
		The proof of their convergence is attributed to Sinkhorn \cite{sinkhorn1964relationship}, hence the name of the
		algorithm.
	\end{comment}

	
	
	
	\begin{remark}
		Die Lösung zum regularisierten Problem lässt sich nach den Sinkhorn-Iterationen wie folgt angeben: $P_L = diag(u_L)K diag(v_L)$ Das ist  der optimal Transport plan für das Regularisierte Problem.Optimal Transport Caost lässt sich berechnen als:
		$\langle P_L, M_{XY}\rangle = u_L ^\top ( K \odot M_{XY})v_L$.	\end{remark}	
	
	
	Für die globale Konvergenzanalayse der Sinkhorn-Algorithmus lässt sich ein Zusammenhang mit der Hilbertschen Projektionsmetrik benutzen, der erstmals in \cite{franklin_sinkhorn_convergence} vorgestellt wurde.
	
	Diese ist wie folgt definiert:
	
	\begin{definition}[Projektive Hilbert-Metrik]
		Seien $u,u' \in \mathbb{R}_{+,\star}^n$.
		Dann ist die projektive Hilbert-Metrik $d_\mathcal{H}$ definiert durch
		\begin{equation}
		d_\mathcal{H}(u,u') := \log \max_{i,j}{\frac{u_iu_j'}{u_ju_i'}}.
		\end{equation}
	\end{definition}
	
	\begin{remark}
		Die Hilbert-Metrik $ d_\mathcal{H}$ definiert eine Metrik auf dem projektiven Kegel $\mathbb{R}_{+, \star}^n \sim$, wobei $u \sim u'$ bedeutet, dass gilt: $\exists r >0:u=ru'$, d.h. die Vektoren $u$ und $u'$ sind bis auf Skalierung identisch.
		
	\end{remark}
	
	\begin{comment}
			The Hilbert metric was introduced independently by [Birkhoff,
		1957] and [Samelson et al., 1957]. They proved the following fundamental theorem,
		which shows that a positive matrix is a strict contraction on the cone of positive
		vectors.
	\end{comment}

	
	Das folgende Theorem zeigt, dass eine positive Matrix eine Kontraktion auf dem Kegel positiver Vektoren bezüglich der Hilbert-Metrik ist.
	
	\begin{theorem}\label{theorem41}
		Sei $K \in \mathbb{R}_{+,\star}^{n \times m}$. Dann gilt für $(v,v') \in (\mathbb{R}_{+, \star}^m)^2$
		
		\begin{equation}
		d_\mathcal{H}(Kv,Kv') \leq \lambda (K) d_\mathcal{H}(v,v'), \text{ mit } \begin{cases}
		\lambda (K) := \frac{\sqrt{\nu (K)} -1}{\sqrt{\nu (K)}+1}\\
		\nu (K) := \max_{i,j,k,l} \frac{K_{i,k}K_{j,l}}{K_{j,k}K_{i,l}}
		
		\end{cases}
		\end{equation}
	\end{theorem}
	
	Visualisierung des Theorems vgl \cite{COTcuturi},Seite 70.
	
	Mit diesem Resultat lässt sich die Konvergenz des Verfahrens zeigen:
	
	\begin{theorem}
		Es gilt $(u^{(l)}, v^{(l)})\to (u^\star, v^\star)$ und
		\begin{equation}
		d_{\mathcal{H}}(u^{(l)}, u^\star) = \mathcal{O}(\lambda(K)^{2l}), \qquad d_\mathcal{H}(v^{(l)},v^\star) = \mathcal{O}(\lambda (K)^{2l}) \label{eq:erstesResThm42}
		\end{equation}
		Es gelten außerdem die beiden folgenden Abschätzungen
		\begin{align}
		d_\mathcal{H} (u^{(l)}, u^\star) &\leq \frac{d_\mathcal{H}(P^{(l)}\boldsymbol{1}_m, a)}{1-\lambda(K)^2}, \label{eq:thm42zweiAbschätzungen1}\\
		d_\mathcal{H} (v^{(l)}, v^\star) &\leq \frac{d_\mathcal{H}(P^{(l)\top}\boldsymbol{1}_n, b)}{1-\lambda(K)^2}, \label{eq:thm42zweiAbschätzungen}		
		\end{align}
		wobei \begin{equation}
		P^{(l)} := diag(u^{(l)})K diag(v^{(l)}) \label{eq:reconstruction_TransportPlan}
		\end{equation}
		gilt. Desweiteren gilt die Abschätzung
		\begin{equation}
		|| \log(P^{(l)}) - \log (P^\star)||_\infty \leq d_\mathcal{H} (u^{(l)}, u^\star) + d_\mathcal{H} (v^{(l)}, v^\star), \label{eq:thm42letzteAbschätzung}
		\end{equation}
		wobei $P^\star$ die eindeutige Lösung von \autoref{eq:kantorovich_reg_allgemein} ist.
	\end{theorem}
	\begin{proof}
		Für ein beliebiges Paar $(v,v') \in (\mathbb{R}_{+,\star}^m)^2$ gilt
		\begin{equation*}
		d_\mathcal{H} (v,v') = d_\mathcal{H}(v/v',\boldsymbol{1}_m) = d_\mathcal{H}(\boldsymbol{1}_m/v,\boldsymbol{1}_m/v').
		\end{equation*}
		Mit dieser Beziehung und \autoref{theorem41} erhalten wir
		\begin{align*}
		d_\mathcal{H}(u^{(l+1)}, u^\star) &= d_\mathcal{H}\left(\frac{a}{Kv^{(l)},\frac{a}{Kv^\star}}\right)\\
		&=d_\mathcal{H}(Kv^{(l)}, Kv^\star) \\
		&\leq \lambda (K)d_\mathcal{H}(v^{(l),v^\star}).
		\end{align*}
		Dies zeigt \autoref{eq:erstesResThm42}. Mit Hilfe der Dreiecksungleichung erhalten wir
		\begin{align*}
		d_\mathcal{H}(u^{(l)}, u^\star) &\leq d_\mathcal{H}(u^{(l+1)},u^{(l)}) + d_\mathcal{H}(u^{(l+1)},u^\star)\\
		& \leq d_\mathcal{H}\left(\frac{a}{Kv^{(l)}}, u^{(l)}\right) + \lambda (K)^2 d_\mathcal{H}(u^{(l),u^\star})\\
		&= d_\mathcal{H}\left(a, u^{(l)} \odot (Kv^{(l)})\right) + \lambda (K)^2 d_\mathcal{H}(u^{(l)},u^\star)\\
		&= d_\mathcal{H}\left(a, P^{(l)}\boldsymbol{1}_m \right) + \lambda (K)^2 d_\mathcal{H}(u^{(l)},u^\star)
		\end{align*}
		und damit nach Division durch $1-\lambda(K)^2$  \autoref{eq:thm42zweiAbschätzungen1}. Die zweite Abschätzung, \autoref{eq:thm42zweiAbschätzungen}, folgt analog. 
		Die \autoref{eq:thm42letzteAbschätzung} gilt nach Lemma 3 in \cite{franklin_sinkhorn_convergence}.
	\end{proof}
	
	\begin{comment}
	
	\begin{remark}
		\leavevmode 
		\begin{itemize}
			\item Konvergenzrate?
			\item Berechnung der optimalen Transportpläne mit \autoref{eq:reconstruction_TransportPlan} im Zeitschritt $l$ und Berechnung der Transportkosten ...
			\item Abbruchkriterien (vgl. mit der POT Implementierung)
		\end{itemize}
	\end{remark}
		content...
	\end{comment}
	\subsubsection{Komplexitätsanalyse}
	\cite{altschuler2017near} liefert eine Komplexitätsanalyse für die Sinkhorn-Iterationen. Im Fall $n=m$ sind für die Wahl $\varepsilon = \frac{4 \log (n)}{\tau}$ $\mathcal{O}(||C||_\infty^3 \log (n)\tau ^{-3})$ Sinkhorn-Iterationen (inklusive eines Rundungsschrittes) notwendig, um eine zulässige Kopplung $\hat{\boldsymbol{P}} \in \Pi(\boldsymbol{a}, \boldsymbol{b})$ zu berechnen, die die Abschätzung $\langle \hat{\boldsymbol{P}}, \boldsymbol{C} \rangle \leq L_{\boldsymbol{C}}(\boldsymbol{a}, \boldsymbol{b} +  \tau)$ zu berechnen. Somit liefert das Sinkhorn-Verfahren eine $\tau$-Approximation des nicht regularisierten Optimal Transport-Problems in $\mathcal{O}(n^2 \log (n)\tau ^{-3})$ Operationen.
	Gleichzeitig wir dort eine greedy Variante der Sinkhorn-Iterationen namens Greenkhorn präsentiert, die eine $\tau$-Approximation in $\mathcal{O}(n^2\tau^{-3})$ Operationen liefert.
	\cite{dvurechensky2018computational} verbessert diese auf $\mathcal{O}(n^2\tau^{-2})$ Operationen.
	\subsection{Gromov-Wasserstein-Divergenz}
	In den vorherigen Abschnitten hatten wir jeweils Wahrscheinlichkeitsmaße auf demselben metrischen Raum verglichen. In diesem Abschnitt wollen wir diesen Abstandsbegriff auf die Distanz zweier verschiedener metrischer Maßräume (mM) verallgemeinern. Dazu definieren wir die Gromov-Wasserstein-Distanz, die der Wasserstein-Distanz sehr ähnlich und eine Relaxierung der Hausdorff-Distanz ist.
	
	\subsubsection{Gromov-Wasserstein-Divergenz}
	
	
	\begin{definition}[Tensor-Matrix-Multiplikation]
		Für einen Tensor $\mathcal{L} = (\mathcal{L}_{i,j,k,l})_{i,j,k,l}$ und eine Matrix $(T_{i,j})_{i,j}$ definieren wir die Tensor-Matrix-Multiplikation als
		\begin{equation}
		\mathcal{L} \otimes T := \left(\sum_{k,l}{\mathcal{L}_{i,j,k,l}T_{k,l}}\right)_{i,j}. \label{eq:tensor_matrix_mul}
		\end{equation}
	\end{definition}
	\cite{vialard2019elementary}
	Wir definieren zunächst die beiden folgenden Distanzen:
	
	\begin{definition}[Hausdorff-Distanz]
		Sei $X$ ein metrischer Raum.
		Für  $X,Y \subset \mathscr{X}$ kompakt und nichtleer definieren wir die \emph{Hausdorff-Distanz} $d_H(X,Y)$ als
		\begin{equation}
		d_H(X,Y) = \max \lbrace \sup_{x \in X} \inf_{y \in Y} d(x,y), \sup_{y \in Y} \inf_{x \in Y} d(x,y) \rbrace .
		\end{equation} 
		
	\end{definition}
	Anschaulich haben zwei kompakte Teilmengen einen geringen Hausdorff-Abstand, wenn es zu jedem Element der einen Menge ein Element der anderen Menge gibt, zu dem dieses einen geringen Abstand hat. In \autoref{im:hausdorff_example} ist die Hausdorff-Distanz zweier Mengen $X$ und $Y$ dargestellt.
	
	\begin{figure}[!ht]
		\centering
		\includegraphics[width=0.3\textheight]{Hausdorff_distance.png}
		\caption{Visualisierung der Hausdorff-Distanz zwischen den Mengen $X$ und $Y$ in $\mathbb{R}^2$.}
		\source{By Rocchini - Own work, CC BY 3.0, https://commons.wikimedia.org/w/index.php?curid=2918812}
		\label{im:hausdorff_example}
	\end{figure}
	
	
	Eine Teilmenge $R \subset X \times Y$ ist eine Korrespondenz zwischen den Mengen $X$ und $Y$, falls $\pi_1(R) = X$ und $\pi_2(R) = Y$, wobei $\pi_1: X \times Y \to X$ und $\pi_2: X \times Y \to Y$ die kanonischen Projektionen sind. Sei $\mathcal{R}(X,Y)$ die Menge aller Korrespondenzen zwischen $X$ und $Y$.
	
	\begin{definition}[Gromov-Hausdorff-Distanz]
		Für die kompakten, metrischen Räume $(X,d_X)$ und $(Y,d_Y)$ ist die \emph{Gromov-Hausdorff-Distanz} definiert als
		\begin{equation}
		d_{\mathcal{G}\mathcal{H}}(X,Y) = \frac{1}{2}\inf_{R} \sup_{(x,y),(x',y') \in R}{|d_X(x,x')- d_Y(y,y')|}, \label{eq:gh}
		\end{equation}
		wobei $R$ über ganz $\mathcal{R}(X,Y)$ reicht.
	\end{definition}
	
	Sei nun $p\geq 1$. Für zwei metrische Maßräume $(X,d_X,\mu_X)$ und $(Y,d_Y,\mu_Y)$ betrachten die Funktion 
	\begin{equation}
	L(x,y,x',y') = |d_X(x,x') - d_Y(y,y')|
	\end{equation}
	und definieren die Gromov-Wasserstein-Distanz der Ordnung $p$ \cite{memoli2011gromov}:
	\begin{equation}
	d_{\mathcal{GW},p}(\mu_X,\mu_Y):=\left(\inf_{\mu \in \Pi(\mu_X, \mu_Y)} {J_p(\pi)}\right)^{1/p},
	\end{equation}
	wobei
	\begin{equation}
	J_p(\pi) := \int\limits_{X\times Y \times  X\times Y}{L(x,y,x',y')^pd\pi(x,y)d\pi(x',y'))}
	\end{equation}
	gilt.
	
	\begin{remark}
		Mit dieser Definition erhalten wir nun eine relaxierte $L^p$-Version der Gromov-Hausdorff-Distanz \autoref{eq:gh}
	\end{remark}
	Die Gromov-Wasserstein Distanz definiert eine Metrik auf dem Raum aller metrischen Räume $\mathcal{M}^{iso}$. 
	Mit dieser Definition wir der Vergleich von Maßen über unterschiedlichen Grundräumen möglich und damit auch ein Vergleich von Objekten jeglicher Art.
	
	\begin{figure}[h]
		\begin{center}
			\includegraphics[width=0.3\textheight]{gwd_Transportplan.png}
			\caption[Beispiel der Gromov-Wasserstein-Distanz]{\textbf{Links:} Die beiden metrischen Maßräume $X$ und $Y$. \textbf{Rechts:} Zugehöriger Transportplan}
		\end{center}
	\end{figure}
	
	Wir zitieren einige Eigenschaften der Gromov-Wasserstein-Distanz:
	
	\begin{theorem}\cite[Thm. 5.1]{memoli2011gromov} Sei $p \in [1, \infty]$ Dann gilt:
		\begin{itemize}
			\item[(a)] $d_{\mathcal{GW},p}$ definiert eine Metrik auf der Menge aller Isomorphieklassen von metrischen Maßräumen. 
			\item[(b)] (Was passiert im Fall zweier Wahrscheinlichkeitsmaße auf demselben Raum?) Sei $(Z,d)$ ein kompakter metrischer Raum und $\alpha$ und $\beta$ zwei verschiedene Borel-Maße auf $Z$. Sei $X=(Z,d,\alpha)$ und $Y=(Z,d,\beta)$. Dann gilt
			\begin{equation}
			d_{\mathcal{GW},p}(X,Y) \leq d_{\mathcal{W},p}^Z(\alpha,\beta).
			\end{equation}
		\end{itemize}
		
	\end{theorem}
	
Dieses Theorem zeigt nun, dass wir mit der Gromov-Wasserstein-Distanz einen Distanzbegriff erhalten, der invariant gegenüber Rotationen, Translationen und Permutationen ist\cite{vayer2020contribution}. \\

Aufgrund genau dieser Inavrianz vermuten wir, dass sich dieser Distanzbegriff deutlich besser als eine Pixel-weise $L_2$-Distanz für ein Clustering auf der Grundlage von Heatmaps ist. Diese Invarianz resultiert daraus, dass wir eine Metrik auf den Isomorphie-Klassen metrischer Maßräume betrachten.\\

Im Folgenden werden wir die numerischen Verfahren zu Bestimmung der Gromov-Wasserstein-Distanz behandeln. Auch hier ermöglicht eine Entropie-regularisierte Version die einfache Berechnung einer Approximation wie im Fall der Wasserstein-Distanz.\\
	
Wir betrachten dazu wieder die diskreten Wahrscheinlichkeitsmaße $\mu = \sum_{i=1}^n{a_i\delta_{x_i}},$ $\nu = \sum_{j=1}^m{b_j\delta_{y_j}}$ auf den Räumen $(X,d_X)$ bzw. $(Y,d_Y)$. Mit $\boldsymbol{C}_1$ und $\boldsymbol{C}_2$ bezeichnen wir die Distanzmatrizen der paarweisen Distanzen aller Punkte innerhalb des entsprechenden Raumes, d.h. es gilt $\forall (i,k) \in \lbrace 1,...,n \rbrace^2 : C_1(i,k) = d_X(x_i,x_k)$ und	$\forall (j,l) \in \lbrace 1,...,m \rbrace^2 : C_1(j,l) = d_Y(x_j,x_l)$. Damit lautet das Gromov-Wasserstein-Problem im diskreten Fall:
	
	\begin{align}
		GW_p^p(\boldsymbol{C}_1, \boldsymbol{C}_2,\boldsymbol{a},\boldsymbol{b}) &= \min_{\pi \in \Pi(\boldsymbol{a}, \boldsymbol{b})}\sum_{i,j,k,l}{|C_1(i,k)- C_2(j,l)|\pi_{i,j}\pi_{k,l}}\\
		&=\min_{\pi \in \Pi(\boldsymbol{a}, \boldsymbol{b})} \langle \boldsymbol{L}(\boldsymbol{C}_1, \boldsymbol{C}_2)^p \otimes \boldsymbol{\pi}, \boldsymbol{\pi}\rangle_\mathcal{F},\label{eq:GW-Problem}
	\end{align}
	
	wobei $\langle .,.\rangle_\mathcal{F}$ das Matrix-Produkt $\langle \boldsymbol{P}, \boldsymbol{Q} \rangle_\mathcal{F}  = tr(\boldsymbol{Q}^\top\boldsymbol{P})$ bezeichnet und $\boldsymbol{L}(\boldsymbol{C}_1, \boldsymbol{C}_2) = (|C_1(i,k)-C_2(j,l)|)_{i,j,k,l}$ und $\otimes$ die Tensor-Matrix-Multiplikation \autoref{eq:tensor_matrix_mul} ist.
	
	\autoref{eq:GW-Problem} ist ein nicht-konvexes quadratisches Optimierungsproblem, das im Allgemeinen NP-schwierig zu lösen und ebenfalls schwer zu approximieren ist.
	
	Für $p=2$ und damit $\boldsymbol{L}=|\cdot|^2$ können wir \autoref{eq:GW-Problem} schreiben als:
	
	\begin{equation}
	\min_{\pi \in \Pi(\boldsymbol{a}, \boldsymbol{b})}{tr(\boldsymbol{c}_{\boldsymbol{C}_1,  \boldsymbol{C}_2}\pi^\top) - 2 tr(\boldsymbol{C}_1\boldsymbol{\pi}\boldsymbol{C}_2\boldsymbol{\pi}^\top)},
	\end{equation}
	wobei $\boldsymbol{c}_{\boldsymbol{C}_1,  \boldsymbol{C}_2}:= f_1(C)a \boldsymbol{1}_{N_2}^T + \boldsymbol{1}_{N_1}b^Tf_2(\bar{C})^T$ unabhängig von $\boldsymbol{\pi}$ ist.	
	In Standardform erhalten wir
	
	\begin{equation}
	\min_{\pi \in \Pi(\boldsymbol{a}, \boldsymbol{b})}{\boldsymbol{c}^\top \boldsymbol{x}(\boldsymbol{\pi}) + \frac{1}{2}\boldsymbol{x}(\boldsymbol{\pi})^\top \boldsymbol{Q}\boldsymbol{x}(\boldsymbol{\pi})},	 \label{eq:GW_p2}		
	\end{equation}
	wobei $\boldsymbol{x}(\boldsymbol{\pi}) = vec(\boldsymbol{\pi}), \boldsymbol{c}= vec(\boldsymbol{c}_{\boldsymbol{C}_1, \boldsymbol{C}_2})$ und $\boldsymbol{Q} = -4 \boldsymbol{C}_1 \otimes_K \boldsymbol{C}_2$ und $\otimes_K$ das Kronecker-Matrix-Produkt für $\boldsymbol{A} \in \mathbb{R}^{n\times m}, \boldsymbol{B} \in \mathbb{R}^{p\times q}, \boldsymbol{A}\otimes_K \boldsymbol{B} \in \mathbb{R}^{np \times mq}$ mit $\boldsymbol{A} \otimes_K \boldsymbol{B} = (A_{i,j}\boldsymbol{B})_{i,j}$ gilt. \\
	
	\autoref{eq:GW_p2} ist ein nicht konvexes quadratisches Optimierungsproblem, da die Hesse-Matrix $\boldsymbol{Q}$ im Allgemeinen nicht positiv semi-definit ist (die Eigenwerte sind die Produkte der Eigenwerte der Matrizen $\boldsymbol{C}_1$ und $\boldsymbol{C}_2)$.\\
	
	%TODO: Erklärung der KL-Divergenz:
	%\url{http://people.csail.mit.edu/jsolomon/assets/gw.pdf}
	
	Verwenden wir nun auch hier einen Regularisierungs-Term basierend auf der Entropie erhalten wir das folgende Optimierungsproblem:
	
	\begin{equation}
	\min_{\pi \in \Pi (\alpha , \beta)}{\langle \boldsymbol{L}(\boldsymbol{C}_1, \boldsymbol{C}_2)^p \otimes \boldsymbol{\pi}, \boldsymbol{\pi} \rangle_\mathcal{F} - \varepsilon H(\boldsymbol{\pi})}. \label{eq:GWprob_regularised2}
	\end{equation}
	
	Dieses nicht-konvexe Optimierungsproblem können wir mithilfe eines projektiven Gradienten-Verfahrens lösen, bei dem sowohl für den Gradienten-Schritt als auch die Projektion die KL-Divergenz verwendet wird.\\
	
	\begin{comment}
	
	
	\begin{definition}[Divergenz]
	Sei $S$ der Raum aller Wahrscheinlichkeitsverteilungen mit gemeinsamem Support. Dann bezeichnet die Divergenz auf $S$ eine Funktion $D(\cdot || \cdot):S \times S \to \mathbb{R}$, für die gilt:
	\begin{enumerate}
	\item $D(p || q) \geq 0$ f.a. $p,q \in S$\\
	\item $D(p || q) = 0$ gdw. $p = q$.
	\end{enumerate}
	\end{definition}
	\end{comment}
	
	
	%egin{definition}[Entropie]
	%	Für $T \in \mathbb{R}_{+}^{N \times N}$ definieren wir die Entropie als
%		\begin{equation}
%		H(T) := - \sum_{i,j=1}^N{T_{i,j}(log(T_{i,j})-1)}.
%		\end{equation}
%	\end{definition}
	
	%Warum wir GW-Distanz brauchen
	%\url{https://arxiv.org/pdf/1811.02834.pdf}
	
	\begin{comment}

	Der Vergleich zwischen Ähnlichkeits- bzw. Distanzmatrizen ist schwierig, da diese die innere Struktur eines Datensatzes beschreiben, die unabhängig von Rotationen und Translationen ist. Es existiert keine kanonische Ordnung der Reihen und Spalten.
	Verallgemeinerung auf beliebige  Matrizen C, d.h. diese Distanzmatrizen müssen nicht notwendigerweise positiv sein und die Dreiecksungleichung erfüllen.
			content...
	\end{comment}
	
	
	\noindent Häufig verwendete Fehlerfunktionen sind die quadratische Fehlerfunktion $L(a,b) = L_2(a,b) := \frac{1}{2}|a-b|^2$ und die Kullback-Leibler-Divergenz $L(a,b)  = KL(a|b) := a\log(a/b) -a+b$.\\
	
	Diese Definition der Gromov-Wasserstein-Distanz verallgemeinert die Version in \cite{gwd_averaging_kernels}, da nun beliebige Fehlerfunktionen betrachtet werden.\\
	
	
	
	Mit der folgenden Proposition ergibt sich eine effizientere Berechnung von $\mathcal{L} (C, \bar{C}) \otimes T$ in \autoref{eq:GWprob_regularised2} für eine bestimmte Klasse von Fehlerfunktionen $L$:
	
	\begin{proposition}\label{prop:loss_reformulated}
		Die Fehlerfunktion $L$ lasse sich schreiben als 
		\begin{equation}
		L(a,b) = f_1(a) + f_2(b) - h_1(a)h_2(b) \label{eq:L_darstellung}
		\end{equation}
		für $f_1, f_2,h_1, h_2:\mathbb{R} \to \mathbb{R}$. Dann gilt für $T \in \Pi (p,q)$:
		\begin{equation}
		\mathcal{L} (C, \bar{C}) \otimes T = c_{C_1, C_2} - h_1(C)Th_2(\bar{C})^T. \label{eq:berechnung_tensorprodukt}
		\end{equation}
	\end{proposition} 

	
	
	\begin{comment}
		\begin{proof}
	Aufgrund von \autoref{eq:L_darstellung} gilt nach der Tensor-Matrix-Multiplikation \autoref{eq:tensor_matrix_mul}
	die Zerlegung $\mathcal{L} (C, \bar{C}) \otimes T = A + B + C$ mit
	
	\begin{align*}
	A_{i,j} &= \sum_k{f_1(C_{i,k})} \sum_l{T_{k,l}} = (f_1(C)(T\boldsymbol{1}))_i, \\
	B_{i,j} &= \sum_l{f_2(\bar{C}_{j,l})} \sum_k{T_{k,l}} = (f_2(\bar{C})(T^\top\boldsymbol{1}))_j,\\
	C_{i,j} &= \sum_k{h_1(C_{i,k})} \sum_l{h_2(\bar{C}_{j,l})T_{k,l}}.
	\end{align*}
	Dies ist äquivalent zu $(h_1(C))(h_1(\bar{C}T^\top)^\top)_{i,j}.$\\
	(? Wie folgt daraus die Behauptung)
	\end{proof}
	\end{comment}

	
	\begin{remark}[Verbesserte Komplexität]
		Mit dem Resultat in \autoref{prop:loss_reformulated} können wir $\mathcal{L} (C,\bar{C}) \otimes T$ effizient in der Größenordnung $\mathcal{O}(N_1^2N_2 + N_2^2N_1)$ mit ausschließlich Matrix/Matrix-Multiplikationen berechnen im Unterschied zur Komplexität von $\mathcal{O}(N_1^2N_2^2)$ für die Implementierung von \autoref{eq:tensor_matrix_mul}.
	\end{remark}
	
	\begin{remark}[Spezialfälle]
		Im Fall $L=L_2$ ist die Bedingung \autoref{eq:L_darstellung} für die Funktionen $f_1(a) = a^2, f_2(b) = b^2, h_1(a) = a$ und $h_2(b) = 2b$ erfüllt.
		Für $L=KL$ sind die Funktionen $f_1(a) = a \log (a) -a, f_2(b) = b, h_1(a) =a $ und $h_2(b) = \log (b)$ notwendig.
	\end{remark}
	
	
	%Wir betrachten nun die regularisierte Version der Gromow-Wasserstein-Diskrepanz \ref{GWD_definition} und definieren:
	
	
	
	Wir erhalten damit ein nicht-konvexes Optimierungsproblem. Für dessen Lösung benutzen wir ein projiziertes Gradienten-Verfahren, bei dem sowohl die Schrittweite als auch die Projektion bezüglich der KL-Metrik berechnet werden.\\
	
	Die Iterationen sind gegeben durch
	\begin{equation}
	T \leftarrow Proj_{\Pi(p,q)}^{KL} \left(T \odot e^{-\tau( \nabla \boldsymbol{\varepsilon}_{C, \bar{C}}(T) -\varepsilon H(T))} \right), \label{iteration_projection}
	\end{equation}
	wobei die Schrittweite $\tau > 0$ und die KL-Projektion einer beliebigen Matrix $K$ gegeben ist durch:
	\begin{equation}
	Proj_{\Pi(p,q)}^{KL}(K) := \argmin_{T \in \Pi (p,q)} KL(T'|K).
	\end{equation}
	
	\begin{proposition} \label{prop:iteration_GW_eps}
		Für den Fall $\tau= 1/\varepsilon$ erhalten wir die Iterationsvorschrift
		\begin{equation}
		T \leftarrow L_{\mathcal{L} (C, \bar{C}) \otimes T}(p,q). \label{simple_iteration}
		\end{equation}
		
	
	\end{proposition}
	% TODO: Hier in Prop 2kommt wohl noch der Faktor 2 rein: vgl. POT Implementerung
	\begin{proof}
		Nach \cite{iterative_bregman_projections} ist die Projektion in \ref{iteration_projection} gegeben durch die Lösung des regularisierten Transportproblems \ref{eq:reg_problem} und lässt sich damit schreiben als:
		\begin{equation}
		Proj_{\Pi(a,b)}^{KL}(K) = L_{\mathcal{L} (C, \bar{C}) \otimes T}(p,q)
		\end{equation}
		
		Es gilt außerdem
		\begin{equation}
		\nabla \boldsymbol{\varepsilon}_{C, \bar{C}}(T) -\varepsilon H(T) = \mathcal{L}(C,\bar{C}) \otimes T + \varepsilon\log (T).
		\end{equation}
		Durch Umordnen der Terme in \autoref{iteration_projection} erhalten wir für $\tau \varepsilon = 1$ die angegebene Vorschrift.
	\end{proof}
	
	\begin{remark}
		Die Iterationsvorschrift \ref{simple_iteration} definiert einen einfachen Algorithmus, der in jedem Update von $T$ eine Sinkhorn-Projektion benötigt.
	\end{remark}
	\begin{comment}
	
	\begin{remark}[Konvergenz]
		Die Iterationen \autoref{iteration_projection} konvergieren nach \cite{boct2016inertial} für $\tau < \tau_{max}$. Im Allgemeinen gilt $1/\varepsilon < \tau_{max}$ jedoch nicht, womit die Wahl der Schrittweite $\tau = 1 $ in \autoref{prop:iteration_GW_eps} nicht durch die Theorie abgedeckt ist. Laut \cite{gwd_averaging_kernels} konvergiert die Iteration mit $\tau = 1/\varepsilon$ jedoch in der Praxis.\\
		Für den Fall $L=L_2$ ergibt sich der \textit{Softassign quadratic assignment algorithm} \cite{rangarajan1999convergence}, für welchen ein Konvergenzresultat im Fall eines konvexen Problems existiert. Da wir in unserem Fall nur positive symmetrische Matrizen $C,C_s$ betrachten ist hier die Konvergenz gesichert.
	\end{remark}
		content...
	\end{comment}
	
	
	\begin{remark}
		Für gewöhnlich wählt man die Schrittweite $ \tau$ im Gradientenverfahren nicht zu groß, um die Konvergenz des Verfahrens zu erhalten. Da die Schrittweite $\tau$ hier jedoch antiproportional zum Regularisierungs-Parameter $\varepsilon$ ist, gibt es einen Trade-off zwischen der Konvergenz des Verfahrens und einer Unschärfe in der optimalen Lösung. 
	\end{remark}
	
	\begin{remark}[Wahl von $\varepsilon$]
		In \cite{cuturi2013sinkhorn} werden verschiedene Werte für $\varepsilon$ angegeben. Diese sind $\varepsilon = 0.02, 0.1, 1.0$ Im zugehörigen Beispiel\footnote{\url{https://pythonot.github.io/auto_examples/gromov/plot_gromov.html}} von POT wird $\varepsilon = 0.0005$ verwendet. \\
		Für $\varepsilon$ klein werden die Ergebnisse besser während der Rechenaufwand steigt.\\
		welche Resultate existieren bezüglich der Approximationsgüte abhängig von $\varepsilon$?
	\end{remark}
	\subsubsection{Gromov-Wasserstein Baryzentren}
	In diesem Kapitel wollen wir uns mit dem "Mittelwert" befassen, der elementar für das kmeans-Clustering ist.
	Auch hier soll der Mittelwert auf die abstrakte Ebene von gewichteten Distanzmatrizen angehoben werden.
	Dazu definieren wir im Folgenden sogenannte Wasserstein-Baryzentren und folgen \cite{gwd_averaging_kernels} für die Lösung des entstehenden Optimierungsproblems.
	Gute Einführung\footnote{\url{https://hal.archives-ouvertes.fr/hal-00637399/document}}
	\begin{definition}[Gromov-Wasserstein Baryzentrum]
		Seien die gewichteten Distanzmatrizen $C_s)_{s=1}^S$, mit $C_s \in \mathbb{R}^{N_s \times N_s}$ und den zugehörigen Histogrammen $(p_s)_s$ gegeben.
		
		Dann ist das Gromov-Wasserstein Baryzentrum definiert durch
		
		\begin{equation}
		\min_{C \in \mathbb{R}^{N \times N}} \sum_s{\lambda_s GW_{\varepsilon}(C,C_s,p,p_s)}. \label{eq:bary_prob}
		\end{equation}
	\end{definition}
	
	Existenz und Eindeutigkeit von Baryzentren: siehe \cite{bary_wasserstein_space}.
	
	\begin{remark}[Darstellung des Baryzentrums]
		Um das berechnete Bary-Zentrum $C$ wieder zu visualisieren, kann $C$ als Distanzmatrix wieder in den zweidimensionalen Raum eingebettet werden. Dies kann beispielsweise durch Multi-dimensionale Skalierung erreicht werden\footnote{\url{https://pythonot.github.io/auto_examples/gromov/plot_gromov_barycenter.html}}.  
		
	\end{remark}
	
	\begin{remark}
		Wir gehen im Folgenden davon aus, dass sowohl die Histogramme $(p_s)_s$ als auch das Histogramm $p$ bekannt sind. Die Größe $(N,N)$ des gesuchten Bary-Zentrums muss ebenfalls vorher festgelegt werden.
		Eine Erweiterung auf den Fall, dass auch $p$ unbekannt sein sollte und damit als Optimierungsparameter aufgefasst wird, ist leicht möglich \cite{gwd_averaging_kernels}.
	\end{remark}
	
	Wir können das Bary-Zentrum mithilfe von Kopplungen umformulieren als
	
	\begin{equation}
	\min_{C,(T_s)_s}{\sum_s{\lambda_s(\varepsilon_{C,C_s}(T_s) - \varepsilon H(T_s))}}, \label{eq:bary_prob_reformulated} 
	\end{equation}
	unter den Nebenbedingungen: $ \forall s: T_s \in \mathcal{C}_{p,p_s} \subset \mathbb{R}_{+}^{N \times N_s}$.
	Für den Fall, dass $L$ bezüglich der ersten Variable konvex ist, ist dieses Problem konvex bezüglich $C$. Bezüglich $(T_s)_s$ ist diese Problem quadratisch aber nicht notwendigerweise positiv.
	
	Das Problem \autoref{eq:bary_prob_reformulated} kann durch eine Block-Koordinaten-Relaxierung gelöst werden. Dabei wird iterativ abwechselnd bezüglich den Kopplungen $(T_s)_s$ und der Metrik $C$ miminiert.\\
	
	\noindent \textbf{Minimierung bezüglich $(T_s)_s$.}
	Anhand der Umformulierung \autoref{eq:bary_prob_reformulated} sehen wir, dass das Optimierungsproblem \autoref{eq:bary_prob} bezüglich $(T_s)_s$ in $S$ (?viele) unabhängige $GW_\varepsilon$-Optimierungen
	\begin{equation}
	\forall s : \min_{T_s \in \mathcal{C}_{p, p_s}}{\mathcal{E}_{C,C_s}(T_s)- \varepsilon H(T_s)}
	\end{equation}
	zerfällt, die jeweils wie in \autoref{prop:iteration_GW_eps} angegeben gelöst werden können.\\
	
	\noindent \textbf{Minimierung bezüglich $C$.} Sei $(T_s)$ gegeben. Dann lautet, die Minimierung bezüglich $C$:
	
	\begin{equation}
	\min_C \sum_s{\lambda_s \langle \mathcal{L}(C,C_s) \otimes T,T \rangle}. \label{eq:minimierung_C}
	\end{equation}
	Mit der folgenden Proposition erhalten wir für eine Klasse von Verlustfunktionen $L$ eine Lösung in geschlossener Form.
	
	
	\begin{proposition}
		Sei $L$ eine Fehlerfunktion, die die Bedingung \autoref{eq:L_darstellung} erfüllt. Sei $f_1'/h_1'$ invertierbar. \\
		Dann lässt sich die Lösung zu \autoref{eq:minimierung_C} schreiben als:
		
		\begin{equation}
		C = \left(\frac{f_1'}{h_1'}\right)^{-1} \left(\frac{\sum_s{\lambda_s T_s^\top h_2(C_s)T_s}}{pp^\top}\right),
		\label{eq:sol_bary}
		\end{equation}
		wobei die Normalisierung $\lambda_s = 1$ gilt.
	\end{proposition}
	\begin{proof}
		Nach \autoref{prop:loss_reformulated} können wir das zu minimierende Funtional schreiben als
		
		\begin{equation}
		\sum_s{\lambda_s \langle f_1(C)p\boldsymbol{1}^\top + \boldsymbol{1}p_s^\top f_2(C_s) - h_1(C)T_s h_2(C_s)^\top , T_s \rangle}.
		\end{equation}
		Die Optimalitätsbedingung erster Ordnung lautet folglich 
		\begin{equation}
		f_1'(C) \odot pp^\top = h_1'(C) \odot \sum_s{\lambda_s T_sh_2(C_s)T_s^\top}.
		\end{equation}
		Durh Umstellen der Gleichung erhalten wir die angegebene Form.
	\end{proof}
	Anhand von \autoref{eq:sol_bary} wird die folgende Interpretation deutlich/möglich: Für jedes $s \in S$ ist $T_s^\top h_2(C_s)T_s$ eine wiedereingeordnete Matrix, wobei $T_s$ als Optimal Transport-Kopplung von Zeilen und Spalten der Distanzmatrix $C_s$ fungiert. Über diese Matrizen wird anschließend gemittelt, wobei die Art der Mittelung von der fehlerfunktion $L$ abhängig ist.
	
	Für den Fall $L=L_2$ wird aus dem Update \autoref{eq:sol_bary} die folgende Vorschrift:
	
	\begin{equation}
	C \leftarrow \frac{1}{pp^\top}\sum_s{\lambda_s T_s^\top C_s T_s}. \label{eq:update_forL=L2}
	\end{equation}
	
	\begin{proposition}
		Sei $L=L_2$ und $(C_s)_s$ positiv semi-definit f.a. $s \in S$. Dann sind die Iterierten C ebenfalls positiv semi-definit. 
	\end{proposition}
	\begin{proof}
		\autoref{eq:update_forL=L2} zeigt, dass das Update aus einer Bildung des Mittelwertes der Matrizen $(diag(1/p)T_s^\top C_s T_s diag(1/p))_s$ besteht. Diese sind alle positiv semi-definit, da die $(C_s)_s$ nach Voraussetzung positiv semi-definit sind.
	\end{proof}
	Für den Fall $L = KL$ ergibt sich die folgende Verfahrensvorschrift:
	
	\begin{equation}
	C \leftarrow \left(\frac{1}{pp^\top}\sum_s{\lambda_s T_s^\top log(C_s)T_s}\right).
	\end{equation}
	\begin{algorithm}
		\hspace*{\algorithmicindent} \textbf{Input: } $(C_s,p_s), p.$ \newline
		\hspace*{\algorithmicindent} \textbf{Output: } $C$. 
		\caption{Berechnung der $GW_{\varepsilon}$-Baryzentren}
		\label{alg:GWB_computation}
		\begin{algorithmic}
			\STATE{Initialize $C$.} 
			\REPEAT 
			\STATE// Minimize over $(T_s)_s$
			\FOR{$s=1$ \textbf{to }S}
			\STATE Initialize $T_s$.
			\REPEAT
			\STATE // Compute $c_s = \mathcal{L}(C,C_s)\otimes T_s$ using \autoref*{eq:berechnung_tensorprodukt}
			\STATE $c_s \leftarrow f_1(C) + f_2(C_s)^\top -h_1(C)T_sh_2(C_s)^\top$
			\STATE // Sinkhorn iterations to compute $\mathcal{T}(c_s,p,q)$
			\STATE Initialize $a \leftarrow \boldsymbol{1}$, set $K \leftarrow e^{-c_s/\varepsilon}.$
			\REPEAT 
			\STATE $a \leftarrow \frac{p}{Kb}, b \leftarrow  \frac{q}{K^\top a}.$
			\UNTIL{convergence}
			\STATE $T_s \leftarrow diag(a)Kdiag(b).$
			\UNTIL{convergence}
			\ENDFOR 
			\STATE // Minimize over C 
			\STATE $C \leftarrow \left( \frac{f_1'}{h_1'} \right)^{-1}\left( \frac{\sum_s{\lambda_sT_s^\top h_2(C_s)T_s}}{pp^\top} \right)$ 
			\UNTIL{convergence}
		\end{algorithmic}
	\end{algorithm}
	
	\noindent \textbf{Psuedocode.}
	In \autoref{alg:GWB_computation} ist die Berechnung der Bary-Zentren in Pesudocode angegeben. Dabei wird abwechselnd über $T_s$ und $C$ minimiert. Für die Minimierung über $T_s$ wird ein projektives Gradienten-Verfahren verwendet, bei dem der Sinkhorn-Algorithmus \autoref{alg:sinkhorn} für die Berechnung der Projektion benutzt wird.

	
	
	
	\subsubsection{Komplexitätsanalyse}
	
	
	\subsubsection{Implementierung}
	
	Für die Berechnung der entropisch regularisierten Gromov-Wasserstein-Distanz verwenden wir die \textit{Python Optimal Transport Toolbox} (POT). Diese befindet sich noch in laufender Entwicklung und wir verwenden Version 0.7.0. 
	
	\begin{algorithm}
		\hspace*{\algorithmicindent} \textbf{Input: } $\boldsymbol{a}, \boldsymbol{b}, \boldsymbol{C}, \varepsilon > 0$		\newline
		\hspace*{\algorithmicindent} \textbf{Output: } Optimal Coupling $P^*$. 
		
		\caption{Sinkhorn-Algorithmus}
		\label{alg:sinkhorn}
		\begin{algorithmic}
			\STATE{Initialize $\boldsymbol{u}^{(0)}, \boldsymbol{v}^{(0)} = \boldsymbol{1}, \boldsymbol{K}= exp(-\frac{\boldsymbol{C}}{\varepsilon}).$}
			\REPEAT
			\STATE{$\boldsymbol{u}^{(i)} = \boldsymbol{a} \oslash \boldsymbol{K}^\top \boldsymbol{v}^{(i-1)}$}
			\STATE{$\boldsymbol{v}^{(i)} = \boldsymbol{b} \oslash \boldsymbol{K} \boldsymbol{u}^{(i-1)}$}
			\UNTIL{convergence}
		\end{algorithmic}	
	\end{algorithm}
	
	Wir haben in diesem Kapitel gesehen, wie mithilfe des Wasserstein-Baryzentrums eine Art Mittelwert für Wahrscheinlichkeitsverteilungen definiert werden kann.\\
	
	Wir vefügen mit der diskreten p-Gromov-Wasserstein-Distanz nun also über einen Distanzbegriff zwischen zwei verschiedenen Heatmaps. Wir werden im Folgenden $p=2$ verwenden. 
	
	\section{Ergebnisse} \label{chapter_comparisons}
	
	In diesem Kapitel fassen wir die Ergebnisse der Detektion von Poisoning-Angriffen mithilfe des modifizierten Clusterings auf den Hetmaps zusammen. Dabei gehen wir auf die unterschiedlichen Arten von Poisoning-Angriffen ein und vergleichen die Detektion jeweils mit dem Activation Clustering.
	
	Zu Beginn geben wir das Clustering auf den Rohdaten als Referenzwert an.
	
	Wir konnten beobachten, dass die Qualität des angegriffenen Netzwerkes auf nicht korrumpierten Daten für alle durchgeführten Angriffe über 96 Prozent beträgt. Deshalb werden wir diese Kennzahl als Qualität des Angriffs nicht jeweils zusätzlich angeben.
	
	Die Qualität eines Angriffs, angegeben durch die Angriffserfolgsrate ist abhängig der Größe des Anteils an korrumpierten Daten innerhalb einer Klasse.
	
	\autoref{fig:aerspas3} zeigt, wie sich die Angriffserfolgsrate für verschiedene Werte zwischen 0.125 Prozent und 33 Prozent an korrumpierten Daten verhält. Es ist auffällig, dass die Angriffe bereits für alle Werte über 0.5 Prozent sehr gut funktionieren. Bei 0.25 Prozent korrumpierten Daten wird noch immer eine Angriffserfolgsrate von 85.07 Prozent erreicht.
	
	\begin{figure}
		\centering
		\includegraphics[width=0.7\linewidth]{AER_SPAs3.png}
		\caption{Angriffserfolgsrate für verschiedene prozentuale Anteile bei $s=3$.}
		\label{fig:aerspas3}
	\end{figure}
	
	
	\subsection{Clustering auf den Rohdaten}
	Für das Clustering auf den Rohdaten bei einem Anteil von $15$ Prozent und einer Stickergröße von $3 \times 3$ erhalten wir die \autoref{tab:clustering_raw} in dargestellten Werte unter Verwendung der L2-Distanz. Dazu werden die Bilder als Graustufenbild eingelesen und anschließend in der Dimension auf 10 reduziert.
	\begin{table}[ht]
		\begin{center}
			%\resizebox{\textwidth}{!}{	
				\begin{tabular}{c|c|c}
					& PCA & FastICA \\ \hline
					ACC	 & 	65.49 & 63.13 \\
					TPR		& 51.54 & 31.99 \\
					TNR	& 72.36 	&78.48 	 
				\end{tabular}
			%}	
				\caption[Auswertung des Clusterings auf den rohen Bilddaten]{Auswertung des Clusterings auf den rohen Bilddaten bei 33 Prozent korrumpierten Daten mit einem Sticker der Größe $3 \times 3$. Alle numerischen Werte sind in Prozent angegeben.}	
				\label{tab:clustering_raw}
			
			
		\end{center}
	\end{table}
	
	Für die folgenden Auswertungen werden wir nun die durch die LRP erzeugten Heatmaps benutzen. Damit wir Maße auf zwei verschiedenen metrischen Räumen vergleichen können, wählen wir zunächst diejenigen Pixel aus, die die ersten 99 Prozent der Gesamtmasse beinhalten.
	
	In \autoref{im:punktwolke} sind links zwei Heatmaps korrumpierter Bilder sowie rechts die Positionen der ausgewählten Pixel abgebildet. In der Auswahl auf der rechten Seite können wir sehen, dass eine kreisförmige Auswahl getroffen wird, die ungefähr den Verkehrsschildern entspricht.
	
	\begin{figure}[h]
		\begin{center}
			\includegraphics[width=0.5\textheight]{HeatmapPunktwolke99.png}
			\caption{Auswahl der relevantesten Pixel (bis zu $99\%$ der Gesamtmasse) zweier Heatmaps bei korrumpierten Bildern.}
		\end{center}
		\label{im:punktwolke}
	\end{figure}

	In \autoref{fig:result_specClusteringL2} können wir das Ergebnis des spektralen Clusterings zur Bestimmung der Clusteranzahl für das kMeans-Clustering sehen. Es zeigt sich ein Sprung nach den beiden ersten betragsminimalen Eigenwerten der Laplace-Matrix des Graphen. Hierbei wurde eine Kante zweischen zwei Knoten des Graphen gesetzt, falls ein Knoten zu den 10 nächst-gelegenen Knoten eines zweiten Knoten s gehört.
	
	
	\begin{figure}[h]
		\begin{center}
			\includegraphics[width=0.5\textheight]{specClustering_l2_k10.png}
			\caption{Ergebnis des spektralen Clusterings unter Verwendung der Euklidischen Distanz und k=10 Nachbarn}
			\label{fig:result_specClusteringL2}
		\end{center}
	\end{figure}
	
	\subsection{Standard Poisoning-Angriffe}
	 Für die Standard-Angriffe mittels des $3 \times 3$ Pixel großen Stickers zeigt sich, dass das Heatmap-Clustering für die korrumpierten Anteile von 5, 10, 15 und 33 Prozent mit einer Genauigkeit von über 99 Prozent funktioniert. Im Gegensatz dazu liegt die Genauigkeit beim Activation Clustering zwischen 57 und 95 Prozent, wobei der Fehler vor allem durch eine relativ schlechte Richtig-Negativ-Rate zustande kommt. D.h., dass hier trotz vieler Datenpunkte, die richtigerweise als korrumpierte erkannt werden, leider viele saubere Datenpunkte als korrumpiert deklariert werden.
	 
	 Für einen Anteil von 2 Prozent ist die Detektionsqualität beider Verfahren schlechter als das Clustering auf den Rohdaten und damit unbrauchbar. Die genauen Ergebnisse sind in \autoref{tab:SPA_def_inv3_gwclustering} aufgelistet.
	 \begin{table}[ht]
	 	\begin{center}
	 		\caption[Vergleich von Angriffen und Verteidigungen für SPA]{Qualität der Detektion unterschiedlich starker Angriffe mithilfe von LRP-Clustering und Gromov-Wasserstein-Distanzen. Die Seitenlänge des Stickers beträgt $s=3$.}
	 		\resizebox{\textwidth}{!}{
	 			
	 			
	 			\begin{tabular}{|c|c|ccc|ccc|}
	 				\hline
	 				Prozentualer 	& AER  		& 		&	Detektionsrate 		& 		& 		& Detektionsrate 	& 		  \\
	 				Anteil 		& 			& 		&	Heatmap Clustering 	& 		& 	&Activation Clustering	&		\\
	 				& 			& ACC 	& 	TPR 	& TNR  	& ACC 	& TPR 	& TNR 	 	\\\hline
	 				
	 				33.00			& 100.00	& \textbf{99.96}	& 99.88		& 100.00& 94.76 & 90.77 & 96.73 \\ 
	 				15.00			& 100.00	& \textbf{100.00}	& 100.00 	& 100.00& 76.51 & 99.31	&72.48 \\
	 				10.00			& 100.00 	& \textbf{99.29 }	& 92.9 		& 100.00& 87.62 & 96.17 & 86.17 \\
	 				5.00			& 100.00		& \textbf{99.48 }	& 90.8		& 99.94 & 57.92 & 20.69 & 59.88  \\
	 				2.00			& 100.00	& 52.85				& 0.0 		& 53.94	& \textbf{52.91} & 0.0 	& 54.0 \\ \hline	 				
	 				
	 				
	 				
	 				
	 		\end{tabular}}
	 		
	 		\label{tab:SPA_def_inv3_gwclustering}	
	 	\end{center}
	 \end{table}
 
	 Für die Stickergrößen $2\times 2$ und $1\times 1$ ergibt sich ein sehr ähnliches Verhalten, worauf wir in \autoref{unterschiedlicheStickergrößen} eingehen werden.
	 
	
	

	\begin{comment}
		\begin{remark}[Die Fälle mit einer AER unter 100 Prozent]
		Besonders interessant sind auch genau die Fälle, bei denen die Hintertür im Netzwerk so implementiert ist, dass nicht alle präsentierten korrumpierten samples gewollt falsch klassifiziert werden. Was erwarten wir hier von unserem Detektionsalgorithmus? Wenn wir das Gromov-Wasserstein-Clustering auf den Heatmaps durchführen, können wir ja nur die Informationen nutzn, die das Netzwerk über die LRP liefert. Diese ist aber schon fehlerhaft/mangelhaft. Vielleicht sollte man hier dann das Clustering wieder auf den rohen Bilddaten durchführen?  Welche Pixel nimmt man hier dann? Alle? Wichtig ist hier auch der Vergleich mit dem Clustering bezüglich der L2 Distanz auf den Eingabe Bilder.
		\end{remark}
		
	\end{comment}
	

	
	
	

	
	\begin{comment}
	
	
	\begin{figure}[h]
		\begin{center}
			\includegraphics[width=0.5\textheight]{HeatmapPunktwolke50.png}
			\caption{Auswahl der relevantesten Pixel (bis zu $50\%$ der Gesamtmasse) zweier Heatmaps}
		\end{center}
	\end{figure}
	
	\begin{figure}[h]
		\begin{center}
			\includegraphics[width=0.5\textheight]{bary_embedding99.png}
			\caption{Einbettung des Baryzentrums mithilfe von Multidimensionaler Skalierung(MDS) bei der Wahl von $99\%$ der Gesamtmasse}
		\end{center}
	\end{figure}
	\end{comment}
	
	\begin{comment}
	
	\begin{table}[ht]
		

		
		\begin{center}
			\begin{tabular}{|l|c|c|c|c|}
				\hline
				Seitenlänge des Triggers& Prozentualer Anteil & AER & GUD & num. korrumpierte Daten \\ \hline
				s=2 & 0.000625 & 0.01333333  & 0.962  & 1 \\
				& 0.00125 & 0.356  & 0.964  & 2 \\
				& 0.0025 & 0.576 & 0.97 & 4 \\
				& 0.005 & 0.99867 & 0.962 & 8 \\
				& 0.01 & 0.92 & 0.962 & 17 \\
				& 0.02 & 1.0 & 0.964 & 34\\ 
				& 0.10 & 1.0 & 0.968 & 291\\
				& 0.15 & 1.0 & 0.968 & 436 \\ 
				& 0.33 & 1.0 & 0.968 & 813 \\ \hline
				s=3 & ? & ? & ? &? \\
				& 0.00125 & 34.26 & 96.2 & 2\\
				& 0.0025 & 85.07 & 96.5 & 4\\
				& 0.005	&1.0&96.9& 8 \\ 
				& 0.01 & 1.0 & 0.962& 17 \\
				& 0.05 & 1.0 & 0.966 & 87 \\
				& 0.15 & 1.0 & 0.961& \\ \hline
				s=1 & 0.33 & 1.0 & 0.966 & 813 \\ \hline
			\end{tabular}
			\caption{Qualität der Angriffe auf das Inception v3-Netz mit Stickern Seitenlänge 2 und 3 Pixel bei unterschiedlich großen Anteilen an korrumpierten Daten}
			\label{tab:SPA_incv3}	
		\end{center}
	\end{table}	Inhalt...
	\end{comment}
	\begin{remark}
		Bei der Durchführung von Standard-Poisoning-Angriffen zeigt sich, dass auch für sehr kleine Anteile erfolgreiche Angriffe implementiert werden können. Beispielsweise konnten wir sogar bei einem Anteil von 0.5 Prozent (8 korrumpierte Bilder) noch eine Erfolgsrate von 99.87 Prozent erreichen. Bei 2 korrumpierten Bildern lag die Erfolgsrate bei 35.6 Prozent.
	\end{remark}
	
	\begin{remark}
		Für größere Netzwerke ist es einfacher, erfolgreiche Angriffe zu implementieren, auch schon mit weniger korrumpierten Daten.\\
		Vermutung: Die Detektion mittels Clustering funktioniert für eine größere Anzahl an korrumpierten Daten besser. Wenn wir also nur perfekte Angriffe verteidigen wollen, d.h AER=100.00 funktioniert das bei kleineren Netzwerken besser.
	\end{remark}
	\subsection{Label-konsistente Poisoning-Angriffe}
	\begin{comment}
	
	
	\begin{remark}
		Für einen einzelnen Amplitudensticker mit d=10 ist das eigentlich identisch zu dem Angriff mit dem Sticker
	\end{remark}

	
	\begin{figure}[h]
		\begin{center}
			\includegraphics[width=0.75\textheight]{Vergleich_AER_CLPA.png}
			\caption{Angriffserfolgsrate pro Klasse bei Clean-Label-Poisoning-Attacks für verschiedene Werte \textit{amp} des Amplitudenstickers in vierfacher Ausführung bei Abstand $d=10$ zum Rand}
			\label{fig:AER_proKlasse_CLPA}
		\end{center}
	\end{figure}
	
	In \autoref{fig:AER_proKlasse_CLPA} sind die Angriffserfolgsraten pro Klasse im Fall von $33 \%$ korrumpierten Daten und dem Amplitudensticker in jeder der 4 Bildecken mit dem Abstand von 10 Pixeln zum Rand dargestellt. In beiden Fällen geben wir keine AER für die Klasse 6 an, über die der Angriff stattfindet.
	Die mittlere Angriffserfolgsrate beträgt für $amp=255$ $79.15 \%$. In mehreren Klassen wird eine AER von $100 \%$ erreicht.\\
	Für $amp=64$ fällt der Angriff mit einer mAER von $48.17 \%$ deutlich schwächer aus. Die maximal erreichte AER beträgt $95.33 \%$ in Klasse 10. Die minimalen AER sind $25 \%$ bzw. $0.83 \% $.
	Eine weitere Reduktion der Amplitude auf $amp=32$ führt zu einer mAER von $6.55 \%$ und einer maximalen AER von $33 \%$.
	
	Für d=0, amplitude=64 und eps=1200 ergibt sich kein erfolgreicher Angriff, dabei war fast alles 0, die Trigger im Testdatensatz waren auch auf 64
	Jetzt für d=10, auch hier gilt amp=64 im Testdatensatz:Ergebnis:
	
	

	
	%\subsection{Auswertung der CLPA}
	\end{comment}
	In diesem Abschnitt vergleichen wir die Detektion der Label-konsistenten Poisoning-Angriffe- Wir verwenden dabei den grün-gelben $3\times 3$ großen Sticker, der nach einer Störung des Ausgangsbildes eingefügt wird.
	Interessant ist hierbei, dass die mittlerer Angriffserfolgsrate für alle prozentualen Anteile recht hoch ist. Für die Anteile 33,15,10 und 5 Prozent funktioniert die Detektion bei beiden Verfahren im Bezug auf die Genauigkeit (ACC) ähnlich gut, wobei die Richtig-Positv-Rate bis zu 12 Prozentpunkte höher liegt.
	Für 2 Prozent korrumpierte Daten funktioniert der Angriff mit einer mittleren Angriffsrate von 83.51 Prozent ähnlich gut wie die Angriffe mit höheren korrumpierten Anteilen, beide Detektionsverfahren erweisen sich jedoch als nutzlos.
	
	Die Ergebnisse sind in \autoref{tab:Ergebnisse_CLPA} dargestellt.
	
	
	\begin{table}[ht]
		\caption{Ergebnisse der Detektion von CLPA mit gelb-grünen Stickern bei verschiedenen Anteilen korrumpierter Daten für Heatmap-Clustering(HC) und Activation-Clustering(AC).}
		\begin{center}
			\resizebox{\textwidth}{!}{
				\begin{tabular}[h]{|c|c|ccc|ccc|} \hline
					Prozentualer&		&		& Detektionsrate (HC)	& 		& 		&Detektionsrate (AC)&		\\ 
					Anteil 	& mAER 	& ACC 	& TPR 					& TNR 	& ACC 	& TPR 				& TNR 	\\ \hline
					
					33 		& 90.98	& 99.58	& 98.71					&100.0	& 99.09 & 97.24 			& 100.0 \\
					15		& 83.15 & 98.91 & 96.69  				&100.0	& 96.42 & 89.15				& 100.0 \\
					10		& 90.45 & 99.82 & 98.18					&100.00 & 98.97 & 89.7				& 100.0 \\
					5		& 84.77 & 99.82 & 96.34					&100.00	& 99.09 & 84.15				& 99.87 \\
					2		& 83.51 & 55.33 & 100.00				& 54.42	& 56.3	& 100.00 			& 55.41 \\ \hline
				\end{tabular}	
				
				
			}
		\end{center}
		
		\label{tab:Ergebnisse_CLPA}
		
	\end{table}

	Bei 10 Prozent korrumpierten Daten erkennt das Heatmap-Clustering nur 3 anstatt 17 Punkten als Falsch-Negativ. Bei 5 Prozent gibt es nur 3 anstatt 13 Falsch-Negative.
	



	\begin{comment}
	
	Wir werten hier die Angriffe und Verteidigungen bei CLPA aus:\\
	
	Alle Rotationen: 33 Prozent korrumpierte Daten\\
	0.9        0.85416667 0.93066667 1.         0.9969697         nan
	1.         1.         1.         0.97083333 0.99393939 0.93333333
	0.74057971 0.95277778 0.98888889 0.83333333 0.99333333 0.725
	0.96666667 1.         0.94444444 0.97777778 0.95       0.98666667
	1.         0.90625    1.         1.         0.98       1.
	0.94       1.         1.         0.8        0.30833333 0.88717949
	0.75833333 0.98333333 0.81449275 0.37777778 1.         0.81666667
	1. 
	\\
	
	mAER:  90.98034373809526\\
	min:  30.833333000000003\\
	max  100.0\\
	
	AC:(tn, fp, fn, tp):  1106 0 15 529\\
	ACC: 99.09\\
	TPR:  97.24\\
	TNR:  100.0\\
	
	HC: (tn, fp, fn, tp): 1106,0,7,537\\
	acc: 99.58\\
	tpr: 98.71\\
	tnr: 100.0\\
	--------------------------------------------------------------------------------------------\\
	15 Prozent:\\
	0.85       0.77361111 0.88       1.         0.96212121        nan
	1.         0.97555556 1.         0.92708333 0.98030303 0.69761905
	0.68405797 0.8875     0.86666667 0.71428571 0.87333333 0.55555556
	0.85897436 0.9        0.93333333 0.77777778 0.81666667 0.86666667
	1.         0.78541667 0.84444444 1.         0.89333333 0.66666667
	0.84666667 1.         0.88333333 0.76666667 0.275      0.76666667
	0.6        0.95       0.64782609 0.33333333 1.         0.88333333
	1.       +0.5*width
	
	mAER:  83.15190128571427\\
	min:  27.500000000000004\\
	max:  100.0\\
	 
	(tn, fp, fn, tp):  1106 0 59 485\\
	ACC: 96.42\\
	TPR:  89.15\\
	TNR:  100.0\\
	
	(tn, fp, fn, tp): 1106,0,18,526\\
	acc: 98.91\\
	tpr: 96.69\\
	tnr: 100.0\\
	-------------------------------------------------------------------------------------\\
	10 Prozent:
	
	[1.         0.85138889 0.96533333 1.         1.                nan
	1.         0.99777778 1.         0.96875    0.98636364 0.87380952
	0.6826087  0.925      0.92962963 0.88571429 1.         0.69166667
	0.94102564 1.         0.97777778 0.86666667 0.94166667 1.
	1.         0.85833333 0.97222222 1.         0.92       1.
	0.88       1.         0.93333333 0.68571429 0.425      0.82820513
	0.73333333 1.         0.87391304 0.44444444 1.         0.95
	1.        ]
	
	
	mAER:  90.45161504761903\\
	min:  42.5\\
	max2:  100.0\\
	
	(tn, fp, fn, tp):  1485 0 17 148\\
	ACC: 98.97\\
	TPR:  89.7\\
	TNR:  100.0\\
	
	HC: (tn, fp, fn, tp): 1485,0,3,162\\
	acc: 99.82\\
	tpr: 98.18\\
	tnr: 100.0\\
	
	-------------------------------------------------------------------------------------\\
	5 Prozent:
	[0.93333333 0.85       0.89466667 1.         0.95757576        nan
	1.         0.99333333 1.         0.93541667 0.97575758 0.67380952
	0.55072464 0.88472222 0.85555556 0.67142857 0.86666667 0.52222222
	0.88974359 1.         0.93333333 0.86666667 0.825      0.89333333
	1.         0.80416667 0.87777778 1.         0.94666667 0.9
	0.9        1.         0.9        0.69047619 0.28333333 0.75384615
	0.725      1.         0.81014493 0.33333333 1.         0.75
	0.95555556]
	
	mAER:  84.77045302380954\\
	min:  28.333333\\
	max:  100.0\\
	
	(tn, fp, fn, tp):  1566 2 13 69\\
	ACC: 99.09\\
	TPR:  84.15\\
	TNR:  99.87\\
	
	
	(tn, fp, fn, tp): 1568,0,3,79\\
	acc: 99.82\\
	tpr: 96.34\\
	tnr: 100.0\\
	-------------------------------------------------------------\\
	
	2 Prozent:
	
	0.96666667 0.87222222 0.83866667 0.99777778 0.99090909        nan
	1.         1.         1.         0.875      0.70151515 0.51190476
	0.58550725 0.77777778 0.95555556 0.90952381 0.96666667 0.78055556
	0.90512821 0.91666667 0.8        0.68888889 0.81666667 0.76
	1.         0.5875     0.94444444 1.         0.94666667 0.97777778
	0.81333333 1.         0.9        0.59047619 0.4        0.85128205
	0.78333333 0.98333333 0.77681159 0.33333333 1.         0.7
	0.86666667
	
	mAER:  83.50609076190479
	min:  33.333332999999996
	max  100.0
	
	AC:(tn, fp, fn, tp):  896 721 0 33\\
	ACC: 56.3\\
	TPR:  100.0\\
	TNR:  55.41\\
	
	HC: (tn, fp, fn, tp): 880,737,0,33\\
	acc: 55.33\\
	tpr: 100.0\\
	tnr: 54.42\\
		
	\end{comment}
	
	\subsection{Detektion bei reduzierten Amplitudenstickern}
	
	
	\begin{figure}[!h]
		\begin{center}
			\includegraphics[width=\textwidth]{vergleich_CLPA_AER_amp.png}
			\caption{Angriffserfolgsrate pro Klasse bei Clean-Label-Poisoning-Attacks bei einem Amplitudensticker mit Abstand $d=10$ zum rechten unteren Ecke. Die Angriffserfolgsraten sind pro Klasse für die Amplitudenwerte $amp=128,64,32$ aufgetragen. Für die Klasse 5 über die der Angriff ausgeführt wurde, berechnen wir keine Erfolgsrate.}
			\label{fig:AER_proKlasse_CLPA_amp}
		\end{center}
	\end{figure}
	
	
	\begin{table}[!h]
		\caption{Ergebnisse der Detektion von CLPA mit reduzierten Stickern.}
		\begin{center}
			\resizebox{\textwidth}{!}{
				\begin{tabular}[h]{|c|c|ccc|ccc|}\hline
				&		&		& Detektionsrate (HC)	& 		& 		&Detektionsrate (AC)&		\\
				Amplitudenstärke 	& mAER 	& ACC 	& TPR 					& TNR 	& ACC 	& TPR 				& TNR 	\\ \hline
				
				128 				& 99.18	& 99.7	& 99.08					&100.0	& 99.45 & 98.35 			& 100.0 \\
				64					& 77.97 & 90.79 & 74.08 				&99.01	& 92.06 & 90.44				& 92.86 \\
				32					& 25.65 & 81.58 & 58.46					& 92.95 & 78.97 & 74.26				& 81.28 \\ \hline
				
			\end{tabular}	
				
				
			}
		\end{center}
	
		\label{tab:Ergebnisse_CLPA_reduced}
		
	\end{table}

Wir wollen in diesem Abschnitt noch einen Vergleich zwischen beiden Detektionsverfahren für einen Angriff mit einem reduzierten Amplitudensticker geben. Die einzelnen Ergebnisse sind in \autoref{tab:Ergebnisse_CLPA_reduced} gegeben. 

Der Unterschied beim Clustering im Fall $amp=128$ besteht darin, dass das Heatmap Clustering nur 5 anstatt 9 Datenpunkten als Falsch-Negativ klassifiziert.
	
	Wir sehen also, dass sowohl die Qualität der Angriffe als auch die Detektionsrate durch die Verwendung eines Amplitudenstickers mit kleinerer Amplitude abnimmt.
	
	Vergleichen wir die Ausgaben der LRP für die Werte $amp=64$ und $amp=32$, wird deutlich, dass die LRP den Sticker nicht mehr als die relevante Größe im Bild erkennt. Die Vermutung liegt nahe, dass dies also an der LRP liegen muss. Es ist jedoch so, dass das Netzwerk im Fall $amp=32$ bereits ein Viertel aller Auslöser nicht mehr erkennt. Ein Vergleich zweier Heatmaps findet sich in \autoref{fig:vergleich_heatmaps_red_Amplituden}
	
	\begin{figure}
		\centering
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.7\linewidth]{140_poison_CLPA_1sticker_amp32n5d10e-rule_heatmap.png}
			%\caption{Verkehrsschild der Klasse 'Höchstgeschwindigkeit: 50km/h' versehen mit einem 3x3 Sticker und dem Label 'Höchstgeschwindigkeit: 80km/h'}
			
		\end{subfigure}%
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.7\linewidth]{140_poison_CLPA_1sticker_amp64n5d10e-rule_heatmap.png}
			%\caption{Zugehörige Heatmap bezüglich der Klasse 'Höchstgeschwindigkeit: 80km/h'}
			
		\end{subfigure}
		\caption[Vergleich zweier Heatmaps mit Amplitudenstickern.]{\textbf{Links:} Heatmap eines korrumpierten Bildes bei der Verwendung eines Amplitudenstickers mit $amp=32$.  \textbf{Rechts:} Heatmap eines korrumpierten Bildes bei der Verwendung eines Amplitudenstickers mit $amp=64$.}
		
		
		\label{fig:vergleich_heatmaps_red_Amplituden}
	\end{figure}
	
	
	
	\begin{comment}
comment
	Wir erhalten die folgenden 
	BDSR classwise:
	[0.91666667 0.98055556 0.91466667 1.         1.                nan
	1.         1.         1.         0.99791667 1.         0.69285714
	1.         0.9875     1.         1.         1.         0.68055556
	0.98717949 0.83333333 0.86666667 0.65555556 0.64166667 0.80666667
	1.         0.83125    1.         1.         0.97333333 0.94444444
	0.91333333 1.         1.         0.74761905 0.56666667 0.84615385
	0.73333333 1.         0.79275362 0.33333333 1.         0.88333333
	1.        ]
	Performance of poisoned net on unpoisoned training data:
	loss on test dataset: 0.11639516854210974
	Accuracy on test Dataset: 0.977 
	
	===> Get activations.
	===> Segment data by labels.
	
	===> Reduce dimensionality.
	===> Cluster data.
	(1650,)
	1146
	(tn, fp, fn, tp):  1093 13 53 491
	ACC: 96.0
	TPR:  90.26
	TNR:  98.82
	
	
	(tn, fp, fn, tp):  1106 0 10 534
	ACC: 99.39
	TPR:  98.16
	TNR:  100.0
	
	--------------------------------------------------------------------
	Reduzierte Amplitude auf amp=128 bei d=10 ein Sticker
	BDSR classwise:
	
	[1.         1.         1.         1.         1.                nan
	1.         1.         1.         1.         1.         0.98809524
	1.         1.         1.         1.         1.         0.77777778
	1.         1.         0.98888889 0.9        1.         1.
	1.         1.         1.         1.         1.         1.
	1.         1.         1.         1.         1.         1.
	1.         1.         1.         1.         1.         1.
	1.        ]
	
	mAER:  99.17800454761904
	min:  77.777778
	max2  100.0
	
	Performance of poisoned net on unpoisoned training data:
	loss on test dataset: 0.19974493713244573
	Accuracy on test Dataset: 0.963 
	
	===> Get activations.
	===> Segment data by labels.

	Check only one class
	===> Reduce dimensionality.
	===> Cluster data.
	(1650,)
	535
	(tn, fp, fn, tp):  1106 0 9 535
	ACC: 99.45
	TPR:  98.35
	TNR:  100.0
	===> LRP started
	===> LRP finished
	
	HC: (tn, fp, fn, tp):  1106 0 5 539
	ACC: 99.7
	TPR:  99.08
	TNR:  100.0
	
	Jetzt noch mit n_steps=5 und amp=64:
	1.         0.98888889 0.996      1.         1.                nan
	0.98       1.         1.         0.975      0.93484848 0.62857143
	0.83768116 0.925      0.98148148 1.         0.90666667 0.45555556
	0.92307692 0.51666667 0.8        0.24444444 0.35833333 0.49333333
	0.93333333 0.81041667 0.99444444 0.93333333 0.95333333 1.
	0.82       0.54814815 1.         0.52857143 0.3        0.60512821
	0.51666667 0.38333333 0.54782609 0.32222222 0.63333333 0.98333333
	0.98888889]
	
	
	mAER:  77.97109788095237
	min4:  24.444444
	max24  100.0
	
	Performance of poisoned net on unpoisoned training data:
	loss on temAER:  25.647225690476198
	min:  0.0
	max2:  96.190476
	
	
	
	(tn, fp, fn, tp):  899 207 140 404
	ACC: 78.97
	TPR:  74.26
	TNR:  81.28
	
	HC: (tn, fp, fn, tp):  1028 78 226 318
	ACC: 81.58
	TPR:  58.46
	TNR:  92.95st dataset: 0.16618648792378718
	Accuracy on test Dataset: 0.965 
	
	===> Get activations.
	===> Segment data by labels.
	
	Check only one class
	===> Reduce dimensionality.
	===> Cluster data.
	(1650,)
	571
	(tn, fp, fn, tp):  1027 79 52 492
	ACC: 92.06
	TPR:  90.44
	TNR:  92.86
	
	HC: (tn, fp, fn, tp):  1095 11 141 403
	ACC: 90.79
	TPR:  74.08
	TNR:  99.01
	
	
	
	nsteps5, amp=32:
	0.73333333 0.73055556 0.70933333 0.67333333 0.43181818        nan
	0.54       0.42666667 0.46       0.18333333 0.03939394 0.05952381
	0.23768116 0.33888889 0.34814815 0.96190476 0.01333333 0.16388889
	0.28461538 0.01666667 0.25555556 0.12222222 0.025      0.05333333
	0.11111111 0.01666667 0.08333333 0.06666667 0.22666667 0.24444444
	0.00666667 0.15555556 0.25       0.17619048 0.26666667 0.22564103
	0.09166667 0.06666667 0.24202899 0.         0.25555556 0.1
	0.37777778
	
	mAER:  25.647225690476198
	min:  0.0
	max2:  96.190476
	
	
	
	(tn, fp, fn, tp):  899 207 140 404
	ACC: 78.97
	TPR:  74.26
	TNR:  81.28
	
	HC: (tn, fp, fn, tp):  1028 78 226 318
	ACC: 81.58
	TPR:  58.46
	TNR:  92.95
	\end{comment}
	
	\subsection{Zusammenfassung}
	
	\newpage       
	\subsection{Räumliche Transformationen}
	\begin{itemize}
		\item ASR ist sehr stark vom Ort des Triggers abhängig.
		\item Ort des Triggers kann nicht direkt geändert werden.
		\item Benutze Transformationen(Flipping, Scaling), um den Trigger wirkungslos zu machen.
		\item Somit kann die ASR während der Inferenz verringert werden. Es lässt sich aber keine Auussage darüber treffen, ob ein Angriff vorliegt
	\end{itemize}
	\newpage
	\section{Weitere mögliche Schritte} \label{chapter_weitereSchritte}
	\begin{itemize}
		\item Untersuchung der Detektionsqualität in Abhängigkeit von $\varepsilon$
		\item Automatische Platzierung des Auslösers an fest gewählter Position auf dem Verkehrsschild anstatt zufälligem Platzieren in einem Fenster mit vorher festgelegter Größe. In \cite{badnets} wird  Faster-RCNN (F-RCNN) zur Klassifikation des LISA-Datensatzes\footnote{\url{http://cvrr.ucsd.edu/LISA/lisa-traffic-sign-dataset.html}} benutzt. Es ist die Aufgabe, die Verkehrsschilder in die 3 Superklassen Stoppschild, Geschwindigkeitsbegrenzung und Warnschild einzuteilen. Der Datensatz enthält zudem die BoundingBoxen, sodass der Auslöser genauer angebracht werden kann.
		\item Verbesserte Version der Layer-wise Relevance Propagation
		\item Untersuchung anderer Verfahren, die die Interpretierbarkeit ermöglichen, beispielsweise: VisualBackProp: efficient visualization of CNNs\footnote{\url{https://arxiv.org/abs/1611.05418}}
		\item Vergleich mit Cifar-10/Cifar-100 Datensatz\footnote{\url{https://www.cs.toronto.edu/~kriz/cifar.html}}\footnote{\url{https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}}
	\end{itemize}
	
	
	\section{Zusammenfassung und Ausblick} \label{chapter_conclusion}
	Beobachtung: Je größer die Netzwerke sind, desto leichter lassen sich Poisoning-Angriffe realisieren.
	Angriffe mit AER <100 Prozent sehr schwierig zu erkennen.
	
	
	\newpage
	\newpage
	\appendix
	\section{Verwendete Netzwerke}
	Unser Netzwerk besitzt eine Testgenauigkeit von 97.8 Prozent.
	
	Aufbau dieses Netzwerkes:
	1. Inception-Modul
	2. [pool1, batchConv1, pool2, batchConv2, pool3, batchConv3, pool4]
	3. Drei Lineare Schichten mit ReLu und Dropout dazwischen
	
	Im Unterschied zum offiziellen Inception Netz(v1v2v3) gibt es in dieser 
	vereinfachten Version keinen "stem" aus convs, 
	es geht direkt mit InceptionA los.
	
	Wie ähnlich sind sich InceptionA(hier) und das offizielle InceptionA-Modul?
	
	
	\begin{figure}
		\centering
		
		\centering
		\includegraphics[width=.7\linewidth]{inceptionNet_layout.jpg}
		
		\caption{Struktur des verwendeten Inception-Netzwerkes}
		\source{\cite{goingdeeperwithconvolutions}}
		
		\label{im:inceptionv3layout}
	\end{figure}
	
	\section{Parameter für Training und Einlesen der Daten}\label{param_net}
	Die in \cite{CH} gewählten Parameter wären ein guter Ausgangspunkt.\\
	Für das Einlesen der Daten benutzen wir, sofern nicht weiter angegeben die folgenden Augmentierungen:
	
	\begin{lstlisting}[language=Python, caption=Augmentierung beim Einlesen der Daten]
	__train_transform = transforms.Compose(
	[
	transforms.RandomResizedCrop((image_size, image_size), 
	scale=(0.6, 1.0)),
	transforms.RandomRotation(degrees=15),
	transforms.ColorJitter(brightness=0.1, contrast=0.1, 
	saturation=0.1, hue=0.1),
	transforms.RandomAffine(15),
	transforms.RandomGrayscale(),
	transforms.Normalize(	mean=[0.485, 0.456, 0.406], 
	std=[0.229, 0.224, 0.225]),
	transforms.ToTensor()
	
	]
	
	
	
	\end{lstlisting}
	Die Werte von mean und std variieren für alle ausgeführten Poisoning-Angriffe. Anstatt beide jedes Mal erneut zu berechnen, verwenden wir die von pytorch angegebenen Werte \footnote{\url{https://github.com/pytorch/examples/blob/97304e232807082c2e7b54c597615dc0ad8f6173/imagenet/main.py\#L197-L198}}, die für die vor-trainierten Modelle empfohlen werden und auf dem Datensatz ImageNet\footnote{\url{https://image-net.org/}} basieren.\\ 
	Wir trainieren die Netzwerke über maximal 100 Epochen und benutzen \textit{early stopping} mit einer $patience=20$. Die verwendete Implementierung ist eine modifizierte Version von Bjarte Mehus Sunde \footnote{\url{https://github.com/Bjarten/early-stopping-pytorch}}, die wiederum auf PyTorch Ignite\footnote{\url{https://github.com/pytorch/ignite/blob/master/ignite/handlers/early\_stopping.pyt}} basiert.\\
	
	%\section{Einlesen der Daten bei AC}
	%Ohne Transformationen, wie den Testdatensatz.
	
	
	\section{Parameter für die ausgeführten Angriffe}\label{param_attacks}
	
	\noindent \textbf{Standard-Poisoning-Angriffe:}\\
	
	
	\noindent \textbf{Label-konsistente Poisoning-Angriffe:}\\
	
	Für das projektive Gradientenverfahren benutzen wir $n=5$ Iterationen und eine Schrittweite von 0.015.\\
	
	\section{Angriff und Detektion für mehrere Durchläufe bei $s=3$}
	Es zeigt sich, dass wir unterschiedliche Ergebnisse für das Clustering erhalten, wenn wir für einen gewissen prozentualen Anteil verschiedene Mengen an zu korrumpierenden Bildern innerhalb einer Klasse auswählen. Um eine etwas allgemeinere Aussage für die Detektion treffen zu können führen wir $n=5$ Angriffe pro prozentualem Anteil durch. Dabei unterscheidet sich der Angriff dann dahingehend, dass unterschiedliche Bilder an unterschiedlichen Stellen manipuliert werden.
	Die Ergebnisse dazu befinden sich in 
	
	\begin{table}[ht]
		\begin{center}
			\resizebox{\textwidth}{!}{
				
				
				\begin{tabular}{|l|c|ccc|ccc|}
					\hline
					Prozentualer	&  				&		&	Detektionsrate 		& 			& 			& Detektionsrate 	& 		  \\
					Anteil 			&  	 			&		&	Heatmap Clustering 	& 			& 			&Activation Clustering	&		\\
									& 			 	& ACC 	& 	TPR 	& TNR  		& ACC 		& TPR 	& TNR 	 	\\\hline
					
					33.00			& Mittelwert	&99.82	& 99.46	& 100.00	& 90.36		& 94.41& 87.16   \\ 
									& Varianz		& 0.19	& 0.58 	& 0.00	& 6.81 		& 2.98		& 9.96 \\ \hline
					15.00			& Mittelwert	&99.89	& 99.32	& 99.98	& 85.24		& 96.56& 83.24   \\ 
									& Varianz		& 0.17	& 1.17 	& 0.024	& 10.75 	& 1.98	& 12.88 \\ \hline
					10.00			& Mittelwert	&	& 	& & 68,82		& 77.92	& 67.82   \\ 
									& Varianz		& 	&  	& & 17.82 		& 35.90	& 17.17 \\ \hline
			\end{tabular}}
			\label{tab:ergebnisse_SPA_s3_gemittelt}
			\caption{Gemittelte Detektionsraten für Angriffe mit dem Standard-Sticker und $s=3$.}
		\end{center}
	\end{table}
	
	
	\section{Angriff und Detektion für unterschiedliche Stickergrößen} \label{unterschiedlicheStickergrößen}
	
		\begin{table}[ht]
		\begin{center}
			\resizebox{\textwidth}{!}{
				
				
				\begin{tabular}{|l|c|c|ccc|ccc|}
					\hline
					Seitenlänge s	& Prozentualer 	& AER  		& 		&	Detektionsrate 		& 		& 		& Detektionsrate 	& 		  \\
					des Auslösers 	& Anteil 		& 			& 		&	Heatmap Clustering 	& 		& 	&Activation Clustering	&		\\
					& 				& 			& ACC 	& 	TPR 	& TNR  	& ACC 	& TPR 	& TNR 	 	\\\hline
					
					s=3 			& 33.00			& 100.00	& \textbf{99.96}	& 99.88		& 100.00& 94.76 & 90.77 & 96.73 \\ 
					& 15.00			& 100.00	& \textbf{100.00}	& 100.00 	& 100.00& 76.51 & 99.31	&72.48 \\
					& 10.00			& 100.00 	& \textbf{99.29 }	& 92.9 		& 100.00& 87.62 & 96.17 & 86.17 \\
					& 5.00			& 99.6		& \textbf{99.48 }	& 90.8		& 99.94 & 57.92 & 20.69 & 59.88  \\
					& 2.00			& 100.00	& 52.85				& 0.0 		& 53.94	& \textbf{52.91} & 0.0 	& 54.0 \\ \hline	 				
					
					
					
					s=2 			& 33.00			& 100.00	& \textbf{100.00}& 100.00	& 100.00&99.72	& 99.14	&100.00		\\
					& 15.00			& 100.00	& \textbf{100.00}& 100.00	& 100.00&87.53	& 97.59	& 85.76	\\
					& 10.00			& 100.00	& \textbf{99.72	}& 100.00 	& 99.69	&67.21	& 93.99	& 64.24 \\
					& 5.00 			& 100.00	& \textbf{100.00}& 100.00	& 100.00&47.44	& 10.34	& 49.39 \\
					& 2.00 			& 100.00	& \textbf{58.73	}& 100.00	& 57.88	&49.41	& 17.65	& 50.06	\\
					& 1.00 			& 100.00 	& \textbf{52.37	}& 0.00		& 52.91	& 50.39	& 41.18	& 50.48		 \\\hline
					
					
					
					
					
					
					s=1 			& 33.0 			& 100.0 	& \textbf{100.00}& 100.00	& 100.00& 98.78	& 97.66	& 99.33	 \\ 
					& 15.0			& 100.0		& \textbf{100.00}& 100.00	& 100.00& 96.29	& 79.04	& 99.33	 \\
					& 10.0			& 100.0		& \textbf{100.00}& 100.00	& 100.00& 71.47	& 87.43 & 69.7 	 \\
					& 5.00			& 100.0		& \textbf{100.00}& 100.00	& 100.00& 73.4	& 100.00& 72.0	\\
					& 2.00			& 100.0		& \textbf{100.00}& 100.00	& 100.00& 58.31 & 100.00& 57.45		\\
					& 1.00			& 13.87		& \textbf{60.77 }& 47.06		& 60.91	& 56.99	& 100.00& 56.55 \\ \hline
			\end{tabular}}
	\end{center}
	\end{table}
	\section{Code}
%	Der vollständige Programmcode ist verfügbar unter \url{https://github.com/lukasschulth/MA-Detection-of-Poisoning-Attacks}
	
	%\verbatiminput{Netlayout.txt}
	
	%\verbatiminput{InceptionNet3layout.txt}
	\section{Notizen}
	registered spaces \footnote{\url{https://arxiv.org/pdf/1809.06422.pdf}}
	Barycenters in the Wasserstein Space\footnote{\url{https://arxiv.org/pdf/1809.06422.pdf}}\\
	Was passiert bei der Kombination von 2 verschiedenen Triggern? Einmal keine Überlappung(d.h. 2verschiedene Trigger auf dem selben Bild) vs. auch beide Trigger auf einem Bild ist zulässig.
	\newpage
	
	\printglossaries
	
	\newpage
	
	\bibliographystyle{alpha}
	
	\bibliography{bibfileMAlukasschulth}
	
	
	
\end{document}
